{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu9n3SAO4S87"
      },
      "source": [
        "# 0️⃣ 기본 세팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfgElWgE8FJP",
        "outputId": "6e787d8a-8b51-4b34-afcd-c1b5d7ff28fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.23.5\n",
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n",
        "\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "from tqdm.notebook import trange\n",
        "\n",
        "import random\n",
        "import math\n",
        "from math import floor\n",
        "import queue\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "from collections import Counter\n",
        "import torch.multiprocessing as mp\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKvnq4202dQu",
        "outputId": "b01c8601-cd0c-4278-9f58-2b48ecc91695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0ixhQVY2_Wj",
        "outputId": "71fc4f13-368f-4296-a2f9-f7bdd1cf512f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqL8v9-r3hJJ",
        "outputId": "b2ab6447-5ee9-4202-9c19-e9788ec01d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/🌊Ulsan_parkinglot/alphazero_models\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/My Drive/🌊Ulsan_parkinglot/alphazero_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtjJelMJ8eq-"
      },
      "source": [
        "# 1️⃣ 몬테카를로 시뮬레이션을 이용한 중장기 스케줄링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39cQHa9I-OH-"
      },
      "source": [
        "## 기본 상수 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmR-7QpTH6zc"
      },
      "source": [
        "평균 입항 교통량 / 그 날의 총 처리 화물 건수 / 화물차 한 대가 들어가는데 걸리는 시간"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWENqyMC8J3M"
      },
      "outputs": [],
      "source": [
        "avg_traffic_per_10min = [3, 3, 3, 3, 3, 3,    # 5시\n",
        "                         3, 3, 3, 3, 3, 3,    # 6시\n",
        "                         8, 8, 8, 8, 8, 8,    # 7시\n",
        "                         7, 7, 7, 7, 7, 7,    # 8시\n",
        "                         10, 10, 10, 10, 10, 10, # 9시\n",
        "                         9, 9, 9, 9, 9, 9,  # 10시\n",
        "                         8, 8, 8, 8, 8, 8,  # 11시\n",
        "                         6, 6, 6, 6, 6, 6,  # 12시\n",
        "                         7, 7, 7, 7, 7, 7,  # 13시\n",
        "                         7, 7, 7, 7, 7, 7,  # 14시\n",
        "                         5, 5, 5, 5, 5, 5,  # 15시\n",
        "                         3, 3, 3, 3, 3, 3,  # 16시\n",
        "                         2, 2, 2, 2, 2, 2,  # 17시\n",
        "                         2, 2, 2, 2, 2, 2,  # 18시\n",
        "                         2, 2, 2, 2, 2, 2,  # 19시\n",
        "                         1, 1, 1, 1, 1, 1,  # 20시\n",
        "                         1, 1, 1, 1, 1, 1,  # 21시\n",
        "                         1, 1, 1, 1, 1, 1,  # 22시\n",
        "                         1, 1, 1, 1, 1, 1,  #23시\n",
        "                         ]\n",
        "\n",
        "avg_probabilities = np.array(avg_traffic_per_10min) / sum(avg_traffic_per_10min)\n",
        "\n",
        "scheduled_cars_of_day = 700\n",
        "n = 1.05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu6ZPD_RIPS_"
      },
      "source": [
        "## 중장기 스케줄링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXdvi24iK7ZG"
      },
      "source": [
        "### 몬테카를로"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2ztUOUfITHv"
      },
      "source": [
        "함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Osl30iI-_U7"
      },
      "outputs": [],
      "source": [
        "def generate_random_list(scheduled_cars_of_day, avg_probabilities):\n",
        "    total_traffic = scheduled_cars_of_day\n",
        "    probabilities = avg_probabilities\n",
        "    chosen_intervals = np.random.choice(range(len(probabilities)), size=total_traffic, p=probabilities)\n",
        "    generated_data = [random.uniform(i*10, (i+1)*10) for i in chosen_intervals]\n",
        "\n",
        "    return generated_data\n",
        "\n",
        "def balls_left_in_queue(enter_times):\n",
        "    exit_times = []\n",
        "    current_exit_time = 0\n",
        "    total_front_cars = 0\n",
        "    front_cars_distribution = []\n",
        "    for i, enter_time in enumerate(enter_times):\n",
        "        if current_exit_time == enter_time:\n",
        "            current_exit_time = enter_time\n",
        "        elif current_exit_time + n < enter_time:\n",
        "            current_exit_time = enter_time\n",
        "        else:\n",
        "            current_exit_time += n\n",
        "        exit_times.append(current_exit_time)\n",
        "\n",
        "        front_cars = np.sum(np.array(exit_times[:i+1]) > enter_time)\n",
        "        front_cars_distribution.append(front_cars)\n",
        "        total_front_cars += front_cars\n",
        "\n",
        "    return total_front_cars, front_cars_distribution\n",
        "\n",
        "def monte_carlo_distribution(num_samples, scheduled_cars_of_day, avg_probabilities):\n",
        "    total_front_cars_distribution = {}\n",
        "    enter_times_storage = {}\n",
        "    front_cars_distribution_storage = {}\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        enter_times = generate_random_list(scheduled_cars_of_day, avg_probabilities)\n",
        "        enter_times = sorted(enter_times)\n",
        "        total_front_cars, front_cars_distribution = balls_left_in_queue(enter_times)\n",
        "\n",
        "        if total_front_cars not in total_front_cars_distribution:\n",
        "            total_front_cars_distribution[total_front_cars] = 0\n",
        "            enter_times_storage[total_front_cars] = []\n",
        "            front_cars_distribution_storage[total_front_cars] = []\n",
        "\n",
        "        total_front_cars_distribution[total_front_cars] += 1\n",
        "        enter_times_storage[total_front_cars].append(enter_times)\n",
        "        front_cars_distribution_storage[total_front_cars].append(front_cars_distribution)\n",
        "\n",
        "    return total_front_cars_distribution, enter_times_storage, front_cars_distribution_storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqVfrrh4IWGU"
      },
      "source": [
        "몬테 카를로 시뮬레이션 10000 번 돌리기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq4spolmBVB7"
      },
      "outputs": [],
      "source": [
        "total_front_cars_distribution, enter_times_storage, front_cars_distribution_storage = monte_carlo_distribution(10000, scheduled_cars_of_day, avg_probabilities)\n",
        "\n",
        "labels = sorted(total_front_cars_distribution.keys())\n",
        "values = [total_front_cars_distribution[key] for key in labels]\n",
        "plt.bar(labels, values)\n",
        "plt.xlabel(\"distibution of (total_front_cars == total delay time)\")\n",
        "plt.ylabel(\"frequency\")\n",
        "plt.title(\"montecarlo result\" +\"of total_front_cars_distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpO1H2j3KeBg"
      },
      "source": [
        "몬테카를로 돌렸을 때 상위/하위 총 지연 시간 따져주기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojNtpXuoCIr6"
      },
      "outputs": [],
      "source": [
        "sorted_front_cars_distribution_keys = sorted(total_front_cars_distribution.keys())\n",
        "\n",
        "print(\"하위 5개 총 지연 시간: \\n\")\n",
        "for key in sorted_front_cars_distribution_keys[:5]:\n",
        "    print(f\"지연 시간: {key}, 빈도: {total_front_cars_distribution[key]}\")\n",
        "    print(f\"평균 지연 시간: {key / scheduled_cars_of_day}, 빈도: {total_front_cars_distribution[key]}\")\n",
        "\n",
        "print(\"\\n상위 5개 총 지연시간: \\n\")\n",
        "for key in sorted_front_cars_distribution_keys[-5:][::-1]:\n",
        "    print(f\"지연 시간: {key}, 빈도: {total_front_cars_distribution[key]}\")\n",
        "    print(f\"평균 지연 시간: {key / scheduled_cars_of_day}, 빈도: {total_front_cars_distribution[key]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPaM0OyEKkgd"
      },
      "source": [
        "### 지연 시간 최소일 때"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1P4zMuhwC9Ng"
      },
      "outputs": [],
      "source": [
        "min_key = sorted_front_cars_distribution_keys[0]\n",
        "\n",
        "min_key_sample_enter_time = enter_times_storage[min_key][0]\n",
        "min_key_sample_front_cars = front_cars_distribution_storage[min_key][0]\n",
        "\n",
        "min_total_front_cars, min_front_cars_distribution = balls_left_in_queue(min_key_sample_enter_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7ZJ7q_aKnj7"
      },
      "source": [
        "지연 시간 최소일 때 상위/하위 10개 화물차 한 대 대기시간"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaXAiE5fEzlS"
      },
      "outputs": [],
      "source": [
        "min_front_cars_distribution.sort(reverse = True)\n",
        "print(\"지연 시간 최소일 때 상위 10개 화물차 한 대 대기시간\")\n",
        "print(min_front_cars_distribution[:10])\n",
        "print(\"지연 시간 최소일 때 하위 10개 화물차 한 대 대기시간\")\n",
        "print(min_front_cars_distribution[-10:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLVJ0YoXKtPw"
      },
      "source": [
        "지연 시간 최소일 때 입항량 분포"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0KJRykDE0iz"
      },
      "outputs": [],
      "source": [
        "bins = np.arange(0, (23-5)*6*10 + 1, 10)\n",
        "min_key_sample_enter_time_counts, _ = np.histogram(min_key_sample_enter_time, bins)\n",
        "\n",
        "time_labels = [f\"{i}-{i+10}\" for i in range(0, (23-5)*6*10, 10)]\n",
        "\n",
        "plt.figure(figsize=(16,5))\n",
        "plt.bar(time_labels, min_key_sample_enter_time_counts, color='orange')\n",
        "plt.title(\"distribution of enter time of min delay time case\")\n",
        "plt.xlabel(\"Time interval (10 minutes)\", fontsize=14)\n",
        "plt.ylabel(\"Number of cars\", fontsize=12)\n",
        "plt.xticks(rotation=90, fontsize=7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7T__lLFCoAJ"
      },
      "outputs": [],
      "source": [
        "bins_60min = np.arange(0, (23-5)*6*10 + 1, 60)\n",
        "\n",
        "min_key_sample_enter_time_counts_60min, _ = np.histogram(min_key_sample_enter_time, bins_60min)\n",
        "\n",
        "time_labels_60min = [f\"{i}-{i+60}\" for i in range(0, (23-5)*6*10, 60)]\n",
        "\n",
        "plt.figure(figsize=(16,5))\n",
        "plt.bar(time_labels_60min, min_key_sample_enter_time_counts_60min, color='orange')\n",
        "plt.title(\"Distribution of enter time of min delay time case (60-minute intervals)\")\n",
        "plt.xlabel(\"Time interval (60 minutes)\", fontsize=14)\n",
        "plt.ylabel(\"Number of cars\", fontsize=12)\n",
        "plt.xticks(rotation=90, fontsize=7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT1feG6oJSdR"
      },
      "source": [
        "지연 시간 최소일 때 화물차 한 대마다 얼마나 앞에 차량들이 밀려있는지와 관련된 시계열 분포"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay7Sr6VVGV6c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(min_key_sample_front_cars, color='skyblue')\n",
        "plt.title(\"Time Series of min_key_sample_front_cars\")\n",
        "plt.xlabel(\"each cars\", fontsize=14)\n",
        "plt.ylabel(\"cars count\", fontsize=12)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4i403CP8l37"
      },
      "source": [
        "# 2️⃣ 알파고 제로를 이용한 실시간 스케줄링"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3KEDg4cLPo5",
        "outputId": "303b9df8-0cf0-4124-a2de-3edb80c8e02f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3  7  9  3  6  4  5  5  4  9  5  5 11 14 12 12 12 10  2  5 11  9 11  4\n",
            " 16  7 12 10  9 12 11 13 15 15 11 15  5  8  7  9 13  7  7  8  4 11  4 10\n",
            "  5  6 10  8 10  9 18 10 14 17 11 11  8  8  3  5  5  8  6  5  3  4  6  0\n",
            "  3  1  2  2  0  3  2  2  3  3  1  1  1  5  8  5  4  3  3  3  2  7  0  3\n",
            "  2  2  2  2  1  1  0  3  1  1  2  1]\n"
          ]
        }
      ],
      "source": [
        "print(min_key_sample_enter_time_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWxQWR_RNPI1"
      },
      "source": [
        "## balls_left_in_queue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lhOnwTPNOpT"
      },
      "outputs": [],
      "source": [
        "def balls_left_in_queue(enter_times):\n",
        "    exit_times = []\n",
        "    current_exit_time = 0\n",
        "    total_front_cars = 0\n",
        "\n",
        "    enter_times = sorted(enter_times)\n",
        "\n",
        "    for i, enter_time in enumerate(enter_times):\n",
        "        if current_exit_time == enter_time:\n",
        "            current_exit_time = enter_time\n",
        "        elif current_exit_time + n < enter_time:\n",
        "            current_exit_time = enter_time\n",
        "        else:\n",
        "            current_exit_time += n\n",
        "        exit_times.append(current_exit_time)\n",
        "\n",
        "        front_cars = np.sum(np.array(exit_times[:i+1]) > enter_time)\n",
        "        total_front_cars += front_cars\n",
        "\n",
        "    return total_front_cars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3Yrrem-PB7J"
      },
      "source": [
        "## monte carlo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSqjkd6hPEbx"
      },
      "outputs": [],
      "source": [
        "def generate_random_list(scheduled_cars_sum, probabilities):\n",
        "    chosen_intervals = np.random.choice(range(len(probabilities)), size = scheduled_cars_sum, p = probabilities)\n",
        "    generated_data = [random.uniform(i*10, (i+1)*10) for i in chosen_intervals]\n",
        "\n",
        "    return generated_data\n",
        "\n",
        "def monte_carlo_distribution(num_samples, scheduled_cars_sum, probabilities):\n",
        "    total_front_cars_distribution = {}\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        enter_times = generate_random_list(scheduled_cars_sum, probabilities)\n",
        "        enter_times = sorted(enter_times)\n",
        "        total_front_cars = balls_left_in_queue(enter_times)\n",
        "\n",
        "        if total_front_cars not in total_front_cars_distribution:\n",
        "            total_front_cars_distribution[total_front_cars] = 0\n",
        "\n",
        "        total_front_cars_distribution[total_front_cars] += 1\n",
        "\n",
        "    return total_front_cars_distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j93u-TAp3zTW"
      },
      "source": [
        "## eta_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-m008lL307H"
      },
      "outputs": [],
      "source": [
        "eta_distribution = [2, 5, 7, 5, 5, 4, 3, 2, 1.5, 1]\n",
        "eta_prob = np.array(eta_distribution) / sum(eta_distribution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vD6g8hhNz29"
      },
      "source": [
        "## eta_distribution_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNBoOwbCN3y0"
      },
      "outputs": [],
      "source": [
        "eta_distribution0 = [2, 5, 7, 5, 5, 4, 3, 2, 1.5, 1, 0, 0, 0]\n",
        "eta_distribution1 = [0, 2, 5, 7, 5, 5, 4, 3, 2, 1.5, 1, 0, 0]\n",
        "eta_distribution2 = [0, 0, 2, 5, 7, 5, 5, 4, 3, 2, 1.5, 1, 0]\n",
        "eta_distribution3 = [0, 0, 0, 2, 5, 7, 5, 5, 4, 3, 2, 1.5, 1]\n",
        "\n",
        "distributions = [eta_distribution0, eta_distribution1, eta_distribution2, eta_distribution3]\n",
        "matrix = np.array(distributions)\n",
        "eta_distribution = matrix.sum(axis=0)\n",
        "eta_distribution_prob = np.array(eta_distribution) / sum(eta_distribution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T4rYZqaLWmu"
      },
      "source": [
        "## MinDelay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBXUBDXaLQ2H"
      },
      "outputs": [],
      "source": [
        "class MinDelay:\n",
        "    def __init__(self, eta_distribution_prob, eta_prob):\n",
        "\n",
        "        self.eta_distribution_prob = eta_distribution_prob\n",
        "        self.eta_prob = eta_prob\n",
        "\n",
        "        self.row_count = 50 * 2\n",
        "        self.col_count = 3 + (18-7) * 6 + 9\n",
        "        self.action_size = 4     # 0분, 10분, 20분, 30분 지연  (0, 1, 2, 3)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"MinDelay\"\n",
        "\n",
        "    def get_initial_state(self):\n",
        "        return np.zeros((self.row_count, self.col_count))\n",
        "\n",
        "    # 🔴\n",
        "    def get_next_state(self, state, action, player, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index, car_action, test = False):\n",
        "\n",
        "        # non_zero_indices = np.where(np.array(schedule_range) > 0)[0]\n",
        "        # first_non_zero_index = non_zero_indices[0]\n",
        "\n",
        "        # exclude_indicies = np.where(np.array(long_term_scheduled) <= 0)[0]\n",
        "\n",
        "        # if all(x <= 0 for x in long_term_scheduled[0 : first_non_zero_index + 1]):\n",
        "        #     schedule_range[first_non_zero_index] = 0\n",
        "        #     first_non_zero_index += 7\n",
        "\n",
        "        # if first_non_zero_index < 15 - 1:\n",
        "        #     index_choices = [i for i in range(0, first_non_zero_index + 1) if i not in exclude_indicies]\n",
        "\n",
        "        #     if len(index_choices) == 0:\n",
        "        #         index_choices = [i for i in range(0, first_non_zero_index + 1)]\n",
        "\n",
        "        #     origin_index = random.choice(index_choices)\n",
        "        # elif first_non_zero_index < ((18-7) * 6 - 1) :\n",
        "        #     if long_term_scheduled[first_non_zero_index - 15 + 1] != 0:\n",
        "        #         origin_index = first_non_zero_index - 15 + 1\n",
        "        #     else:\n",
        "        #         index_choices = [i for i in range(first_non_zero_index - 15 + 1, first_non_zero_index + 1) if i not in exclude_indicies]\n",
        "\n",
        "        #         if len(index_choices) == 0:\n",
        "        #             index_choices = [i for i in range(first_non_zero_index - 15 + 1, first_non_zero_index + 1 + 7)]\n",
        "\n",
        "        #         origin_index = random.choice(index_choices)\n",
        "        # else:\n",
        "        #     if long_term_scheduled[first_non_zero_index - 15 + 1] != 0:\n",
        "        #         origin_index = first_non_zero_index - 15 + 1\n",
        "        #     else:\n",
        "        #         index_choices = [i for i in range(first_non_zero_index - 15 + 1, (18-7) * 6 - 1 + 1) if i not in exclude_indicies]\n",
        "\n",
        "        #         if len(index_choices) == 0:\n",
        "        #             index_choices = [first_non_zero_index + 1]\n",
        "\n",
        "        #         origin_index = random.choice(index_choices)\n",
        "\n",
        "        non_zero_indices = np.where(np.array(long_term_scheduled) > 0)[0]\n",
        "        first_non_zero_index = non_zero_indices[0]\n",
        "        origin_index = first_non_zero_index\n",
        "\n",
        "\n",
        "        if sum(scheduled_cars_list) % 2 == 0:\n",
        "            actioned_index = origin_index + 3 + action\n",
        "        else:\n",
        "            car_action = np.random.choice(range(-3, 6 + 1), size=1, p=self.eta_prob)\n",
        "\n",
        "            a_new_row = np.where(state[:50, actioned_index + car_action] == 0)[0][0]\n",
        "            state[a_new_row, actioned_index + car_action] = -1\n",
        "\n",
        "            if test:\n",
        "                b_row_indices = np.where(state[50:, actioned_index + car_action] == 0)[0][0]\n",
        "                b_row = b_row_indices + 50\n",
        "                state[b_row, actioned_index + car_action] = player\n",
        "            else:\n",
        "                b_row_indices = np.where(state[50:, origin_index + 3 + action + car_action] == 0)[0][0]\n",
        "                b_row = b_row_indices + 50\n",
        "                state[b_row, origin_index + 3 + action + car_action] = player\n",
        "\n",
        "            actioned_index = None\n",
        "\n",
        "\n",
        "        # schedule_range[origin_index] -= 1\n",
        "        long_term_scheduled[origin_index] -= 1\n",
        "        scheduled_cars_list[origin_index + 3] += 1\n",
        "\n",
        "        return state, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index\n",
        "\n",
        "    def get_valid_moves(self, state):\n",
        "        return 1\n",
        "\n",
        "    # 🟢\n",
        "    def check_win(self, state, a_score, b_score, scheduled_cars_list, judge_num, is_self = False):\n",
        "        # 심사 시작 조건\n",
        "        # if (sum(scheduled_cars_list) >= 0) and (sum(scheduled_cars_list) % 4 == 0):\n",
        "\n",
        "            # 지금까지 재조정한 화물차들의 시간대\n",
        "            non_zero_indices = np.where(np.array(scheduled_cars_list) != 0)[0]\n",
        "\n",
        "            # 지금까지 재조정한 화물차들의 (재조정 -> 스스로 이동 후) 확률 분포\n",
        "            distributions = []\n",
        "            for index in non_zero_indices:\n",
        "                for cars_count in range(int(scheduled_cars_list[index] // 2)):\n",
        "                    distributions.append([0] * (index - 3) + list(self.eta_distribution_prob) + [0] * ((3 + (18-7) * 6 + 9) - (index + 9)))\n",
        "            matrix = np.array(distributions)\n",
        "            eta_distribution = matrix.sum(axis=0)\n",
        "            probabilities = np.array(eta_distribution) / sum(eta_distribution)\n",
        "\n",
        "            # 하위 20, 25, 50 (몬테카를로)\n",
        "            if sum(scheduled_cars_list) % 2 == 0:\n",
        "                sum_scheduled_cars = sum(scheduled_cars_list) // 2\n",
        "            else:\n",
        "                sum_scheduled_cars = sum(scheduled_cars_list) // 2 + 1\n",
        "\n",
        "            total_front_cars_distribution = monte_carlo_distribution(200, sum_scheduled_cars , probabilities)\n",
        "            labels = sorted(total_front_cars_distribution.keys())\n",
        "            values = [total_front_cars_distribution[key] for key in labels]\n",
        "            cumulative_values = np.cumsum(values)\n",
        "\n",
        "            bottom20 = labels[np.where(cumulative_values >= cumulative_values[-1] / (1/0.2))[0][0]]\n",
        "            bottom35 = labels[np.where(cumulative_values >= cumulative_values[-1] / (1/0.35))[0][0]]\n",
        "            bottom50 = labels[np.where(cumulative_values >= cumulative_values[-1] / (1/0.5))[0][0]]\n",
        "\n",
        "\n",
        "            # a의 총 지연 시간\n",
        "            a_arr = state[:50, :]\n",
        "            a_indices = np.where((a_arr == 1) | (a_arr == -1))\n",
        "            a_result = [a_indices[0][np.where(a_indices[1] == col)] for col in range(a_arr.shape[1])]\n",
        "            a_total_list = []\n",
        "            for i in range(200):\n",
        "                a_chosen_intervals = [idx for idx, arr in enumerate(a_result) for _ in arr]\n",
        "                a_enter_times = [random.uniform(i*10, (i+1)*10) for i in a_chosen_intervals]\n",
        "                a_total_front_cars = balls_left_in_queue(a_enter_times)\n",
        "                a_total_list.append(a_total_front_cars)\n",
        "            counter = Counter(a_total_list)\n",
        "            top_3_common = counter.most_common(3)\n",
        "            top_3_values = [item[0] for item in top_3_common]\n",
        "            avg_a_total_front_cars = sum(top_3_values) / len(top_3_values)\n",
        "\n",
        "\n",
        "            # b의 총 지연 시간\n",
        "            b_arr = state[50:, :]\n",
        "            b_indices = np.where((b_arr == 1) | (b_arr == -1))\n",
        "            b_result = [b_indices[0][np.where(b_indices[1] == col)] for col in range(b_arr.shape[1])]\n",
        "            b_total_list = []\n",
        "            for i in range(200):\n",
        "                b_chosen_intervals = [idx for idx, arr in enumerate(b_result) for _ in arr]\n",
        "                b_enter_times = [random.uniform(i*10, (i+1)*10) for i in b_chosen_intervals]\n",
        "                b_total_front_cars = balls_left_in_queue(b_enter_times)\n",
        "                b_total_list.append(b_total_front_cars)\n",
        "            counter = Counter(b_total_list)\n",
        "            top_3_common = counter.most_common(3)\n",
        "            top_3_values = [item[0] for item in top_3_common]\n",
        "            avg_b_total_front_cars = sum(top_3_values) / len(top_3_values)\n",
        "\n",
        "\n",
        "            if not is_self:\n",
        "                if ((avg_a_total_front_cars > bottom20) or (avg_b_total_front_cars > bottom20)):\n",
        "                    if (avg_a_total_front_cars > bottom35) and (avg_b_total_front_cars <= bottom20):\n",
        "                        return 1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                    if (avg_a_total_front_cars <= bottom20) and (avg_b_total_front_cars > bottom35):\n",
        "                        return (-1)*1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "                    if (avg_a_total_front_cars > bottom35) and (avg_b_total_front_cars > bottom35):\n",
        "                        return 0, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                    if (avg_a_total_front_cars > bottom35) and (avg_b_total_front_cars < bottom35):\n",
        "                        return 1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                    if (avg_a_total_front_cars < bottom35) and (avg_b_total_front_cars > bottom35):\n",
        "                        return (-1)*1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "                    if (avg_a_total_front_cars < bottom35) and (avg_b_total_front_cars < bottom35):\n",
        "                        return 0, False, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "                # if abs(a_score - b_score) > 5 * judge_num:\n",
        "                #     if avg_b_total_front_cars > avg_a_total_front_cars:\n",
        "                #         return (-1) * 1, True, a_score, b_score, scheduled_cars_list, judge_num\n",
        "                #     else:\n",
        "                #         return 1, True, a_score, b_score, scheduled_cars_list, judge_num\n",
        "\n",
        "                # if judge_num == 0:\n",
        "                #     if avg_b_total_front_cars > avg_a_total_front_cars:\n",
        "                #       return (-1) * 1, True, a_score, b_score, scheduled_cars_list, judge_num\n",
        "                #     else:\n",
        "                #         return 1, True, a_score, b_score, scheduled_cars_list, judge_num\n",
        "            else:\n",
        "                print(\"bottom20: \", bottom20, \" bottom35: \", bottom35, \"  bottom50: \", bottom50)\n",
        "                print(\"avg_a_total_front_cars: \", avg_a_total_front_cars)\n",
        "                print(\"avg_b_total_front_cars: \", avg_b_total_front_cars)\n",
        "\n",
        "                # 180\n",
        "                if ((sum(scheduled_cars_list) >= 1000) and ((avg_a_total_front_cars > bottom50) or (avg_b_total_front_cars > bottom50))):\n",
        "                    if (avg_a_total_front_cars > bottom50) and (avg_b_total_front_cars > bottom50):\n",
        "                        return 0, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                    if (avg_a_total_front_cars > bottom50):\n",
        "                        if (avg_b_total_front_cars <= bottom35):\n",
        "                            return 1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                        if (avg_b_total_front_cars > bottom35):\n",
        "                            return 0, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                    if (avg_b_total_front_cars > bottom50):\n",
        "                        if (avg_a_total_front_cars <= bottom35):\n",
        "                            return (-1)*1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                        if (avg_b_total_front_cars > bottom35):\n",
        "                            return 0, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "                # 350\n",
        "                if ((sum(scheduled_cars_list) >= 1000) and ((avg_a_total_front_cars > bottom20) or (avg_b_total_front_cars > bottom20))):\n",
        "                    if (avg_a_total_front_cars > bottom35) and (avg_b_total_front_cars <= bottom20):\n",
        "                        print(sum(scheduled_cars_list))\n",
        "                        return 1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                    if (avg_a_total_front_cars <= bottom20) and (avg_b_total_front_cars > bottom35):\n",
        "                        print(sum(scheduled_cars_list))\n",
        "                        return (-1)*1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "                    if (avg_a_total_front_cars > bottom35) and (avg_b_total_front_cars > bottom35):\n",
        "                        print(sum(scheduled_cars_list))\n",
        "                        return 0, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                    if (avg_a_total_front_cars > bottom35) and (avg_b_total_front_cars < bottom35):\n",
        "                        print(sum(scheduled_cars_list))\n",
        "                        return 1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                    if (avg_a_total_front_cars < bottom35) and (avg_b_total_front_cars > bottom35):\n",
        "                        print(sum(scheduled_cars_list))\n",
        "                        return (-1)*1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "                    if (avg_a_total_front_cars < bottom35) and (avg_b_total_front_cars < bottom35):\n",
        "                        return 0, False, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "                # if abs(a_score - b_score) > 5 * judge_num:\n",
        "                #     if avg_b_total_front_cars > avg_a_total_front_cars:\n",
        "                #         return (-1) * 1, True, a_score, b_score, scheduled_cars_list, judge_num\n",
        "                #     else:\n",
        "                #         return 1, True, a_score, b_score, scheduled_cars_list, judge_num\n",
        "\n",
        "                # if judge_num == 0:\n",
        "                #     if avg_b_total_front_cars > avg_a_total_front_cars:\n",
        "                #       return (-1) * 1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                #     else:\n",
        "                #         return 1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "            # 점수 부여\n",
        "            if avg_a_total_front_cars <= bottom20:\n",
        "                a_score += 5\n",
        "            elif avg_a_total_front_cars <= bottom35:\n",
        "                a_score += 2\n",
        "            elif avg_a_total_front_cars <= bottom50:\n",
        "                a_score += 0\n",
        "            else:\n",
        "                a_score -= 3\n",
        "\n",
        "            if avg_b_total_front_cars <= bottom20:\n",
        "                b_score += 5\n",
        "            elif avg_b_total_front_cars <= bottom35:\n",
        "                b_score += 2\n",
        "            elif avg_b_total_front_cars <= bottom50:\n",
        "                b_score += 0\n",
        "            else:\n",
        "                b_score -= 3\n",
        "\n",
        "            # 남은 심사 횟수 1 감소\n",
        "            judge_num -= 1\n",
        "\n",
        "            # 어차피 terminated 아니면 value 값 무시됨\n",
        "            if a_score > b_score:\n",
        "                    return (-1) * 1, False, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "            else:\n",
        "                return 1, False, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "        # else:\n",
        "        #     # return 0, False, a_score, b_score, scheduled_cars_list, judge_num\n",
        "        #     if a_score > b_score:\n",
        "        #             return (-1) * a_score, False, a_score, b_score, scheduled_cars_list, judge_num\n",
        "        #     else:\n",
        "        #         return b_score, False, a_score, b_score, scheduled_cars_list, judge_num\n",
        "\n",
        "    # 🟢\n",
        "    def get_value_and_terminated(self, state, action, a_score, b_score, scheduled_cars_list, judge_num):\n",
        "        value = 0\n",
        "        if ((sum(scheduled_cars_list) >= 0) and sum(scheduled_cars_list) % 2 == 0):\n",
        "            value, terminated, a_score, b_score, scheduled_cars_list, judge_num, _, _, _, _, _  = self.check_win(state, a_score, b_score, scheduled_cars_list, judge_num)\n",
        "            if terminated :\n",
        "                return value, True, a_score, b_score, scheduled_cars_list, judge_num\n",
        "        return value, False, a_score, b_score, scheduled_cars_list, judge_num\n",
        "\n",
        "    def self_get_value_and_terminated(self, state, action, a_score, b_score, scheduled_cars_list, self_judge_num):\n",
        "        value = 0\n",
        "        if (sum(scheduled_cars_list) % 2 == 0):\n",
        "            value, terminated, a_score, b_score, scheduled_cars_list, self_judge_num, _, _, _, _, _ = self.check_win(state, a_score, b_score, scheduled_cars_list, self_judge_num, is_self = True)\n",
        "            if terminated :\n",
        "                return value, True, a_score, b_score, scheduled_cars_list, self_judge_num\n",
        "        return value, False, a_score, b_score, scheduled_cars_list, self_judge_num\n",
        "\n",
        "    def test_get_value_and_terminated(self, state, action, a_score, b_score, scheduled_cars_list, test_judge_num):\n",
        "        value = 0\n",
        "        if True :\n",
        "            value, terminated, a_score, b_score, scheduled_cars_list, test_judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\\\n",
        "             = self.check_win(state, a_score, b_score, scheduled_cars_list, test_judge_num, is_self = True)\n",
        "            if terminated :\n",
        "                return value, True, a_score, b_score, scheduled_cars_list, test_judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "        return value, False, a_score, b_score, scheduled_cars_list, test_judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "    def get_opponent(self, player):\n",
        "        return (-1) *  player\n",
        "\n",
        "    def get_opponent_value(self, value):\n",
        "        return (-1) *  value\n",
        "\n",
        "    def change_perspective(self, state, player):\n",
        "        return state * player\n",
        "\n",
        "    def get_encoded_state(self, state):\n",
        "        encoded_state = np.stack(\n",
        "            (state == -1, state == 0, state == 1)\n",
        "        ).astype(np.float32)\n",
        "\n",
        "        if len(state.shape) == 3:\n",
        "            encoded_state = np.swapaxes(encoded_state, 0, 1)\n",
        "\n",
        "        return encoded_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d1jRJuh332U"
      },
      "source": [
        "## Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7J4T6Q8Z4HPT"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, game, num_resBlocks, num_hidden, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.startBlock = nn.Sequential(\n",
        "            nn.Conv2d(3, num_hidden, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(num_hidden),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.backBone = nn.ModuleList(\n",
        "            [ResBlock(num_hidden) for i in range(num_resBlocks)]\n",
        "        )\n",
        "\n",
        "        self.policyHead = nn.Sequential(\n",
        "            nn.Conv2d(num_hidden, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * game.row_count * game.col_count, game.action_size)\n",
        "        )\n",
        "\n",
        "        self.valueHead = nn.Sequential(\n",
        "            nn.Conv2d(num_hidden, 3, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(3),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3 * game.row_count * game.col_count, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.startBlock(x)\n",
        "        for resBlock in self.backBone:\n",
        "            x = resBlock(x)\n",
        "        policy = self.policyHead(x)\n",
        "        value = self.valueHead(x)\n",
        "        return policy, value\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, num_hidden):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(num_hidden)\n",
        "        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(num_hidden)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        x += residual\n",
        "        x = F.relu(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvCf_DS5uJen"
      },
      "source": [
        "## Node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Q-Isp57tZ4D"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "    def __init__(self, game, args, state, long_term_scheduled, schedule_range, scheduled_cars_list, a_score, b_score, judge_num, actioned_index, parent=None, action_taken=None, prior=0, visit_count=0):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.state = state\n",
        "        self.parent = parent\n",
        "        self.action_taken = action_taken\n",
        "        self.prior = prior\n",
        "\n",
        "        self.children = []\n",
        "\n",
        "        self.visit_count = visit_count\n",
        "        self.value_sum = 0\n",
        "\n",
        "        self.long_term_scheduled = long_term_scheduled\n",
        "        self.schedule_range = schedule_range\n",
        "        self.scheduled_cars_list = scheduled_cars_list\n",
        "        self.a_score = a_score\n",
        "        self.b_score = b_score\n",
        "        self.judge_num = judge_num\n",
        "        self.actioned_index = actioned_index\n",
        "\n",
        "    def is_fully_expanded(self):\n",
        "        return len(self.children) > 0\n",
        "\n",
        "    def select(self):\n",
        "        best_child = None\n",
        "        best_ucb = -np.inf\n",
        "\n",
        "        for child in self.children:\n",
        "            ucb = self.get_ucb(child)\n",
        "            if ucb > best_ucb:\n",
        "                best_child = child\n",
        "                best_ucb = ucb\n",
        "\n",
        "        return best_child\n",
        "\n",
        "    def get_ucb(self, child):\n",
        "        if child.visit_count == 0:\n",
        "            q_value = 0\n",
        "        else:\n",
        "            q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n",
        "        return q_value + self.args['C'] * (math.sqrt(self.visit_count) / (child.visit_count + 1)) * child.prior\n",
        "\n",
        "    # 🔴\n",
        "    def expand(self, policy, origin_long_term_scheduled, origin_schedule_range, origin_scheduled_cars_list, a_score, b_score, judge_num, origin_actioned_index):\n",
        "\n",
        "        car_action = np.random.choice(range(-3, 6 + 1), size=1, p=self.game.eta_prob)\n",
        "\n",
        "        for action, prob in enumerate(policy):\n",
        "            long_term_scheduled = copy.deepcopy(origin_long_term_scheduled)\n",
        "            schedule_range = copy.deepcopy(origin_schedule_range)\n",
        "            scheduled_cars_list = copy.deepcopy(origin_scheduled_cars_list)\n",
        "\n",
        "            if prob > 0:\n",
        "                child_state = self.state.copy()\n",
        "\n",
        "                child_state, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index \\\n",
        "                 = self.game.get_next_state(child_state, action, 1, long_term_scheduled, schedule_range, scheduled_cars_list, origin_actioned_index, car_action)\n",
        "                # 🟡\n",
        "                child_state = self.game.change_perspective(child_state, player=-1)\n",
        "\n",
        "                child = Node(self.game, self.args, child_state, long_term_scheduled, schedule_range, scheduled_cars_list, a_score, b_score, judge_num, actioned_index, self, action, prob)\n",
        "                self.children.append(child)\n",
        "\n",
        "        return child\n",
        "\n",
        "    def backpropagate(self, value):\n",
        "        self.value_sum += value\n",
        "        self.visit_count += 1\n",
        "\n",
        "        value = self.game.get_opponent_value(value)\n",
        "        if self.parent is not None:\n",
        "            self.parent.backpropagate(value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE9K19beue1f"
      },
      "source": [
        "## MCTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddp2E3wUucdN"
      },
      "outputs": [],
      "source": [
        "class MCTS:\n",
        "    def __init__(self, game, args, model):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.model = model\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def search(self, state, origin_long_term_scheduled, origin_schedule_range, origin_scheduled_cars_list, origin_judge_num, origin_actioned_index, origin_a_score = 0, origin_b_score = 0):\n",
        "        root = Node(self.game, self.args, state, origin_long_term_scheduled, origin_schedule_range, origin_scheduled_cars_list, origin_a_score, origin_b_score, origin_judge_num, origin_actioned_index, visit_count=1)\n",
        "\n",
        "        policy, _ = self.model(\n",
        "            torch.tensor(self.game.get_encoded_state(state), device=self.model.device).unsqueeze(0)\n",
        "        )\n",
        "        policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
        "        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
        "            * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size)\n",
        "\n",
        "        valid_moves = self.game.get_valid_moves(state)\n",
        "        policy *= valid_moves\n",
        "        policy /= np.sum(policy)\n",
        "\n",
        "        long_term_scheduled = copy.deepcopy(origin_long_term_scheduled)\n",
        "        schedule_range = copy.deepcopy(origin_schedule_range)\n",
        "        scheduled_cars_list = copy.deepcopy(origin_scheduled_cars_list)\n",
        "        a_score = origin_a_score\n",
        "        b_score = origin_b_score\n",
        "        judge_num = origin_judge_num\n",
        "        actioned_index = origin_actioned_index\n",
        "\n",
        "        # 🔴\n",
        "        child = root.expand(policy, long_term_scheduled, schedule_range, scheduled_cars_list, a_score, b_score, judge_num, actioned_index)\n",
        "\n",
        "        for search in range(self.args['num_searches']):\n",
        "            node = root\n",
        "\n",
        "            long_term_scheduled = copy.deepcopy(origin_long_term_scheduled)\n",
        "            schedule_range = copy.deepcopy(origin_schedule_range)\n",
        "            scheduled_cars_list = copy.deepcopy(origin_scheduled_cars_list)\n",
        "            a_score = origin_a_score\n",
        "            b_score = origin_b_score\n",
        "            judge_num = origin_judge_num\n",
        "\n",
        "            while node.is_fully_expanded():\n",
        "                node = node.select()\n",
        "\n",
        "            long_term_scheduled = node.long_term_scheduled\n",
        "            schedule_range = node.schedule_range\n",
        "            scheduled_cars_list = node.scheduled_cars_list\n",
        "            a_score = node.a_score\n",
        "            b_score = node.b_score\n",
        "            judge_num = node.judge_num\n",
        "\n",
        "            # 🟢\n",
        "\n",
        "            value, is_terminal, a_score, b_score, scheduled_cars_list, judge_num \\\n",
        "            = self.game.get_value_and_terminated(node.state, node.action_taken, a_score, b_score, scheduled_cars_list, judge_num)\n",
        "            value = self.game.get_opponent_value(value)\n",
        "\n",
        "            # if (is_terminal):\n",
        "                # print(\"⭐⭐⭐⭐⭐⭐⭐⭐⭐⭐⭐⭐⭐⭐\")\n",
        "\n",
        "            if not is_terminal:\n",
        "                policy, value = self.model(\n",
        "                    torch.tensor(self.game.get_encoded_state(node.state), device=self.model.device).unsqueeze(0)\n",
        "                )\n",
        "                policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
        "                valid_moves = self.game.get_valid_moves(node.state)\n",
        "                policy *= valid_moves\n",
        "                policy /= np.sum(policy)\n",
        "\n",
        "                value = value.item()\n",
        "\n",
        "                # 🔴\n",
        "                child = node.expand(policy, long_term_scheduled, schedule_range, scheduled_cars_list, a_score, b_score, judge_num, node.actioned_index)\n",
        "\n",
        "            node.backpropagate(value)\n",
        "\n",
        "\n",
        "        # ⭐⭐⭐\n",
        "        action_probs = np.zeros(self.game.action_size)\n",
        "        for child in root.children:\n",
        "            action_probs[child.action_taken] = child.visit_count\n",
        "        action_probs /= np.sum(action_probs)\n",
        "        return action_probs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCodj8Ukz_Hj"
      },
      "source": [
        "## alphagozero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1F60mE80BGq"
      },
      "outputs": [],
      "source": [
        "class AlphaZero:\n",
        "    def __init__(self, model, optimizer, game, args, long_term_scheduled, schedule_range, scheduled_cars_list, judge_num, self_judge_num):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.long_term_scheduled = copy.deepcopy(long_term_scheduled)\n",
        "        self.schedule_range = copy.deepcopy(schedule_range)\n",
        "        self.scheduled_cars_list = copy.deepcopy(scheduled_cars_list)\n",
        "        self.judge_num = judge_num\n",
        "        self.self_judge_num = self_judge_num\n",
        "        self.mcts = MCTS(game, args, model)\n",
        "\n",
        "    def selfPlay(self, long_term_scheduled, schedule_range, scheduled_cars_list, judge_num, self_judge_num, a_score = 0, b_score = 0):\n",
        "        memory = []\n",
        "        player = 1\n",
        "        state = self.game.get_initial_state()\n",
        "\n",
        "        for i, counts in enumerate(scheduled_cars_list):\n",
        "            for count in range(int(counts / 2)):\n",
        "                cars_action = np.random.choice(range(-3, 6 + 1), size=1, p=self.game.eta_prob)\n",
        "\n",
        "                action = random.randint(0, 3)\n",
        "                row = np.where(state[:50, i  + action + cars_action] == 0)[0][0]\n",
        "                state[row, i  + action + cars_action] = -1\n",
        "\n",
        "                action = random.randint(0, 3)\n",
        "                row= np.where(state[50:, i  + action + cars_action] == 0)[0][0] + 50\n",
        "                state[row, i + action + cars_action] = 1\n",
        "\n",
        "        # 마지막으로 b가 둠\n",
        "        # a가 초수를 둬야 하는 판으로 state 들어감\n",
        "\n",
        "        actioned_index = None\n",
        "\n",
        "        while True:\n",
        "            # 🟡\n",
        "            neutral_state = self.game.change_perspective(state, player)\n",
        "\n",
        "            # search\n",
        "            action_probs = self.mcts.search(neutral_state, long_term_scheduled, schedule_range, scheduled_cars_list, judge_num, actioned_index)\n",
        "\n",
        "            memory.append((neutral_state, action_probs, player))\n",
        "\n",
        "            temperature_action_probs = action_probs ** (1 / self.args['temperature'])\n",
        "            temperature_action_probs /= sum(temperature_action_probs)   # Divide temperature_action_probs with its sum in case of an error\n",
        "            action = np.random.choice(self.game.action_size, p=temperature_action_probs)\n",
        "\n",
        "            # 🔴\n",
        "            car_action = np.random.choice(range(-3, 6 + 1), size=1, p=self.game.eta_prob)\n",
        "\n",
        "            state, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index \\\n",
        "             = self.game.get_next_state(state, action, player, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index, car_action)\n",
        "\n",
        "            # 🟢\n",
        "            value, is_terminal, a_score, b_score, scheduled_cars_list, self_judge_num \\\n",
        "            = self.game.self_get_value_and_terminated(state, action, a_score, b_score, scheduled_cars_list, self_judge_num)\n",
        "\n",
        "            print(\"🧠 moved_cars: \", sum(scheduled_cars_list) - sum(self.scheduled_cars_list))\n",
        "            print(\"🧠 action\", action)\n",
        "            print(\"🧠 a_score: \", a_score, \"   🧠 b_score\", b_score)\n",
        "\n",
        "            if is_terminal:\n",
        "                returnMemory = []\n",
        "                for hist_neutral_state, hist_action_probs, hist_player in memory:\n",
        "                    hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
        "                    returnMemory.append((\n",
        "                        self.game.get_encoded_state(hist_neutral_state),\n",
        "                        hist_action_probs,\n",
        "                        hist_outcome\n",
        "                    ))\n",
        "                # 판이 이런 상태일 때(게임 중 어떤 상태), 이 수를 택하면, 결과적으로 진다 / 이긴다\n",
        "                return returnMemory\n",
        "\n",
        "            player = self.game.get_opponent(player)\n",
        "            print(\"🧠 is_terminal:\", is_terminal)\n",
        "            print()\n",
        "\n",
        "    def train(self, memory):\n",
        "        random.shuffle(memory)\n",
        "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
        "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])] # Change to memory[batchIdx:batchIdx+self.args['batch_size']] in case of an error\n",
        "            state, policy_targets, value_targets = zip(*sample)\n",
        "\n",
        "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
        "\n",
        "            state = torch.tensor(state, dtype=torch.float32, device=self.model.device)\n",
        "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n",
        "            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n",
        "\n",
        "            out_policy, out_value = self.model(state)\n",
        "\n",
        "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
        "            value_loss = F.mse_loss(out_value, value_targets)\n",
        "            loss = policy_loss + value_loss\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "    def learn(self):\n",
        "        for iteration in range(self.args['num_iterations']):\n",
        "            memory = []\n",
        "\n",
        "            self.model.eval()\n",
        "            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations']):\n",
        "                memory += self.selfPlay(self.long_term_scheduled, self.schedule_range, self.scheduled_cars_list, self.judge_num, self.self_judge_num)\n",
        "\n",
        "            self.model.train()\n",
        "            for epoch in trange(self.args['num_epochs']):\n",
        "                self.train(memory)\n",
        "\n",
        "            return self.model.state_dict(), self.optimizer.state_dict(), memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj2L-fR_Bo8k"
      },
      "source": [
        "## ⭐ training_demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QmYjKdQBsOX"
      },
      "outputs": [],
      "source": [
        "# min_key_sample_enter_time_counts[min_key_sample_enter_time_counts == 0] = 1\n",
        "# long_term_scheduled = list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1]\n",
        "\n",
        "# schedule_range = []\n",
        "\n",
        "# for i, cars in enumerate(long_term_scheduled):\n",
        "#     if i < 15:\n",
        "#         schedule_range.append(math.ceil(sum(long_term_scheduled[0 : i]) / 15))\n",
        "#     elif i < 6 * (18-7):\n",
        "#         schedule_range.append(math.ceil(sum(long_term_scheduled[i - 15 + 1: i + 1]) / 15))\n",
        "\n",
        "# for i in range( 6*(18-7) - 15 + 1, 6*(18-7)):\n",
        "#     schedule_range.append(math.ceil(sum(long_term_scheduled[i: 6*(18-7)]) / 15))\n",
        "\n",
        "# # =============================================================\n",
        "\n",
        "# # 📌📌 118은 sum(scheduled_cars_list)\n",
        "# # 📌📌 심사 횟수와 judge_num\n",
        "\n",
        "# initial_index = 14\n",
        "\n",
        "# valid_indices = [i for i, val in enumerate(long_term_scheduled[:initial_index]) if val > 0]\n",
        "\n",
        "# selected_indices = []\n",
        "# for _ in range(sum(schedule_range[:initial_index])):\n",
        "#     idx = np.random.choice(valid_indices)\n",
        "#     while long_term_scheduled[idx] <= 0:\n",
        "#         valid_indices.remove(idx)\n",
        "#         idx = np.random.choice(valid_indices)\n",
        "#     long_term_scheduled[idx] -= 1\n",
        "#     selected_indices.append(idx)\n",
        "\n",
        "# sorted_indices = sorted(selected_indices)\n",
        "# counts = Counter(sorted_indices)\n",
        "# count_list = [counts[element] for element in counts]\n",
        "\n",
        "# long_term_scheduled = list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1]\n",
        "# for i, value in enumerate(count_list):\n",
        "#     long_term_scheduled [i] -= value\n",
        "# scheduled_cars_list = [0] * 3 + count_list + [0] * (len(long_term_scheduled) - len(count_list)) + [0] * 9\n",
        "# judge_num = (sum(long_term_scheduled) - sum(schedule_range[:initial_index])) // 1 + 1\n",
        "# self_judge_num = (sum(long_term_scheduled) - sum(schedule_range[:initial_index])) // 4 + 1\n",
        "# schedule_range[0:initial_index] = [0] * initial_index\n",
        "\n",
        "# long_term_scheduled = list(2 * np.array(long_term_scheduled))\n",
        "# schedule_range = list(2 * np.array(schedule_range))\n",
        "# scheduled_cars_list = list(2 * np.array(scheduled_cars_list))\n",
        "\n",
        "# # ===============================================================\n",
        "\n",
        "\n",
        "# game = MinDelay(eta_distribution_prob, eta_prob)\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# model = ResNet(game, 9, 128, device)\n",
        "\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "\n",
        "# args = {\n",
        "#     'C': 2,\n",
        "#     'num_iterations': 1,          # 몇 번 모델을 훈련할꺼냐\n",
        "#     'num_selfPlay_iterations': 2, # 자기대국 몇 번 할꺼냐 = 훈련 샘플의 수\n",
        "#     'num_searches': 50,          # 얼만큼(몇 노드만큼) 더 내다볼거냐\n",
        "#     'num_epochs': 1,              # 몇 에포크 돌릴꺼냐\n",
        "#     'num_parallel_games': 100,\n",
        "#     'batch_size': 128,\n",
        "#     'temperature': 1.25,\n",
        "#     'dirichlet_epsilon': 0.25,\n",
        "#     'dirichlet_alpha': 0.3\n",
        "# }\n",
        "\n",
        "# alphaZero = AlphaZero(model, optimizer, game, args, long_term_scheduled, schedule_range, scheduled_cars_list, judge_num, self_judge_num)\n",
        "# model_state_dict, optimizer_state_dict, memory = alphaZero.learn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDzdzqeSAf74"
      },
      "outputs": [],
      "source": [
        "# print(list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1])\n",
        "# print()\n",
        "# print(count_list)\n",
        "# print()\n",
        "# print(scheduled_cars_list)\n",
        "# print(sum(scheduled_cars_list))\n",
        "# print(len(scheduled_cars_list))\n",
        "# print()\n",
        "# print(long_term_scheduled)\n",
        "# print(sum(long_term_scheduled))\n",
        "# print(len(long_term_scheduled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoBx3Ke10n6L"
      },
      "outputs": [],
      "source": [
        "# long_term_scheduled = [a - b for a, b in zip(long_term_scheduled, count_list)]\n",
        "# print(long_term_scheduled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbq2Eq771btw"
      },
      "source": [
        "## MCTSParellel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwpS_UFd1krK"
      },
      "outputs": [],
      "source": [
        "class MCTSParallel:\n",
        "    def __init__(self, game, args, model):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.model = model\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def search(self, states, spGames, origin_long_term_scheduleds, origin_schedule_ranges, origin_scheduled_cars_lists, origin_judge_nums, origin_actioned_indexes, origin_a_scores = 0, origin_b_scores = 0):\n",
        "        policy, _ = self.model(torch.tensor(self.game.get_encoded_state(states), device=self.model.device))\n",
        "        policy = torch.softmax(policy, axis=1).cpu().numpy()\n",
        "        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
        "            * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size, size=policy.shape[0])\n",
        "\n",
        "        for i, spg in enumerate(spGames):\n",
        "            spg_policy = policy[i]\n",
        "            valid_moves = self.game.get_valid_moves(states[i])\n",
        "            spg_policy *= valid_moves\n",
        "            spg_policy += 0.2\n",
        "            spg_policy /= np.sum(spg_policy)\n",
        "            print(\"mcts policy: \", spg_policy)\n",
        "\n",
        "            state = copy.deepcopy(states[i])\n",
        "            origin_long_term_scheduled = origin_long_term_scheduleds[i]\n",
        "            origin_schedule_range = origin_schedule_ranges[i]\n",
        "            origin_scheduled_cars_list = origin_scheduled_cars_lists[i]\n",
        "            origin_a_score = 0\n",
        "            origin_b_score = 0\n",
        "            origin_judge_num = origin_judge_nums[i]\n",
        "            origin_actioned_index = origin_actioned_indexes[i]\n",
        "\n",
        "            for root_index in range(len(spg.root)):\n",
        "                spg.root[root_index] = Node(self.game, self.args, state, origin_long_term_scheduled, origin_schedule_range, origin_scheduled_cars_list, \\\n",
        "                                origin_a_score, origin_b_score, origin_judge_num, origin_actioned_index, visit_count=1)\n",
        "\n",
        "                long_term_scheduled = copy.deepcopy(origin_long_term_scheduled)\n",
        "                schedule_range = copy.deepcopy(origin_schedule_range)\n",
        "                scheduled_cars_list = copy.deepcopy(origin_scheduled_cars_list)\n",
        "                a_score = origin_a_score\n",
        "                b_score = origin_b_score\n",
        "                judge_num = origin_judge_num\n",
        "                actioned_index = origin_actioned_index\n",
        "\n",
        "                spg.root[root_index].expand(spg_policy, long_term_scheduled, schedule_range, scheduled_cars_list, a_score, b_score, judge_num, actioned_index)\n",
        "\n",
        "\n",
        "        for root_index in range(len(spGames[0].root)):\n",
        "            for search in range(self.args['num_searches']):\n",
        "                for spg in spGames:\n",
        "                    spg.node = None\n",
        "                    node = spg.root[root_index]\n",
        "\n",
        "                    while node.is_fully_expanded():\n",
        "                        node = node.select()\n",
        "\n",
        "                    long_term_scheduled = node.long_term_scheduled\n",
        "                    schedule_range = node.schedule_range\n",
        "                    scheduled_cars_list = node.scheduled_cars_list\n",
        "                    a_score = node.a_score\n",
        "                    b_score = node.b_score\n",
        "                    judge_num = node.judge_num\n",
        "                    actioned_index = node.actioned_index\n",
        "\n",
        "                    value, is_terminal, a_score, b_score, scheduled_cars_list, judge_num \\\n",
        "                    = self.game.get_value_and_terminated(node.state, node.action_taken, a_score, b_score, scheduled_cars_list, judge_num)\n",
        "                    value = self.game.get_opponent_value(value)\n",
        "\n",
        "                    if is_terminal:\n",
        "                        node.backpropagate(value)\n",
        "\n",
        "                    else:\n",
        "                        spg.node = node\n",
        "\n",
        "                expandable_spGames = [mappingIdx for mappingIdx in range(len(spGames)) if spGames[mappingIdx].node is not None]\n",
        "\n",
        "                # 나의 턴의 value 반환\n",
        "                # 💎 => 게임이 끝나지 않았으면 value 업데이트 하여 < 확장 >, < 역전파 >\n",
        "\n",
        "                # 병렬로 한번에 고려할 game 경우의 수에 대해 states 생성,\n",
        "                # 병렬로 states의 policy와 value값 반환 (value 업데이트)\n",
        "\n",
        "                if len(expandable_spGames) > 0:\n",
        "                    states = np.stack([spGames[mappingIdx].node.state for mappingIdx in expandable_spGames])\n",
        "\n",
        "                    policy, value = self.model(\n",
        "                        torch.tensor(self.game.get_encoded_state(states), device=self.model.device)\n",
        "                    )\n",
        "                    policy = torch.softmax(policy, axis=1).cpu().numpy()\n",
        "                    value = value.cpu().numpy()\n",
        "\n",
        "                # 각각의 game에 대해 확장, 역전파 수행\n",
        "                for i, mappingIdx in enumerate(expandable_spGames):\n",
        "                    # 끝나지 않은 게임의 node는 반드시 존재 (해당 게임의 선택된 best_child)\n",
        "                    node = spGames[mappingIdx].node\n",
        "                    spg_policy, spg_value = policy[i], value[i]\n",
        "\n",
        "                    valid_moves = self.game.get_valid_moves(node.state)\n",
        "                    spg_policy *= valid_moves\n",
        "                    spg_policy /= np.sum(spg_policy)\n",
        "\n",
        "                    node.expand(spg_policy, long_term_scheduled, schedule_range, scheduled_cars_list, a_score, b_score, judge_num, actioned_index)\n",
        "                    node.backpropagate(spg_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xStX5BWX1n8s"
      },
      "source": [
        "## AlphaZeroParallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY2RDZNY1qeN"
      },
      "outputs": [],
      "source": [
        "class SPG:\n",
        "    def __init__(self, game, long_term_scheduled, schedule_range, scheduled_cars_list, judge_num, self_judge_num, actioned_index, a_score = 0, b_score = 0, size = 1):\n",
        "        self.state = game.get_initial_state()\n",
        "        self.memory = []\n",
        "        self.root = [None] * size\n",
        "        self.node = None\n",
        "\n",
        "        self.long_term_scheduled = copy.deepcopy(long_term_scheduled)\n",
        "        self.schedule_range = copy.deepcopy(schedule_range)\n",
        "        self.scheduled_cars_list = copy.deepcopy(scheduled_cars_list)\n",
        "        self.judge_num = judge_num\n",
        "        self.self_judge_num = self_judge_num\n",
        "        self.actioned_index = copy.deepcopy(actioned_index)\n",
        "        self.a_score = a_score\n",
        "        self.b_score = b_score\n",
        "\n",
        "        for i, counts in enumerate(scheduled_cars_list):\n",
        "            for count in range(int(counts / 2)):\n",
        "                cars_action = np.random.choice(range(-3, 6 + 1), size=1, p=game.eta_prob)\n",
        "                action = random.randint(0, 3)\n",
        "\n",
        "                row = np.where(self.state[:50, i  + action + cars_action] == 0)[0][0]\n",
        "                self.state[row, i  + action + cars_action] = -1\n",
        "\n",
        "                row= np.where(self.state[50:, i  + action + cars_action] == 0)[0][0] + 50\n",
        "                self.state[row, i + action + cars_action] = 1\n",
        "\n",
        "        _, terminated, _, _, _, _ = game.check_win(self.state, self.a_score, self.b_score, self.scheduled_cars_list, self.judge_num)\n",
        "\n",
        "        while terminated == True:\n",
        "            self.state = game.get_initial_state()\n",
        "            for i, counts in enumerate(scheduled_cars_list):\n",
        "                for count in range(int(counts / 2)):\n",
        "                    cars_action = np.random.choice(range(-3, 6 + 1), size=1, p=game.eta_prob)\n",
        "                    action = random.randint(0, 3)\n",
        "\n",
        "                    row = np.where(self.state[:50, i  + action + cars_action] == 0)[0][0]\n",
        "                    self.state[row, i  + action + cars_action] = -1\n",
        "\n",
        "                    row= np.where(self.state[50:, i  + action + cars_action] == 0)[0][0] + 50\n",
        "                    self.state[row, i + action + cars_action] = 1\n",
        "\n",
        "            _, terminated, _, _, _, _ = game.check_win(self.state, self.a_score, self.b_score, self.scheduled_cars_list, self.judge_num)\n",
        "\n",
        "\n",
        "class AlphaZeroParallel:\n",
        "    def __init__(self, model, optimizer, game, args, long_term_scheduled, schedule_range, scheduled_cars_list, judge_num, self_judge_num):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "\n",
        "        self.long_term_scheduled = copy.deepcopy(long_term_scheduled)\n",
        "        self.schedule_range = copy.deepcopy(schedule_range)\n",
        "        self.scheduled_cars_list = copy.deepcopy(scheduled_cars_list)\n",
        "        self.judge_num = judge_num\n",
        "        self.self_judge_num = self_judge_num\n",
        "\n",
        "        self.mcts = MCTSParallel(game, args, model)\n",
        "\n",
        "    def selfPlay(self, long_term_scheduled, schedule_range, scheduled_cars_list, judge_num, self_judge_num, a_score = 0, b_score = 0):\n",
        "        return_memory = []\n",
        "        player = 1\n",
        "        spGames = [SPG(self.game, self.long_term_scheduled, self.schedule_range, self.scheduled_cars_list, self.judge_num, \\\n",
        "                       self.self_judge_num, actioned_index = None, a_score = 0, b_score = 0) for spg in range(self.args['num_parallel_games'])]\n",
        "\n",
        "        num_cars = 0\n",
        "        while len(spGames) > 0:\n",
        "            # 병렬로 mcts 수행 (계속 번갈아가며 수행)\n",
        "            states = np.stack([spg.state for spg in spGames])\n",
        "            long_term_scheduleds = np.stack([spg.long_term_scheduled for spg in spGames])\n",
        "            schedule_ranges = np.stack([spg.schedule_range for spg in spGames])\n",
        "            scheduled_cars_lists = np.stack([spg.scheduled_cars_list for spg in spGames])\n",
        "            judge_nums = [spg.judge_num for spg in spGames]\n",
        "            self_judge_nums = [spg.self_judge_num for spg in spGames]\n",
        "            actioned_indexs = [spg.actioned_index for spg in spGames]\n",
        "\n",
        "            neutral_states = self.game.change_perspective(states, player)\n",
        "\n",
        "            self.mcts.search(neutral_states, spGames, long_term_scheduleds, schedule_ranges, scheduled_cars_lists, judge_nums, actioned_indexs)\n",
        "\n",
        "            # print(\"⭐⭐⭐⭐⭐search 완⭐⭐⭐⭐⭐\")\n",
        "\n",
        "            # 각각의 게임 하나에 대해 수행\n",
        "            for i in range(len(spGames))[::-1]:\n",
        "                spg = spGames[i]\n",
        "\n",
        "                # 행동 확률 계산:\n",
        "                action_probs = np.zeros(self.game.action_size)\n",
        "\n",
        "                for root_index in range(len(spg.root)):\n",
        "                    for child in spg.root[root_index].children:\n",
        "                        action_probs[child.action_taken] += child.visit_count\n",
        "\n",
        "                action_probs /= np.sum(action_probs)\n",
        "                print(\"action_probs: \", action_probs)\n",
        "\n",
        "\n",
        "                # (상태, 그 상태일 때 확률 분포, player)\n",
        "                spg.memory.append((spg.root[0].state, action_probs, player))\n",
        "\n",
        "                #  행동 확률 분포를 기반으로 하나의 행동을 선택합니다.\n",
        "                temperature_action_probs = action_probs ** (1 / self.args['temperature'])\n",
        "                temperature_action_probs /= sum(temperature_action_probs)\n",
        "                action = np.random.choice(self.game.action_size, p=temperature_action_probs) # Divide temperature_action_probs with its sum in case of an error\n",
        "\n",
        "                # 상태 업데이트\n",
        "\n",
        "                car_action = np.random.choice(range(-3, 6 + 1), size=1, p=self.game.eta_prob)\n",
        "\n",
        "                spg.state, spg.long_term_scheduled, spg.schedule_range, spg.scheduled_cars_list, spg.actioned_index \\\n",
        "                = self.game.get_next_state(spg.state, action, player, spg.long_term_scheduled, spg.schedule_range, spg.scheduled_cars_list, spg.actioned_index, car_action)\n",
        "\n",
        "                # 게임 종료 여부 확인\n",
        "\n",
        "                value, is_terminal, spg.a_score, spg.b_score, spg.scheduled_cars_list, spg.self_judge_num \\\n",
        "                = self.game.self_get_value_and_terminated(spg.state, action, spg.a_score, spg.b_score, spg.scheduled_cars_list, spg.self_judge_num)\n",
        "\n",
        "                a_sub_array = spg.state[:50]\n",
        "                b_sub_array = spg.state[50:]\n",
        "\n",
        "                a_mask = (a_sub_array != 1) & (a_sub_array != -1)\n",
        "                b_mask = (b_sub_array != 1) & (b_sub_array != -1)\n",
        "\n",
        "                a_count = 50 - a_mask.sum(axis=0)\n",
        "                b_count = 50 - b_mask.sum(axis=0)\n",
        "\n",
        "                print(\"a_count\")\n",
        "                print(a_count)\n",
        "                print(\"b_count\")\n",
        "                print(b_count)\n",
        "\n",
        "                if is_terminal:\n",
        "                    for hist_neutral_state, hist_action_probs, hist_player in spg.memory:\n",
        "                        hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
        "                        return_memory.append((\n",
        "                            self.game.get_encoded_state(hist_neutral_state),\n",
        "                            hist_action_probs,\n",
        "                            hist_outcome\n",
        "                        ))\n",
        "                    del spGames[i]\n",
        "\n",
        "                print(i, \"번째 게임판\")\n",
        "                print(\"a_score\", spg.a_score, \"   b_score\", spg.b_score)\n",
        "\n",
        "            num_cars += 1\n",
        "            print(\"🧠 모든 게임에 대해 a, b 모두 합해서\", sum(spg.scheduled_cars_list) , \"만큼 자동차 두었음\")\n",
        "            print()\n",
        "            player = self.game.get_opponent(player)\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        return return_memory\n",
        "\n",
        "    def train(self, memory):\n",
        "        # 데이터 섞기\n",
        "        random.shuffle(memory)\n",
        "\n",
        "        # 배치 학습\n",
        "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
        "            # 현재 배치의 데이터를 추출\n",
        "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])] # Change to memory[batchIdx:batchIdx+self.args['batch_size']] in case of an error\n",
        "            state, policy_targets, value_targets = zip(*sample)\n",
        "\n",
        "            # 데이터 변환\n",
        "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
        "\n",
        "            state = torch.tensor(state, dtype=torch.float32, device=self.model.device)\n",
        "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n",
        "            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n",
        "\n",
        "            # 모델 예측\n",
        "            out_policy, out_value = self.model(state)\n",
        "\n",
        "            # 손실 계산\n",
        "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
        "            value_loss = F.mse_loss(out_value, value_targets)\n",
        "            loss = policy_loss + value_loss\n",
        "\n",
        "            # 역전파 및 업데이트\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "    # 전체 프로세스 지정\n",
        "    def learn(self):\n",
        "        for iteration in range(self.args['num_iterations']):\n",
        "            print()\n",
        "            print(\"📌   📌    📌    📌    📌   📌\")\n",
        "            print(\"훈련 횟수: \", iteration + 1)\n",
        "            print(\"📌   📌    📌    📌    📌    📌\")\n",
        "            print()\n",
        "            memory = []\n",
        "\n",
        "            # 지정된 횟수(num_selfPlay_iterations)만큼 자기대국을 수행하여 기억(memory)을 수집\n",
        "            self.model.eval()\n",
        "            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations'] // self.args['num_parallel_games']):\n",
        "                print()\n",
        "                print(\"🌟   🌟    🌟    🌟    🌟    🌟\")\n",
        "                print(\"자기대국 횟수: \", selfPlay_iteration + 1)\n",
        "                print(\"🌟   🌟    🌟    🌟    🌟    🌟\")\n",
        "                print()\n",
        "                memory += self.selfPlay(self.long_term_scheduled, self.schedule_range, self.scheduled_cars_list, self.judge_num, self.self_judge_num, a_score = 0, b_score = 0)\n",
        "\n",
        "            # 기억을 모두 수집한 후, 모델을 훈련 모드로 전환(train())하고 지정된 에폭(num_epochs) 수만큼 모델을 학습\n",
        "            self.model.train()\n",
        "            for epoch in trange(self.args['num_epochs']):\n",
        "                self.train(memory)\n",
        "\n",
        "            model_path = \"model_{}.pt\".format('current')\n",
        "            optimizer_path = \"optimizer_{}.pt\".format('current')\n",
        "\n",
        "            torch.save(self.model.state_dict(), model_path)\n",
        "            torch.save(self.optimizer.state_dict(), optimizer_path)\n",
        "\n",
        "        return self.model.state_dict(), self.optimizer.state_dict()\n",
        "\n",
        "            # model_path = \"/content/drive/My Drive/🌊Ulsan_parkinglot/alphazero_models/model_{}_{}.pt\".format(iteration, self.game)\n",
        "            # optimizer_path = \"/content/drive/My Drive/🌊Ulsan_parkinglot/alphazero_models/optimizer_{}_{}.pt\".format(iteration, self.game)\n",
        "\n",
        "            # torch.save(self.model.state_dict(), model_path)\n",
        "            # torch.save(self.optimizer.state_dict(), optimizer_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlFCuNrE1tPG"
      },
      "source": [
        "# ⭐ training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xwzvobA1vJV"
      },
      "outputs": [],
      "source": [
        "min_key_sample_enter_time_counts[min_key_sample_enter_time_counts == 0] = 1\n",
        "long_term_scheduled = list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1]\n",
        "\n",
        "schedule_range = []\n",
        "\n",
        "for i, cars in enumerate(long_term_scheduled):\n",
        "    if i < 15:\n",
        "        schedule_range.append(math.ceil(sum(long_term_scheduled[0 : i]) / 15))\n",
        "    elif i < 6 * (18-7):\n",
        "        schedule_range.append(math.ceil(sum(long_term_scheduled[i - 15 + 1: i + 1]) / 15))\n",
        "\n",
        "for i in range( 6*(18-7) - 15 + 1, 6*(18-7)):\n",
        "    schedule_range.append(math.ceil(sum(long_term_scheduled[i: 6*(18-7)]) / 15))\n",
        "\n",
        "# =============================================================\n",
        "\n",
        "# 📌📌 심사 횟수와 judge_num\n",
        "\n",
        "initial_index = 15\n",
        "\n",
        "valid_indices = [i for i, val in enumerate(long_term_scheduled[:initial_index]) if val > 0]\n",
        "\n",
        "selected_indices = []\n",
        "for _ in range(sum(schedule_range[:initial_index])):\n",
        "    idx = np.random.choice(valid_indices)\n",
        "    while long_term_scheduled[idx] <= 0:\n",
        "        valid_indices.remove(idx)\n",
        "        idx = np.random.choice(valid_indices)\n",
        "    long_term_scheduled[idx] -= 1\n",
        "    selected_indices.append(idx)\n",
        "\n",
        "sorted_indices = sorted(selected_indices)\n",
        "counts = Counter(sorted_indices)\n",
        "count_list = [counts[element] for element in counts]\n",
        "\n",
        "long_term_scheduled = list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1]\n",
        "for i, value in enumerate(count_list):\n",
        "    long_term_scheduled [i] -= value\n",
        "scheduled_cars_list = [0] * 3 + count_list + [0] * (len(long_term_scheduled) - len(count_list)) + [0] * 9\n",
        "schedule_range[0:initial_index] = [0] * initial_index\n",
        "\n",
        "# count_list = []\n",
        "# scheduled_cars_list = [0] * 3 + count_list + [0] * (len(long_term_scheduled) - len(count_list)) + [0] * 9\n",
        "\n",
        "initial_long_term_scheduled = copy.deepcopy(list(2 * np.array(long_term_scheduled)))\n",
        "initial_schedule_range = copy.deepcopy(list(2 * np.array(schedule_range)))\n",
        "initial_scheduled_cars_list = copy.deepcopy(list(2 * np.array(scheduled_cars_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSoghR0tJX-k"
      },
      "outputs": [],
      "source": [
        "# 기존 중장기 스케줄링된 결과\n",
        "print(list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1])\n",
        "print(sum((list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1])))\n",
        "print()\n",
        "print(count_list)\n",
        "print()\n",
        "# 초기 화물차들을 조금 둔 채로 시작\n",
        "print(initial_scheduled_cars_list)\n",
        "print(sum(initial_scheduled_cars_list))\n",
        "print(len(initial_scheduled_cars_list))\n",
        "print()\n",
        "# 초기 화물차들을 조금 둔 후 중장기 스케줄링된 결과에서 남은 화물차들\n",
        "#  == 앞으로 실시간 스케줄링 해야 할 화물차들\n",
        "print(initial_long_term_scheduled)\n",
        "print(sum(initial_long_term_scheduled))\n",
        "print(len(initial_long_term_scheduled))\n",
        "print()\n",
        "# 조정 대상 화물차들 indicator\n",
        "print(initial_schedule_range)\n",
        "print(sum(initial_schedule_range))\n",
        "print(len(initial_schedule_range))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsWLvqoNhD8O"
      },
      "source": [
        "### training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDfr1883dWqE"
      },
      "outputs": [],
      "source": [
        "game = MinDelay(eta_distribution_prob, eta_prob)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ResNet(game, 9, 128, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpKe66F1x6BO",
        "outputId": "cfaca7c3-c504-4910-d4fe-c1206415cf32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"model_current.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qurYq29LAY57"
      },
      "outputs": [],
      "source": [
        "judge_num = (sum(long_term_scheduled) - sum(schedule_range[:initial_index])) // 2 + 1\n",
        "self_judge_num = (sum(long_term_scheduled) - sum(schedule_range[:initial_index])) // 2 + 1\n",
        "\n",
        "game = MinDelay(eta_distribution_prob, eta_prob)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "\n",
        "args = {\n",
        "    'C': 2,\n",
        "    'num_iterations': 10,              # 몇 번 모델을 훈련할꺼냐\n",
        "    'num_selfPlay_iterations': 1,    # 자기대국 몇 번 할꺼냐 ... 훈련 샘플의 수\n",
        "    'num_searches': 50,               # 얼만큼(몇 노드만큼) 더 내다볼거냐 .... (2~3수 앞까지 내다보자!)\n",
        "    'num_epochs': 50,                  # 몇 에포크 돌릴꺼냐\n",
        "    'num_parallel_games': 1,          # 한 번에 몇 개씩 병렬로 게임 시행\n",
        "    'batch_size': 10,\n",
        "    'temperature': 1.25,\n",
        "    'dirichlet_epsilon': 0.25,\n",
        "    'dirichlet_alpha': 0.3\n",
        "}\n",
        "\n",
        "# 게임이 얼마나 깊게 진행되느냐도 훈련 샘플의 수와 관련 있음\n",
        "\n",
        "# args = {\n",
        "#     'C': 2,\n",
        "#     'num_iterations': 8,            # 몇 번 모델을 훈련할꺼냐\n",
        "#     'num_selfPlay_iterations': 500, # 자기대국 몇 번 할꺼냐 = 훈련 샘플의 수\n",
        "#     'num_searches': 600,             # 얼만큼(몇 노드만큼) 더 내다볼거냐\n",
        "#     'num_epochs': 4,                # 몇 에포크 돌릴꺼냐\n",
        "#     'num_parallel_games': 100,      # 한 번에 몇 개씩 병렬로 게임 시행\n",
        "#     'batch_size': 128,\n",
        "#     'temperature': 1.25,\n",
        "#     'dirichlet_epsilon': 0.25,\n",
        "#     'dirichlet_alpha': 0.3\n",
        "# }\n",
        "\n",
        "alphaZero = AlphaZeroParallel(model, optimizer, game, args, initial_long_term_scheduled, initial_schedule_range, initial_scheduled_cars_list, judge_num, self_judge_num)\n",
        "model_state_dict, optimizer_state_dict = alphaZero.learn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBItyi7c6Et6"
      },
      "outputs": [],
      "source": [
        "# model_path = \"model_{}.pt\".format('0821')\n",
        "# optimizer_path = \"optimizer_{}.pt\".format('0821')\n",
        "\n",
        "# torch.save(model.state_dict(), model_path)\n",
        "# torch.save(optimizer.state_dict(), optimizer_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRzRmqToka1R"
      },
      "source": [
        "# 4️⃣ 알파고 제로 성능 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jJq3IM1nIU2"
      },
      "source": [
        "## 성능 평가 기본 세팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woGRvmGilErR"
      },
      "outputs": [],
      "source": [
        "min_key_sample_enter_time_counts[min_key_sample_enter_time_counts == 0] = 1\n",
        "long_term_scheduled = list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1]\n",
        "\n",
        "schedule_range = []\n",
        "\n",
        "for i, cars in enumerate(long_term_scheduled):\n",
        "    if i < 15:\n",
        "        schedule_range.append(math.ceil(sum(long_term_scheduled[0 : i]) / 15))\n",
        "    elif i < 6 * (18-7):\n",
        "        schedule_range.append(math.ceil(sum(long_term_scheduled[i - 15 + 1: i + 1]) / 15))\n",
        "\n",
        "for i in range( 6*(18-7) - 15 + 1, 6*(18-7)):\n",
        "    schedule_range.append(math.ceil(sum(long_term_scheduled[i: 6*(18-7)]) / 15))\n",
        "\n",
        "# =============================================================\n",
        "\n",
        "# 📌📌 심사 횟수와 judge_num\n",
        "\n",
        "initial_index = 15\n",
        "\n",
        "while True :\n",
        "    valid_indices = [i for i, val in enumerate(long_term_scheduled[:initial_index]) if val > 0]\n",
        "\n",
        "    selected_indices = []\n",
        "    for _ in range(sum(schedule_range[:initial_index])):\n",
        "        idx = np.random.choice(valid_indices)\n",
        "        while long_term_scheduled[idx] <= 0:\n",
        "            valid_indices.remove(idx)\n",
        "            idx = np.random.choice(valid_indices)\n",
        "        long_term_scheduled[idx] -= 1\n",
        "        selected_indices.append(idx)\n",
        "\n",
        "    sorted_indices = sorted(selected_indices)\n",
        "    counts = Counter(sorted_indices)\n",
        "    count_list = [counts[element] for element in counts]\n",
        "\n",
        "    long_term_scheduled = list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1]\n",
        "    for i, value in enumerate(count_list):\n",
        "        long_term_scheduled [i] -= value\n",
        "    scheduled_cars_list = [0] * 3 + count_list + [0] * (len(long_term_scheduled) - len(count_list)) + [0] * 9\n",
        "    schedule_range[0:initial_index] = [0] * initial_index\n",
        "\n",
        "    # count_list = []\n",
        "    # scheduled_cars_list = [0] * 3 + count_list + [0] * (len(long_term_scheduled) - len(count_list)) + [0] * 9\n",
        "\n",
        "    initial_long_term_scheduled = copy.deepcopy(list(2 * np.array(long_term_scheduled)))\n",
        "    initial_schedule_range = copy.deepcopy(list(2 * np.array(schedule_range)))\n",
        "    initial_scheduled_cars_list = copy.deepcopy(list(2 * np.array(scheduled_cars_list)))\n",
        "\n",
        "    if sum(initial_scheduled_cars_list) % 2 == 0:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsBVI0PNtHOn"
      },
      "outputs": [],
      "source": [
        "# 기존 중장기 스케줄링된 결과\n",
        "print(list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1])\n",
        "print(sum((list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1])))\n",
        "print()\n",
        "print(count_list)\n",
        "print()\n",
        "# 초기 화물차들을 조금 둔 채로 시작\n",
        "print(initial_scheduled_cars_list)\n",
        "print(sum(initial_scheduled_cars_list))\n",
        "print(len(initial_scheduled_cars_list))\n",
        "print()\n",
        "# 초기 화물차들을 조금 둔 후 중장기 스케줄링된 결과에서 남은 화물차들\n",
        "#  == 앞으로 실시간 스케줄링 해야 할 화물차들\n",
        "print(initial_long_term_scheduled)\n",
        "print(sum(initial_long_term_scheduled))\n",
        "print(len(initial_long_term_scheduled))\n",
        "print()\n",
        "# 조정 대상 화물차들 indicator\n",
        "print(initial_schedule_range)\n",
        "print(sum(initial_schedule_range))\n",
        "print(len(initial_schedule_range))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClLh-1TNkmLT"
      },
      "source": [
        "## (비교군1) VS 실시간 스케줄링 미적용\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TwaqU6yC1db"
      },
      "source": [
        "### 인공지능으로 스케줄링 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTkr0dalBn0u"
      },
      "outputs": [],
      "source": [
        "long_term_scheduled = copy.deepcopy(initial_long_term_scheduled)\n",
        "schedule_range = copy.deepcopy(initial_schedule_range)\n",
        "scheduled_cars_list = copy.deepcopy(initial_scheduled_cars_list)\n",
        "judge_num = (sum(long_term_scheduled) - sum(schedule_range[:initial_index])) // 2 + 1\n",
        "self_judge_num = (sum(long_term_scheduled) - sum(schedule_range[:initial_index])) // 2 + 1\n",
        "\n",
        "game = MinDelay(eta_distribution_prob, eta_prob)\n",
        "player = 1\n",
        "\n",
        "args = {\n",
        "    'C': 2,\n",
        "    'num_iterations': 10,              # 몇 번 모델을 훈련할꺼냐\n",
        "    'num_selfPlay_iterations': 1,    # 자기대국 몇 번 할꺼냐 ... 훈련 샘플의 수\n",
        "    'num_searches': 40,               # 얼만큼(몇 노드만큼) 더 내다볼거냐 .... (2~3수 앞까지 내다보자!)\n",
        "    'num_epochs': 50,                  # 몇 에포크 돌릴꺼냐\n",
        "    'num_parallel_games': 1,          # 한 번에 몇 개씩 병렬로 게임 시행\n",
        "    'batch_size': 10,\n",
        "    'temperature': 1.25,\n",
        "    'dirichlet_epsilon': 0.25,\n",
        "    'dirichlet_alpha': 0.3\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ResNet(game, 9, 128, device)\n",
        "model.load_state_dict(torch.load(\"model_current.pt\"))\n",
        "model.eval()\n",
        "\n",
        "mcts = MCTS(game, args, model)\n",
        "\n",
        "state = game.get_initial_state()\n",
        "\n",
        "actioned_index = None\n",
        "a_score = 0\n",
        "b_score = 0\n",
        "\n",
        "for i, counts in enumerate(scheduled_cars_list):\n",
        "    for count in range(int(counts / 2)):\n",
        "        cars_action = np.random.choice(range(-3, 6 + 1), size=1, p=game.eta_prob)\n",
        "        action = random.randint(0, 3)\n",
        "\n",
        "        row = np.where(state[:50, i  + action + cars_action] == 0)[0][0]\n",
        "        state[row, i  + action + cars_action] = -1\n",
        "\n",
        "        row= np.where(state[50:, i  + action + cars_action] == 0)[0][0] + 50\n",
        "        state[row, i + action + cars_action] = 1\n",
        "\n",
        "    _, terminated, _, _, _, _, _, _, _, _, _ = game.check_win(state, a_score, b_score, scheduled_cars_list, judge_num)\n",
        "\n",
        "while terminated == True:\n",
        "      state = game.get_initial_state()\n",
        "      for i, counts in enumerate(scheduled_cars_list):\n",
        "          for count in range(int(counts / 2)):\n",
        "              cars_action = np.random.choice(range(-3, 6 + 1), size=1, p=game.eta_prob)\n",
        "              action = random.randint(0, 3)\n",
        "\n",
        "              row = np.where(state[:50, i  + action + cars_action] == 0)[0][0]\n",
        "              state[row, i  + action + cars_action] = -1\n",
        "\n",
        "              row= np.where(state[50:, i  + action + cars_action] == 0)[0][0] + 50\n",
        "              state[row, i + action + cars_action] = 1\n",
        "\n",
        "      _, terminated, _, _, _, _, _, _, _, _, _ = game.check_win(state, a_score, b_score, scheduled_cars_list, judge_num)\n",
        "\n",
        "while True :\n",
        "    if player == 1:\n",
        "        neutral_state = game.change_perspective(state, player)\n",
        "        mcts_probs = mcts.search(neutral_state, long_term_scheduled, schedule_range, scheduled_cars_list, judge_num, actioned_index)\n",
        "        print(\"mcts_probs : \", mcts_probs)\n",
        "        action = np.argmax(mcts_probs)\n",
        "    else:\n",
        "        action = action\n",
        "\n",
        "    state, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index \\\n",
        "    = game.get_next_state(state, action, player, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index, action, test = True)\n",
        "\n",
        "    value, is_terminal, a_score, b_score, scheduled_cars_list, self_judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars \\\n",
        "    = game.test_get_value_and_terminated(state, action, a_score, b_score, scheduled_cars_list, self_judge_num)\n",
        "\n",
        "    if (sum(scheduled_cars_list)) >= (15 * 2) :\n",
        "        a_sub_array = state[:50]\n",
        "        b_sub_array = state[50:]\n",
        "\n",
        "        a_mask = (a_sub_array != 1) & (a_sub_array != -1)\n",
        "        b_mask = (b_sub_array != 1) & (b_sub_array != -1)\n",
        "\n",
        "        a_count = 50 - a_mask.sum(axis=0)\n",
        "        b_count = 50 - b_mask.sum(axis=0)\n",
        "\n",
        "        print(\"a_count\")\n",
        "        print(a_count)\n",
        "        print(\"b_count\")\n",
        "        print(b_count)\n",
        "\n",
        "\n",
        "    if is_terminal:\n",
        "        # print(state)\n",
        "        # if value == 1:\n",
        "        #     print(\"⭐  ⭐  ⭐  ⭐  ⭐\")\n",
        "        #     print(\"인공지능 패배\")\n",
        "        # elif value == -1:\n",
        "        #     print(\"⭐  ⭐  ⭐  ⭐  ⭐\")\n",
        "        #     print(\"인공지능 승리\")\n",
        "        # else:\n",
        "        #     print(\"⭐  ⭐  ⭐  ⭐  ⭐\")\n",
        "        #     print(\"무승부\")\n",
        "        break\n",
        "\n",
        "    # print(\"a_score\", a_score, \"   b_score\", b_score)\n",
        "    print(\" 🎈 모든 게임에 대해 a, b 모두 합해서\", sum(scheduled_cars_list) , \"만큼 자동차 두었음\")\n",
        "    print()\n",
        "\n",
        "    player = game.get_opponent(player)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVkg4ukLC_7I"
      },
      "source": [
        "### 스케줄링 진행하지 않음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZkzYTza08H6"
      },
      "outputs": [],
      "source": [
        "long_term_scheduled = copy.deepcopy(initial_long_term_scheduled)\n",
        "schedule_range = copy.deepcopy(initial_schedule_range)\n",
        "scheduled_cars_list = copy.deepcopy(initial_scheduled_cars_list)\n",
        "judge_num = (sum(long_term_scheduled) - sum(schedule_range[:initial_index])) // 2 + 1\n",
        "self_judge_num = (sum(long_term_scheduled) - sum(schedule_range[:initial_index])) // 2 + 1\n",
        "\n",
        "game = MinDelay(eta_distribution_prob, eta_prob)\n",
        "player = 1\n",
        "\n",
        "args = {\n",
        "    'C': 2,\n",
        "    'num_iterations': 10,              # 몇 번 모델을 훈련할꺼냐\n",
        "    'num_selfPlay_iterations': 1,    # 자기대국 몇 번 할꺼냐 ... 훈련 샘플의 수\n",
        "    'num_searches': 50,               # 얼만큼(몇 노드만큼) 더 내다볼거냐 .... (2~3수 앞까지 내다보자!)\n",
        "    'num_epochs': 50,                  # 몇 에포크 돌릴꺼냐\n",
        "    'num_parallel_games': 1,          # 한 번에 몇 개씩 병렬로 게임 시행\n",
        "    'batch_size': 10,\n",
        "    'temperature': 1.25,\n",
        "    'dirichlet_epsilon': 0.25,\n",
        "    'dirichlet_alpha': 0.3\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ResNet(game, 9, 128, device)\n",
        "model.load_state_dict(torch.load(\"model_current.pt\"))\n",
        "model.eval()\n",
        "\n",
        "mcts = MCTS(game, args, model)\n",
        "\n",
        "state = game.get_initial_state()\n",
        "\n",
        "actioned_index = None\n",
        "a_score = 0\n",
        "b_score = 0\n",
        "\n",
        "for i, counts in enumerate(scheduled_cars_list):\n",
        "    for count in range(int(counts / 2)):\n",
        "        cars_action = np.random.choice(range(-3, 6 + 1), size=1, p=game.eta_prob)\n",
        "        action = random.randint(0, 3)\n",
        "\n",
        "        row = np.where(state[:50, i  + action + cars_action] == 0)[0][0]\n",
        "        state[row, i  + action + cars_action] = -1\n",
        "\n",
        "        row= np.where(state[50:, i  + action + cars_action] == 0)[0][0] + 50\n",
        "        state[row, i + action + cars_action] = 1\n",
        "\n",
        "    _, terminated, _, _, _, _, _, _, _, _, _ = game.check_win(state, a_score, b_score, scheduled_cars_list, judge_num)\n",
        "\n",
        "while terminated == True:\n",
        "      state = game.get_initial_state()\n",
        "      for i, counts in enumerate(scheduled_cars_list):\n",
        "          for count in range(int(counts / 2)):\n",
        "              cars_action = np.random.choice(range(-3, 6 + 1), size=1, p=game.eta_prob)\n",
        "              action = random.randint(0, 3)\n",
        "\n",
        "              row = np.where(state[:50, i  + action + cars_action] == 0)[0][0]\n",
        "              state[row, i  + action + cars_action] = -1\n",
        "\n",
        "              row= np.where(state[50:, i  + action + cars_action] == 0)[0][0] + 50\n",
        "              state[row, i + action + cars_action] = 1\n",
        "\n",
        "      _, terminated, _, _, _, _, _, _, _, _, _ = game.check_win(state, a_score, b_score, scheduled_cars_list, judge_num)\n",
        "\n",
        "while True :\n",
        "    if player == 1:\n",
        "        action = 0\n",
        "    else:\n",
        "        action = 0\n",
        "\n",
        "    state, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index \\\n",
        "    = game.get_next_state(state, action, player, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index, action, test = True)\n",
        "\n",
        "    value, is_terminal, a_score, b_score, scheduled_cars_list, self_judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars \\\n",
        "    = game.test_get_value_and_terminated(state, action, a_score, b_score, scheduled_cars_list, self_judge_num)\n",
        "\n",
        "    if (sum(scheduled_cars_list)) >= (15 * 2) :\n",
        "        a_sub_array = state[:50]\n",
        "        b_sub_array = state[50:]\n",
        "\n",
        "        a_mask = (a_sub_array != 1) & (a_sub_array != -1)\n",
        "        b_mask = (b_sub_array != 1) & (b_sub_array != -1)\n",
        "\n",
        "        a_count = 50 - a_mask.sum(axis=0)\n",
        "        b_count = 50 - b_mask.sum(axis=0)\n",
        "\n",
        "        print(\"a_count\")\n",
        "        print(a_count)\n",
        "        print(\"b_count\")\n",
        "        print(b_count)\n",
        "\n",
        "\n",
        "    if is_terminal:\n",
        "        # print(state)\n",
        "        # if value == 1:\n",
        "        #     print(\"⭐  ⭐  ⭐  ⭐  ⭐\")\n",
        "        #     print(\"인공지능 패배\")\n",
        "        # elif value == -1:\n",
        "        #     print(\"⭐  ⭐  ⭐  ⭐  ⭐\")\n",
        "        #     print(\"인공지능 승리\")\n",
        "        # else:\n",
        "        #     print(\"⭐  ⭐  ⭐  ⭐  ⭐\")\n",
        "        #     print(\"무승부\")\n",
        "        break\n",
        "\n",
        "    # print(\"a_score\", a_score, \"   b_score\", b_score)\n",
        "    print(\" 🎈 모든 게임에 대해 a, b 모두 합해서\", sum(scheduled_cars_list) , \"만큼 자동차 두었음\")\n",
        "    print()\n",
        "\n",
        "    player = game.get_opponent(player)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n1Z7RTSk2FS"
      },
      "source": [
        "## (비교군2) VS 베이즈 정리 기반 몬테카를로"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def balls_left_in_queue(enter_times):\n",
        "    # 각 공이 빠져나가는 시간을 계산\n",
        "    exit_times = []\n",
        "    current_exit_time = 0\n",
        "    total = 0\n",
        "    q_distribution = []\n",
        "    for i, enter_time in enumerate(enter_times):\n",
        "        # 큐에 아무런 공이 없다면 바로 빠져나갈 수 있다\n",
        "        if current_exit_time == enter_time:\n",
        "            current_exit_time = enter_time\n",
        "        elif current_exit_time + n < enter_time:\n",
        "            current_exit_time = enter_time\n",
        "        else:\n",
        "            # 그렇지 않으면, 이전 공이 빠져나간 시점 + n\n",
        "            current_exit_time += n\n",
        "        exit_times.append(current_exit_time)\n",
        "\n",
        "        # 각 enter_time에 대해 빠져나가지 않은 공의 개수 계산\n",
        "        front_cars = np.sum(np.array(exit_times[:i+1]) > enter_time)\n",
        "        q_distribution.append(front_cars)\n",
        "        total += front_cars\n",
        "\n",
        "    return total\n",
        "\n",
        "def generate_random_list_test(판_copy):\n",
        "    generated_data = []\n",
        "    # 선택된 시간대에 대한 랜덤한 시간 값을 생성\n",
        "    for i,x in enumerate(판_copy):\n",
        "        if x != 0:\n",
        "            for s in range(x):\n",
        "                generated_data.append(random.uniform(i*10, (i+1)*10))\n",
        "    return generated_data\n",
        "\n",
        "def generate(판, origin_index, change_num, num_samples = 1000):\n",
        "    total = []\n",
        "    samples = np.random.choice(len(eta_distribution_prob ), size=num_samples, p=eta_distribution_prob )\n",
        "    # samples 값은 0 이상 len(eta_probabilities) ... 15 이하\n",
        "    samples = np.array(samples)\n",
        "    samples = list(samples)\n",
        "\n",
        "    for sampled_index in samples:\n",
        "        # for s in range(10):\n",
        "        판_copy = copy.deepcopy(판)\n",
        "        판_copy[origin_index + change_num + sampled_index] += 1\n",
        "        sampled = generate_random_list_test(판_copy)\n",
        "        q = balls_left_in_queue(sampled)\n",
        "        total.append((change_num, q))\n",
        "\n",
        "    return total\n",
        "\n",
        "def filter_lower_20(total_samples):\n",
        "    all_q = []\n",
        "    filtered_num = []\n",
        "    # all_samples 중 필터링\n",
        "    for num,q in total_samples:\n",
        "        all_q.append(q)\n",
        "\n",
        "    all_q.sort()\n",
        "\n",
        "    index_20_percent = int(len(all_q) * 0.20)\n",
        "    lower_20_percent_element = all_q[index_20_percent]\n",
        "\n",
        "    print(\"avg_20\", lower_20_percent_element)\n",
        "\n",
        "    for num,q in total_samples:\n",
        "        if q <= lower_20_percent_element:\n",
        "            filtered_num.append(num)\n",
        "\n",
        "    return filtered_num"
      ],
      "metadata": {
        "id": "6CMRL88E5qw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "판 = [1] + [0] * (3 + (18-7) * 6 + 18 - 1)\n",
        "long_term_scheduled = copy.deepcopy(list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1])\n",
        "\n",
        "for origin_index in range(len(long_term_scheduled)):\n",
        "    for _ in range(long_term_scheduled[origin_index]):\n",
        "        total_samples = []\n",
        "\n",
        "        for change_num in range(4):\n",
        "            total_samples.extend(generate(판, origin_index, change_num))\n",
        "\n",
        "        filtered_num = filter_lower_20(total_samples)\n",
        "\n",
        "        counter = Counter(filtered_num)\n",
        "        most_common_element, most_common_count = counter.most_common(1)[0]\n",
        "        for element, count in counter.items():\n",
        "            print(f\"Element: {element}, Count: {count}\")\n",
        "\n",
        "        판[origin_index + most_common_element] += 1\n",
        "\n",
        "        print(str(origin_index + 1) +\"번째 시간대 \" + str(_+1) + \"번째 화물차\")\n",
        "        print(\"선택지\", most_common_element)\n",
        "        print(판)\n",
        "        print()\n",
        "    print(\"=====================\")\n",
        "\n",
        "print()\n",
        "print(\"최종\", 판)"
      ],
      "metadata": {
        "id": "H8w0peDj5r0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 지금까지 재조정한 화물차들\n",
        "initial_long_term_scheduled = [0,0,0] + copy.deepcopy(list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1]) + [0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "# 지금까지 재조정한 화물차들의 (재조정 -> 스스로 이동 후) 확률 분포\n",
        "distributions = []\n",
        "for index, count in enumerate(initial_long_term_scheduled):\n",
        "    for _ in range(count):\n",
        "        distributions.append([0] * (index - 3) + list(eta_distribution_prob ) + [0] * (len(initial_long_term_scheduled) - (index + 9)))\n",
        "distributions = copy.deepcopy(initial_long_term_scheduled)\n",
        "probabilities = np.array(distributions) / sum(distributions)\n",
        "\n",
        "# 하위 20, 25, 50 (몬테카를로)\n",
        "sum_scheduled_cars = sum(copy.deepcopy(initial_long_term_scheduled))\n",
        "\n",
        "total_front_cars_distribution = monte_carlo_distribution(1000, sum_scheduled_cars , probabilities)\n",
        "labels = sorted(total_front_cars_distribution.keys())\n",
        "values = [total_front_cars_distribution[key] for key in labels]\n",
        "cumulative_values = np.cumsum(values)\n",
        "\n",
        "bottom_min = labels[np.where(cumulative_values >= cumulative_values[-1] / (1/0.001))[0][0]]\n",
        "bottom20 = labels[np.where(cumulative_values >= cumulative_values[-1] / (1/0.2))[0][0]]\n",
        "bottom35 = labels[np.where(cumulative_values >= cumulative_values[-1] / (1/0.35))[0][0]]\n",
        "bottom50 = labels[np.where(cumulative_values >= cumulative_values[-1] / (1/0.5))[0][0]]\n",
        "\n",
        "print(\"아마 최소: \", bottom_min)\n",
        "print(\"bottom20: \", bottom20)\n",
        "print(\"bottom35: \", bottom35)\n",
        "print(\"bottom50: \", bottom50)\n",
        "\n",
        "total_front_cars = [1, 1, 5, 15, 12, 11, 12, 12, 8, 7, 8, 15, 7, 8, 12, 7, 14, 12, 9, 17, 8, 7, 12, 7, 10, 10, 10, 10, 12, 7, 14, 9, 6, 6, 10, 5, 8, 6, 14, 11, 14, 11, 11, 10, 9, 8, 7, 7, 9, 5, 9, 7, 9, 11, 7, 7, 3, 5, 4, 4, 8, 6, 2, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "# 📌 total_front_cars에다가 출력값 복사해서 붙여넣기\n",
        "\n",
        "total_list = []\n",
        "\n",
        "for i in range(200):\n",
        "    chosen_intervals = []\n",
        "    for idx, arr in enumerate(total_front_cars):\n",
        "        for _ in range(int(arr)):\n",
        "            chosen_intervals.append(idx)\n",
        "    enter_times = [random.uniform(i*10, (i+1)*10) for i in chosen_intervals]\n",
        "    total_list.append(balls_left_in_queue(enter_times))\n",
        "counter = Counter(total_list)\n",
        "top_3_common = counter.most_common(3)\n",
        "top_3_values = [item[0] for item in top_3_common]\n",
        "avg_total_front_cars = sum(top_3_values) / len(top_3_values)\n",
        "\n",
        "print(\"avg_total_front_cars: \", avg_total_front_cars)"
      ],
      "metadata": {
        "id": "PRBXLHJ65uk3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Hu9n3SAO4S87",
        "KtjJelMJ8eq-",
        "39cQHa9I-OH-",
        "Tu6ZPD_RIPS_",
        "I4i403CP8l37",
        "KWxQWR_RNPI1",
        "_d1jRJuh332U",
        "4jJq3IM1nIU2"
      ],
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}