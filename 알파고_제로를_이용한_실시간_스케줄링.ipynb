{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu9n3SAO4S87"
      },
      "source": [
        "# 0ï¸âƒ£ ê¸°ë³¸ ì„¸íŒ…"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfgElWgE8FJP",
        "outputId": "6e787d8a-8b51-4b34-afcd-c1b5d7ff28fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.23.5\n",
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n",
        "\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "from tqdm.notebook import trange\n",
        "\n",
        "import random\n",
        "import math\n",
        "from math import floor\n",
        "import queue\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "from collections import Counter\n",
        "import torch.multiprocessing as mp\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKvnq4202dQu",
        "outputId": "b01c8601-cd0c-4278-9f58-2b48ecc91695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0ixhQVY2_Wj",
        "outputId": "71fc4f13-368f-4296-a2f9-f7bdd1cf512f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqL8v9-r3hJJ",
        "outputId": "b2ab6447-5ee9-4202-9c19-e9788ec01d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/ğŸŒŠUlsan_parkinglot/alphazero_models\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/My Drive/ğŸŒŠUlsan_parkinglot/alphazero_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtjJelMJ8eq-"
      },
      "source": [
        "# 1ï¸âƒ£ ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ì„ ì´ìš©í•œ ì¤‘ì¥ê¸° ìŠ¤ì¼€ì¤„ë§"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39cQHa9I-OH-"
      },
      "source": [
        "## ê¸°ë³¸ ìƒìˆ˜ ì„¤ì •"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmR-7QpTH6zc"
      },
      "source": [
        "í‰ê·  ì…í•­ êµí†µëŸ‰ / ê·¸ ë‚ ì˜ ì´ ì²˜ë¦¬ í™”ë¬¼ ê±´ìˆ˜ / í™”ë¬¼ì°¨ í•œ ëŒ€ê°€ ë“¤ì–´ê°€ëŠ”ë° ê±¸ë¦¬ëŠ” ì‹œê°„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWENqyMC8J3M"
      },
      "outputs": [],
      "source": [
        "avg_traffic_per_10min = [3, 3, 3, 3, 3, 3,    # 5ì‹œ\n",
        "                         3, 3, 3, 3, 3, 3,    # 6ì‹œ\n",
        "                         8, 8, 8, 8, 8, 8,    # 7ì‹œ\n",
        "                         7, 7, 7, 7, 7, 7,    # 8ì‹œ\n",
        "                         10, 10, 10, 10, 10, 10, # 9ì‹œ\n",
        "                         9, 9, 9, 9, 9, 9,  # 10ì‹œ\n",
        "                         8, 8, 8, 8, 8, 8,  # 11ì‹œ\n",
        "                         6, 6, 6, 6, 6, 6,  # 12ì‹œ\n",
        "                         7, 7, 7, 7, 7, 7,  # 13ì‹œ\n",
        "                         7, 7, 7, 7, 7, 7,  # 14ì‹œ\n",
        "                         5, 5, 5, 5, 5, 5,  # 15ì‹œ\n",
        "                         3, 3, 3, 3, 3, 3,  # 16ì‹œ\n",
        "                         2, 2, 2, 2, 2, 2,  # 17ì‹œ\n",
        "                         2, 2, 2, 2, 2, 2,  # 18ì‹œ\n",
        "                         2, 2, 2, 2, 2, 2,  # 19ì‹œ\n",
        "                         1, 1, 1, 1, 1, 1,  # 20ì‹œ\n",
        "                         1, 1, 1, 1, 1, 1,  # 21ì‹œ\n",
        "                         1, 1, 1, 1, 1, 1,  # 22ì‹œ\n",
        "                         1, 1, 1, 1, 1, 1,  #23ì‹œ\n",
        "                         ]\n",
        "\n",
        "avg_probabilities = np.array(avg_traffic_per_10min) / sum(avg_traffic_per_10min)\n",
        "\n",
        "scheduled_cars_of_day = 700\n",
        "n = 1.05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu6ZPD_RIPS_"
      },
      "source": [
        "## ì¤‘ì¥ê¸° ìŠ¤ì¼€ì¤„ë§"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXdvi24iK7ZG"
      },
      "source": [
        "### ëª¬í…Œì¹´ë¥¼ë¡œ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2ztUOUfITHv"
      },
      "source": [
        "í•¨ìˆ˜ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Osl30iI-_U7"
      },
      "outputs": [],
      "source": [
        "def generate_random_list(scheduled_cars_of_day, avg_probabilities):\n",
        "    total_traffic = scheduled_cars_of_day\n",
        "    probabilities = avg_probabilities\n",
        "    chosen_intervals = np.random.choice(range(len(probabilities)), size=total_traffic, p=probabilities)\n",
        "    generated_data = [random.uniform(i*10, (i+1)*10) for i in chosen_intervals]\n",
        "\n",
        "    return generated_data\n",
        "\n",
        "def balls_left_in_queue(enter_times):\n",
        "    exit_times = []\n",
        "    current_exit_time = 0\n",
        "    total_front_cars = 0\n",
        "    front_cars_distribution = []\n",
        "    for i, enter_time in enumerate(enter_times):\n",
        "        if current_exit_time == enter_time:\n",
        "            current_exit_time = enter_time\n",
        "        elif current_exit_time + n < enter_time:\n",
        "            current_exit_time = enter_time\n",
        "        else:\n",
        "            current_exit_time += n\n",
        "        exit_times.append(current_exit_time)\n",
        "\n",
        "        front_cars = np.sum(np.array(exit_times[:i+1]) > enter_time)\n",
        "        front_cars_distribution.append(front_cars)\n",
        "        total_front_cars += front_cars\n",
        "\n",
        "    return total_front_cars, front_cars_distribution\n",
        "\n",
        "def monte_carlo_distribution(num_samples, scheduled_cars_of_day, avg_probabilities):\n",
        "    total_front_cars_distribution = {}\n",
        "    enter_times_storage = {}\n",
        "    front_cars_distribution_storage = {}\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        enter_times = generate_random_list(scheduled_cars_of_day, avg_probabilities)\n",
        "        enter_times = sorted(enter_times)\n",
        "        total_front_cars, front_cars_distribution = balls_left_in_queue(enter_times)\n",
        "\n",
        "        if total_front_cars not in total_front_cars_distribution:\n",
        "            total_front_cars_distribution[total_front_cars] = 0\n",
        "            enter_times_storage[total_front_cars] = []\n",
        "            front_cars_distribution_storage[total_front_cars] = []\n",
        "\n",
        "        total_front_cars_distribution[total_front_cars] += 1\n",
        "        enter_times_storage[total_front_cars].append(enter_times)\n",
        "        front_cars_distribution_storage[total_front_cars].append(front_cars_distribution)\n",
        "\n",
        "    return total_front_cars_distribution, enter_times_storage, front_cars_distribution_storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqVfrrh4IWGU"
      },
      "source": [
        "ëª¬í…Œ ì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ 10000 ë²ˆ ëŒë¦¬ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq4spolmBVB7"
      },
      "outputs": [],
      "source": [
        "total_front_cars_distribution, enter_times_storage, front_cars_distribution_storage = monte_carlo_distribution(10000, scheduled_cars_of_day, avg_probabilities)\n",
        "\n",
        "labels = sorted(total_front_cars_distribution.keys())\n",
        "values = [total_front_cars_distribution[key] for key in labels]\n",
        "plt.bar(labels, values)\n",
        "plt.xlabel(\"distibution of (total_front_cars == total delay time)\")\n",
        "plt.ylabel(\"frequency\")\n",
        "plt.title(\"montecarlo result\" +\"of total_front_cars_distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpO1H2j3KeBg"
      },
      "source": [
        "ëª¬í…Œì¹´ë¥¼ë¡œ ëŒë ¸ì„ ë•Œ ìƒìœ„/í•˜ìœ„ ì´ ì§€ì—° ì‹œê°„ ë”°ì ¸ì£¼ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojNtpXuoCIr6"
      },
      "outputs": [],
      "source": [
        "sorted_front_cars_distribution_keys = sorted(total_front_cars_distribution.keys())\n",
        "\n",
        "print(\"í•˜ìœ„ 5ê°œ ì´ ì§€ì—° ì‹œê°„: \\n\")\n",
        "for key in sorted_front_cars_distribution_keys[:5]:\n",
        "    print(f\"ì§€ì—° ì‹œê°„: {key}, ë¹ˆë„: {total_front_cars_distribution[key]}\")\n",
        "    print(f\"í‰ê·  ì§€ì—° ì‹œê°„: {key / scheduled_cars_of_day}, ë¹ˆë„: {total_front_cars_distribution[key]}\")\n",
        "\n",
        "print(\"\\nìƒìœ„ 5ê°œ ì´ ì§€ì—°ì‹œê°„: \\n\")\n",
        "for key in sorted_front_cars_distribution_keys[-5:][::-1]:\n",
        "    print(f\"ì§€ì—° ì‹œê°„: {key}, ë¹ˆë„: {total_front_cars_distribution[key]}\")\n",
        "    print(f\"í‰ê·  ì§€ì—° ì‹œê°„: {key / scheduled_cars_of_day}, ë¹ˆë„: {total_front_cars_distribution[key]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPaM0OyEKkgd"
      },
      "source": [
        "### ì§€ì—° ì‹œê°„ ìµœì†Œì¼ ë•Œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1P4zMuhwC9Ng"
      },
      "outputs": [],
      "source": [
        "min_key = sorted_front_cars_distribution_keys[0]\n",
        "\n",
        "min_key_sample_enter_time = enter_times_storage[min_key][0]\n",
        "min_key_sample_front_cars = front_cars_distribution_storage[min_key][0]\n",
        "\n",
        "min_total_front_cars, min_front_cars_distribution = balls_left_in_queue(min_key_sample_enter_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7ZJ7q_aKnj7"
      },
      "source": [
        "ì§€ì—° ì‹œê°„ ìµœì†Œì¼ ë•Œ ìƒìœ„/í•˜ìœ„ 10ê°œ í™”ë¬¼ì°¨ í•œ ëŒ€ ëŒ€ê¸°ì‹œê°„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaXAiE5fEzlS"
      },
      "outputs": [],
      "source": [
        "min_front_cars_distribution.sort(reverse = True)\n",
        "print(\"ì§€ì—° ì‹œê°„ ìµœì†Œì¼ ë•Œ ìƒìœ„ 10ê°œ í™”ë¬¼ì°¨ í•œ ëŒ€ ëŒ€ê¸°ì‹œê°„\")\n",
        "print(min_front_cars_distribution[:10])\n",
        "print(\"ì§€ì—° ì‹œê°„ ìµœì†Œì¼ ë•Œ í•˜ìœ„ 10ê°œ í™”ë¬¼ì°¨ í•œ ëŒ€ ëŒ€ê¸°ì‹œê°„\")\n",
        "print(min_front_cars_distribution[-10:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLVJ0YoXKtPw"
      },
      "source": [
        "ì§€ì—° ì‹œê°„ ìµœì†Œì¼ ë•Œ ì…í•­ëŸ‰ ë¶„í¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0KJRykDE0iz"
      },
      "outputs": [],
      "source": [
        "bins = np.arange(0, (23-5)*6*10 + 1, 10)\n",
        "min_key_sample_enter_time_counts, _ = np.histogram(min_key_sample_enter_time, bins)\n",
        "\n",
        "time_labels = [f\"{i}-{i+10}\" for i in range(0, (23-5)*6*10, 10)]\n",
        "\n",
        "plt.figure(figsize=(16,5))\n",
        "plt.bar(time_labels, min_key_sample_enter_time_counts, color='orange')\n",
        "plt.title(\"distribution of enter time of min delay time case\")\n",
        "plt.xlabel(\"Time interval (10 minutes)\", fontsize=14)\n",
        "plt.ylabel(\"Number of cars\", fontsize=12)\n",
        "plt.xticks(rotation=90, fontsize=7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7T__lLFCoAJ"
      },
      "outputs": [],
      "source": [
        "bins_60min = np.arange(0, (23-5)*6*10 + 1, 60)\n",
        "\n",
        "min_key_sample_enter_time_counts_60min, _ = np.histogram(min_key_sample_enter_time, bins_60min)\n",
        "\n",
        "time_labels_60min = [f\"{i}-{i+60}\" for i in range(0, (23-5)*6*10, 60)]\n",
        "\n",
        "plt.figure(figsize=(16,5))\n",
        "plt.bar(time_labels_60min, min_key_sample_enter_time_counts_60min, color='orange')\n",
        "plt.title(\"Distribution of enter time of min delay time case (60-minute intervals)\")\n",
        "plt.xlabel(\"Time interval (60 minutes)\", fontsize=14)\n",
        "plt.ylabel(\"Number of cars\", fontsize=12)\n",
        "plt.xticks(rotation=90, fontsize=7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT1feG6oJSdR"
      },
      "source": [
        "ì§€ì—° ì‹œê°„ ìµœì†Œì¼ ë•Œ í™”ë¬¼ì°¨ í•œ ëŒ€ë§ˆë‹¤ ì–¼ë§ˆë‚˜ ì•ì— ì°¨ëŸ‰ë“¤ì´ ë°€ë ¤ìˆëŠ”ì§€ì™€ ê´€ë ¨ëœ ì‹œê³„ì—´ ë¶„í¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay7Sr6VVGV6c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(min_key_sample_front_cars, color='skyblue')\n",
        "plt.title(\"Time Series of min_key_sample_front_cars\")\n",
        "plt.xlabel(\"each cars\", fontsize=14)\n",
        "plt.ylabel(\"cars count\", fontsize=12)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4i403CP8l37"
      },
      "source": [
        "# 2ï¸âƒ£ ì•ŒíŒŒê³  ì œë¡œë¥¼ ì´ìš©í•œ ì‹¤ì‹œê°„ ìŠ¤ì¼€ì¤„ë§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3KEDg4cLPo5",
        "outputId": "303b9df8-0cf0-4124-a2de-3edb80c8e02f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3  7  9  3  6  4  5  5  4  9  5  5 11 14 12 12 12 10  2  5 11  9 11  4\n",
            " 16  7 12 10  9 12 11 13 15 15 11 15  5  8  7  9 13  7  7  8  4 11  4 10\n",
            "  5  6 10  8 10  9 18 10 14 17 11 11  8  8  3  5  5  8  6  5  3  4  6  0\n",
            "  3  1  2  2  0  3  2  2  3  3  1  1  1  5  8  5  4  3  3  3  2  7  0  3\n",
            "  2  2  2  2  1  1  0  3  1  1  2  1]\n"
          ]
        }
      ],
      "source": [
        "print(min_key_sample_enter_time_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWxQWR_RNPI1"
      },
      "source": [
        "## balls_left_in_queue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lhOnwTPNOpT"
      },
      "outputs": [],
      "source": [
        "def balls_left_in_queue(enter_times):\n",
        "    exit_times = []\n",
        "    current_exit_time = 0\n",
        "    total_front_cars = 0\n",
        "\n",
        "    enter_times = sorted(enter_times)\n",
        "\n",
        "    for i, enter_time in enumerate(enter_times):\n",
        "        if current_exit_time == enter_time:\n",
        "            current_exit_time = enter_time\n",
        "        elif current_exit_time + n < enter_time:\n",
        "            current_exit_time = enter_time\n",
        "        else:\n",
        "            current_exit_time += n\n",
        "        exit_times.append(current_exit_time)\n",
        "\n",
        "        front_cars = np.sum(np.array(exit_times[:i+1]) > enter_time)\n",
        "        total_front_cars += front_cars\n",
        "\n",
        "    return total_front_cars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3Yrrem-PB7J"
      },
      "source": [
        "## monte carlo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSqjkd6hPEbx"
      },
      "outputs": [],
      "source": [
        "def generate_random_list(scheduled_cars_sum, probabilities):\n",
        "    chosen_intervals = np.random.choice(range(len(probabilities)), size = scheduled_cars_sum, p = probabilities)\n",
        "    generated_data = [random.uniform(i*10, (i+1)*10) for i in chosen_intervals]\n",
        "\n",
        "    return generated_data\n",
        "\n",
        "def monte_carlo_distribution(num_samples, scheduled_cars_sum, probabilities):\n",
        "    total_front_cars_distribution = {}\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        enter_times = generate_random_list(scheduled_cars_sum, probabilities)\n",
        "        enter_times = sorted(enter_times)\n",
        "        total_front_cars = balls_left_in_queue(enter_times)\n",
        "\n",
        "        if total_front_cars not in total_front_cars_distribution:\n",
        "            total_front_cars_distribution[total_front_cars] = 0\n",
        "\n",
        "        total_front_cars_distribution[total_front_cars] += 1\n",
        "\n",
        "    return total_front_cars_distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j93u-TAp3zTW"
      },
      "source": [
        "## eta_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-m008lL307H"
      },
      "outputs": [],
      "source": [
        "eta_distribution = [2, 5, 7, 5, 5, 4, 3, 2, 1.5, 1]\n",
        "eta_prob = np.array(eta_distribution) / sum(eta_distribution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vD6g8hhNz29"
      },
      "source": [
        "## eta_distribution_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNBoOwbCN3y0"
      },
      "outputs": [],
      "source": [
        "eta_distribution0 = [2, 5, 7, 5, 5, 4, 3, 2, 1.5, 1, 0, 0, 0]\n",
        "eta_distribution1 = [0, 2, 5, 7, 5, 5, 4, 3, 2, 1.5, 1, 0, 0]\n",
        "eta_distribution2 = [0, 0, 2, 5, 7, 5, 5, 4, 3, 2, 1.5, 1, 0]\n",
        "eta_distribution3 = [0, 0, 0, 2, 5, 7, 5, 5, 4, 3, 2, 1.5, 1]\n",
        "\n",
        "distributions = [eta_distribution0, eta_distribution1, eta_distribution2, eta_distribution3]\n",
        "matrix = np.array(distributions)\n",
        "eta_distribution = matrix.sum(axis=0)\n",
        "eta_distribution_prob = np.array(eta_distribution) / sum(eta_distribution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T4rYZqaLWmu"
      },
      "source": [
        "## MinDelay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBXUBDXaLQ2H"
      },
      "outputs": [],
      "source": [
        "class MinDelay:\n",
        "    def __init__(self, eta_distribution_prob, eta_prob):\n",
        "\n",
        "        self.eta_distribution_prob = eta_distribution_prob\n",
        "        self.eta_prob = eta_prob\n",
        "\n",
        "        self.row_count = 50 * 2\n",
        "        self.col_count = 3 + (18-7) * 6 + 9\n",
        "        self.action_size = 4     # 0ë¶„, 10ë¶„, 20ë¶„, 30ë¶„ ì§€ì—°  (0, 1, 2, 3)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"MinDelay\"\n",
        "\n",
        "    def get_initial_state(self):\n",
        "        return np.zeros((self.row_count, self.col_count))\n",
        "\n",
        "    # ğŸ”´\n",
        "    def get_next_state(self, state, action, player, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index, car_action, test = False):\n",
        "\n",
        "        # non_zero_indices = np.where(np.array(schedule_range) > 0)[0]\n",
        "        # first_non_zero_index = non_zero_indices[0]\n",
        "\n",
        "        # exclude_indicies = np.where(np.array(long_term_scheduled) <= 0)[0]\n",
        "\n",
        "        # if all(x <= 0 for x in long_term_scheduled[0 : first_non_zero_index + 1]):\n",
        "        #     schedule_range[first_non_zero_index] = 0\n",
        "        #     first_non_zero_index += 7\n",
        "\n",
        "        # if first_non_zero_index < 15 - 1:\n",
        "        #     index_choices = [i for i in range(0, first_non_zero_index + 1) if i not in exclude_indicies]\n",
        "\n",
        "        #     if len(index_choices) == 0:\n",
        "        #         index_choices = [i for i in range(0, first_non_zero_index + 1)]\n",
        "\n",
        "        #     origin_index = random.choice(index_choices)\n",
        "        # elif first_non_zero_index < ((18-7) * 6 - 1) :\n",
        "        #     if long_term_scheduled[first_non_zero_index - 15 + 1] != 0:\n",
        "        #         origin_index = first_non_zero_index - 15 + 1\n",
        "        #     else:\n",
        "        #         index_choices = [i for i in range(first_non_zero_index - 15 + 1, first_non_zero_index + 1) if i not in exclude_indicies]\n",
        "\n",
        "        #         if len(index_choices) == 0:\n",
        "        #             index_choices = [i for i in range(first_non_zero_index - 15 + 1, first_non_zero_index + 1 + 7)]\n",
        "\n",
        "        #         origin_index = random.choice(index_choices)\n",
        "        # else:\n",
        "        #     if long_term_scheduled[first_non_zero_index - 15 + 1] != 0:\n",
        "        #         origin_index = first_non_zero_index - 15 + 1\n",
        "        #     else:\n",
        "        #         index_choices = [i for i in range(first_non_zero_index - 15 + 1, (18-7) * 6 - 1 + 1) if i not in exclude_indicies]\n",
        "\n",
        "        #         if len(index_choices) == 0:\n",
        "        #             index_choices = [first_non_zero_index + 1]\n",
        "\n",
        "        #         origin_index = random.choice(index_choices)\n",
        "\n",
        "        non_zero_indices = np.where(np.array(long_term_scheduled) > 0)[0]\n",
        "        first_non_zero_index = non_zero_indices[0]\n",
        "        origin_index = first_non_zero_index\n",
        "\n",
        "\n",
        "        if sum(scheduled_cars_list) % 2 == 0:\n",
        "            actioned_index = origin_index + 3 + action\n",
        "        else:\n",
        "            car_action = np.random.choice(range(-3, 6 + 1), size=1, p=self.eta_prob)\n",
        "\n",
        "            a_new_row = np.where(state[:50, actioned_index + car_action] == 0)[0][0]\n",
        "            state[a_new_row, actioned_index + car_action] = -1\n",
        "\n",
        "            if test:\n",
        "                b_row_indices = np.where(state[50:, actioned_index + car_action] == 0)[0][0]\n",
        "                b_row = b_row_indices + 50\n",
        "                state[b_row, actioned_index + car_action] = player\n",
        "            else:\n",
        "                b_row_indices = np.where(state[50:, origin_index + 3 + action + car_action] == 0)[0][0]\n",
        "                b_row = b_row_indices + 50\n",
        "                state[b_row, origin_index + 3 + action + car_action] = player\n",
        "\n",
        "            actioned_index = None\n",
        "\n",
        "\n",
        "        # schedule_range[origin_index] -= 1\n",
        "        long_term_scheduled[origin_index] -= 1\n",
        "        scheduled_cars_list[origin_index + 3] += 1\n",
        "\n",
        "        return state, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index\n",
        "\n",
        "    def get_valid_moves(self, state):\n",
        "        return 1\n",
        "\n",
        "    # ğŸŸ¢\n",
        "    def check_win(self, state, a_score, b_score, scheduled_cars_list, judge_num, is_self = False):\n",
        "        # ì‹¬ì‚¬ ì‹œì‘ ì¡°ê±´\n",
        "        # if (sum(scheduled_cars_list) >= 0) and (sum(scheduled_cars_list) % 4 == 0):\n",
        "\n",
        "            # ì§€ê¸ˆê¹Œì§€ ì¬ì¡°ì •í•œ í™”ë¬¼ì°¨ë“¤ì˜ ì‹œê°„ëŒ€\n",
        "            non_zero_indices = np.where(np.array(scheduled_cars_list) != 0)[0]\n",
        "\n",
        "            # ì§€ê¸ˆê¹Œì§€ ì¬ì¡°ì •í•œ í™”ë¬¼ì°¨ë“¤ì˜ (ì¬ì¡°ì • -> ìŠ¤ìŠ¤ë¡œ ì´ë™ í›„) í™•ë¥  ë¶„í¬\n",
        "            distributions = []\n",
        "            for index in non_zero_indices:\n",
        "                for cars_count in range(int(scheduled_cars_list[index] // 2)):\n",
        "                    distributions.append([0] * (index - 3) + list(self.eta_distribution_prob) + [0] * ((3 + (18-7) * 6 + 9) - (index + 9)))\n",
        "            matrix = np.array(distributions)\n",
        "            eta_distribution = matrix.sum(axis=0)\n",
        "            probabilities = np.array(eta_distribution) / sum(eta_distribution)\n",
        "\n",
        "            # í•˜ìœ„ 20, 25, 50 (ëª¬í…Œì¹´ë¥¼ë¡œ)\n",
        "            if sum(scheduled_cars_list) % 2 == 0:\n",
        "                sum_scheduled_cars = sum(scheduled_cars_list) // 2\n",
        "            else:\n",
        "                sum_scheduled_cars = sum(scheduled_cars_list) // 2 + 1\n",
        "\n",
        "            total_front_cars_distribution = monte_carlo_distribution(200, sum_scheduled_cars , probabilities)\n",
        "            labels = sorted(total_front_cars_distribution.keys())\n",
        "            values = [total_front_cars_distribution[key] for key in labels]\n",
        "            cumulative_values = np.cumsum(values)\n",
        "\n",
        "            bottom20 = labels[np.where(cumulative_values >= cumulative_values[-1] / (1/0.2))[0][0]]\n",
        "            bottom35 = labels[np.where(cumulative_values >= cumulative_values[-1] / (1/0.35))[0][0]]\n",
        "            bottom50 = labels[np.where(cumulative_values >= cumulative_values[-1] / (1/0.5))[0][0]]\n",
        "\n",
        "\n",
        "            # aì˜ ì´ ì§€ì—° ì‹œê°„\n",
        "            a_arr = state[:50, :]\n",
        "            a_indices = np.where((a_arr == 1) | (a_arr == -1))\n",
        "            a_result = [a_indices[0][np.where(a_indices[1] == col)] for col in range(a_arr.shape[1])]\n",
        "            a_total_list = []\n",
        "            for i in range(200):\n",
        "                a_chosen_intervals = [idx for idx, arr in enumerate(a_result) for _ in arr]\n",
        "                a_enter_times = [random.uniform(i*10, (i+1)*10) for i in a_chosen_intervals]\n",
        "                a_total_front_cars = balls_left_in_queue(a_enter_times)\n",
        "                a_total_list.append(a_total_front_cars)\n",
        "            counter = Counter(a_total_list)\n",
        "            top_3_common = counter.most_common(3)\n",
        "            top_3_values = [item[0] for item in top_3_common]\n",
        "            avg_a_total_front_cars = sum(top_3_values) / len(top_3_values)\n",
        "\n",
        "\n",
        "            # bì˜ ì´ ì§€ì—° ì‹œê°„\n",
        "            b_arr = state[50:, :]\n",
        "            b_indices = np.where((b_arr == 1) | (b_arr == -1))\n",
        "            b_result = [b_indices[0][np.where(b_indices[1] == col)] for col in range(b_arr.shape[1])]\n",
        "            b_total_list = []\n",
        "            for i in range(200):\n",
        "                b_chosen_intervals = [idx for idx, arr in enumerate(b_result) for _ in arr]\n",
        "                b_enter_times = [random.uniform(i*10, (i+1)*10) for i in b_chosen_intervals]\n",
        "                b_total_front_cars = balls_left_in_queue(b_enter_times)\n",
        "                b_total_list.append(b_total_front_cars)\n",
        "            counter = Counter(b_total_list)\n",
        "            top_3_common = counter.most_common(3)\n",
        "            top_3_values = [item[0] for item in top_3_common]\n",
        "            avg_b_total_front_cars = sum(top_3_values) / len(top_3_values)\n",
        "\n",
        "\n",
        "            if not is_self:\n",
        "                if ((avg_a_total_front_cars > bottom20) or (avg_b_total_front_cars > bottom20)):\n",
        "                    if (avg_a_total_front_cars > bottom35) and (avg_b_total_front_cars <= bottom20):\n",
        "                        return 1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                    if (avg_a_total_front_cars <= bottom20) and (avg_b_total_front_cars > bottom35):\n",
        "                        return (-1)*1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "                    if (avg_a_total_front_cars > bottom35) and (avg_b_total_front_cars > bottom35):\n",
        "                        return 0, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                    if (avg_a_total_front_cars > bottom35) and (avg_b_total_front_cars < bottom35):\n",
        "                        return 1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                    if (avg_a_total_front_cars < bottom35) and (avg_b_total_front_cars > bottom35):\n",
        "                        return (-1)*1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "                    if (avg_a_total_front_cars < bottom35) and (avg_b_total_front_cars < bottom35):\n",
        "                        return 0, False, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "                # if abs(a_score - b_score) > 5 * judge_num:\n",
        "                #     if avg_b_total_front_cars > avg_a_total_front_cars:\n",
        "                #         return (-1) * 1, True, a_score, b_score, scheduled_cars_list, judge_num\n",
        "                #     else:\n",
        "                #         return 1, True, a_score, b_score, scheduled_cars_list, judge_num\n",
        "\n",
        "                # if judge_num == 0:\n",
        "                #     if avg_b_total_front_cars > avg_a_total_front_cars:\n",
        "                #       return (-1) * 1, True, a_score, b_score, scheduled_cars_list, judge_num\n",
        "                #     else:\n",
        "                #         return 1, True, a_score, b_score, scheduled_cars_list, judge_num\n",
        "            else:\n",
        "                print(\"bottom20: \", bottom20, \" bottom35: \", bottom35, \"  bottom50: \", bottom50)\n",
        "                print(\"avg_a_total_front_cars: \", avg_a_total_front_cars)\n",
        "                print(\"avg_b_total_front_cars: \", avg_b_total_front_cars)\n",
        "\n",
        "                # 180\n",
        "                if ((sum(scheduled_cars_list) >= 1000) and ((avg_a_total_front_cars > bottom50) or (avg_b_total_front_cars > bottom50))):\n",
        "                    if (avg_a_total_front_cars > bottom50) and (avg_b_total_front_cars > bottom50):\n",
        "                        return 0, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                    if (avg_a_total_front_cars > bottom50):\n",
        "                        if (avg_b_total_front_cars <= bottom35):\n",
        "                            return 1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                        if (avg_b_total_front_cars > bottom35):\n",
        "                            return 0, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                    if (avg_b_total_front_cars > bottom50):\n",
        "                        if (avg_a_total_front_cars <= bottom35):\n",
        "                            return (-1)*1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                        if (avg_b_total_front_cars > bottom35):\n",
        "                            return 0, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "                # 350\n",
        "                if ((sum(scheduled_cars_list) >= 1000) and ((avg_a_total_front_cars > bottom20) or (avg_b_total_front_cars > bottom20))):\n",
        "                    if (avg_a_total_front_cars > bottom35) and (avg_b_total_front_cars <= bottom20):\n",
        "                        print(sum(scheduled_cars_list))\n",
        "                        return 1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                    if (avg_a_total_front_cars <= bottom20) and (avg_b_total_front_cars > bottom35):\n",
        "                        print(sum(scheduled_cars_list))\n",
        "                        return (-1)*1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "                    if (avg_a_total_front_cars > bottom35) and (avg_b_total_front_cars > bottom35):\n",
        "                        print(sum(scheduled_cars_list))\n",
        "                        return 0, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                    if (avg_a_total_front_cars > bottom35) and (avg_b_total_front_cars < bottom35):\n",
        "                        print(sum(scheduled_cars_list))\n",
        "                        return 1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                    if (avg_a_total_front_cars < bottom35) and (avg_b_total_front_cars > bottom35):\n",
        "                        print(sum(scheduled_cars_list))\n",
        "                        return (-1)*1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "                    if (avg_a_total_front_cars < bottom35) and (avg_b_total_front_cars < bottom35):\n",
        "                        return 0, False, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "                # if abs(a_score - b_score) > 5 * judge_num:\n",
        "                #     if avg_b_total_front_cars > avg_a_total_front_cars:\n",
        "                #         return (-1) * 1, True, a_score, b_score, scheduled_cars_list, judge_num\n",
        "                #     else:\n",
        "                #         return 1, True, a_score, b_score, scheduled_cars_list, judge_num\n",
        "\n",
        "                # if judge_num == 0:\n",
        "                #     if avg_b_total_front_cars > avg_a_total_front_cars:\n",
        "                #       return (-1) * 1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "                #     else:\n",
        "                #         return 1, True, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "            # ì ìˆ˜ ë¶€ì—¬\n",
        "            if avg_a_total_front_cars <= bottom20:\n",
        "                a_score += 5\n",
        "            elif avg_a_total_front_cars <= bottom35:\n",
        "                a_score += 2\n",
        "            elif avg_a_total_front_cars <= bottom50:\n",
        "                a_score += 0\n",
        "            else:\n",
        "                a_score -= 3\n",
        "\n",
        "            if avg_b_total_front_cars <= bottom20:\n",
        "                b_score += 5\n",
        "            elif avg_b_total_front_cars <= bottom35:\n",
        "                b_score += 2\n",
        "            elif avg_b_total_front_cars <= bottom50:\n",
        "                b_score += 0\n",
        "            else:\n",
        "                b_score -= 3\n",
        "\n",
        "            # ë‚¨ì€ ì‹¬ì‚¬ íšŸìˆ˜ 1 ê°ì†Œ\n",
        "            judge_num -= 1\n",
        "\n",
        "            # ì–´ì°¨í”¼ terminated ì•„ë‹ˆë©´ value ê°’ ë¬´ì‹œë¨\n",
        "            if a_score > b_score:\n",
        "                    return (-1) * 1, False, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "            else:\n",
        "                return 1, False, a_score, b_score, scheduled_cars_list, judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "        # else:\n",
        "        #     # return 0, False, a_score, b_score, scheduled_cars_list, judge_num\n",
        "        #     if a_score > b_score:\n",
        "        #             return (-1) * a_score, False, a_score, b_score, scheduled_cars_list, judge_num\n",
        "        #     else:\n",
        "        #         return b_score, False, a_score, b_score, scheduled_cars_list, judge_num\n",
        "\n",
        "    # ğŸŸ¢\n",
        "    def get_value_and_terminated(self, state, action, a_score, b_score, scheduled_cars_list, judge_num):\n",
        "        value = 0\n",
        "        if ((sum(scheduled_cars_list) >= 0) and sum(scheduled_cars_list) % 2 == 0):\n",
        "            value, terminated, a_score, b_score, scheduled_cars_list, judge_num, _, _, _, _, _  = self.check_win(state, a_score, b_score, scheduled_cars_list, judge_num)\n",
        "            if terminated :\n",
        "                return value, True, a_score, b_score, scheduled_cars_list, judge_num\n",
        "        return value, False, a_score, b_score, scheduled_cars_list, judge_num\n",
        "\n",
        "    def self_get_value_and_terminated(self, state, action, a_score, b_score, scheduled_cars_list, self_judge_num):\n",
        "        value = 0\n",
        "        if (sum(scheduled_cars_list) % 2 == 0):\n",
        "            value, terminated, a_score, b_score, scheduled_cars_list, self_judge_num, _, _, _, _, _ = self.check_win(state, a_score, b_score, scheduled_cars_list, self_judge_num, is_self = True)\n",
        "            if terminated :\n",
        "                return value, True, a_score, b_score, scheduled_cars_list, self_judge_num\n",
        "        return value, False, a_score, b_score, scheduled_cars_list, self_judge_num\n",
        "\n",
        "    def test_get_value_and_terminated(self, state, action, a_score, b_score, scheduled_cars_list, test_judge_num):\n",
        "        value = 0\n",
        "        if True :\n",
        "            value, terminated, a_score, b_score, scheduled_cars_list, test_judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\\\n",
        "             = self.check_win(state, a_score, b_score, scheduled_cars_list, test_judge_num, is_self = True)\n",
        "            if terminated :\n",
        "                return value, True, a_score, b_score, scheduled_cars_list, test_judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "        return value, False, a_score, b_score, scheduled_cars_list, test_judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars\n",
        "\n",
        "    def get_opponent(self, player):\n",
        "        return (-1) *  player\n",
        "\n",
        "    def get_opponent_value(self, value):\n",
        "        return (-1) *  value\n",
        "\n",
        "    def change_perspective(self, state, player):\n",
        "        return state * player\n",
        "\n",
        "    def get_encoded_state(self, state):\n",
        "        encoded_state = np.stack(\n",
        "            (state == -1, state == 0, state == 1)\n",
        "        ).astype(np.float32)\n",
        "\n",
        "        if len(state.shape) == 3:\n",
        "            encoded_state = np.swapaxes(encoded_state, 0, 1)\n",
        "\n",
        "        return encoded_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d1jRJuh332U"
      },
      "source": [
        "## Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7J4T6Q8Z4HPT"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, game, num_resBlocks, num_hidden, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.startBlock = nn.Sequential(\n",
        "            nn.Conv2d(3, num_hidden, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(num_hidden),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.backBone = nn.ModuleList(\n",
        "            [ResBlock(num_hidden) for i in range(num_resBlocks)]\n",
        "        )\n",
        "\n",
        "        self.policyHead = nn.Sequential(\n",
        "            nn.Conv2d(num_hidden, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * game.row_count * game.col_count, game.action_size)\n",
        "        )\n",
        "\n",
        "        self.valueHead = nn.Sequential(\n",
        "            nn.Conv2d(num_hidden, 3, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(3),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3 * game.row_count * game.col_count, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.startBlock(x)\n",
        "        for resBlock in self.backBone:\n",
        "            x = resBlock(x)\n",
        "        policy = self.policyHead(x)\n",
        "        value = self.valueHead(x)\n",
        "        return policy, value\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, num_hidden):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(num_hidden)\n",
        "        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(num_hidden)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        x += residual\n",
        "        x = F.relu(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvCf_DS5uJen"
      },
      "source": [
        "## Node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Q-Isp57tZ4D"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "    def __init__(self, game, args, state, long_term_scheduled, schedule_range, scheduled_cars_list, a_score, b_score, judge_num, actioned_index, parent=None, action_taken=None, prior=0, visit_count=0):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.state = state\n",
        "        self.parent = parent\n",
        "        self.action_taken = action_taken\n",
        "        self.prior = prior\n",
        "\n",
        "        self.children = []\n",
        "\n",
        "        self.visit_count = visit_count\n",
        "        self.value_sum = 0\n",
        "\n",
        "        self.long_term_scheduled = long_term_scheduled\n",
        "        self.schedule_range = schedule_range\n",
        "        self.scheduled_cars_list = scheduled_cars_list\n",
        "        self.a_score = a_score\n",
        "        self.b_score = b_score\n",
        "        self.judge_num = judge_num\n",
        "        self.actioned_index = actioned_index\n",
        "\n",
        "    def is_fully_expanded(self):\n",
        "        return len(self.children) > 0\n",
        "\n",
        "    def select(self):\n",
        "        best_child = None\n",
        "        best_ucb = -np.inf\n",
        "\n",
        "        for child in self.children:\n",
        "            ucb = self.get_ucb(child)\n",
        "            if ucb > best_ucb:\n",
        "                best_child = child\n",
        "                best_ucb = ucb\n",
        "\n",
        "        return best_child\n",
        "\n",
        "    def get_ucb(self, child):\n",
        "        if child.visit_count == 0:\n",
        "            q_value = 0\n",
        "        else:\n",
        "            q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n",
        "        return q_value + self.args['C'] * (math.sqrt(self.visit_count) / (child.visit_count + 1)) * child.prior\n",
        "\n",
        "    # ğŸ”´\n",
        "    def expand(self, policy, origin_long_term_scheduled, origin_schedule_range, origin_scheduled_cars_list, a_score, b_score, judge_num, origin_actioned_index):\n",
        "\n",
        "        car_action = np.random.choice(range(-3, 6 + 1), size=1, p=self.game.eta_prob)\n",
        "\n",
        "        for action, prob in enumerate(policy):\n",
        "            long_term_scheduled = copy.deepcopy(origin_long_term_scheduled)\n",
        "            schedule_range = copy.deepcopy(origin_schedule_range)\n",
        "            scheduled_cars_list = copy.deepcopy(origin_scheduled_cars_list)\n",
        "\n",
        "            if prob > 0:\n",
        "                child_state = self.state.copy()\n",
        "\n",
        "                child_state, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index \\\n",
        "                 = self.game.get_next_state(child_state, action, 1, long_term_scheduled, schedule_range, scheduled_cars_list, origin_actioned_index, car_action)\n",
        "                # ğŸŸ¡\n",
        "                child_state = self.game.change_perspective(child_state, player=-1)\n",
        "\n",
        "                child = Node(self.game, self.args, child_state, long_term_scheduled, schedule_range, scheduled_cars_list, a_score, b_score, judge_num, actioned_index, self, action, prob)\n",
        "                self.children.append(child)\n",
        "\n",
        "        return child\n",
        "\n",
        "    def backpropagate(self, value):\n",
        "        self.value_sum += value\n",
        "        self.visit_count += 1\n",
        "\n",
        "        value = self.game.get_opponent_value(value)\n",
        "        if self.parent is not None:\n",
        "            self.parent.backpropagate(value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE9K19beue1f"
      },
      "source": [
        "## MCTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddp2E3wUucdN"
      },
      "outputs": [],
      "source": [
        "class MCTS:\n",
        "    def __init__(self, game, args, model):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.model = model\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def search(self, state, origin_long_term_scheduled, origin_schedule_range, origin_scheduled_cars_list, origin_judge_num, origin_actioned_index, origin_a_score = 0, origin_b_score = 0):\n",
        "        root = Node(self.game, self.args, state, origin_long_term_scheduled, origin_schedule_range, origin_scheduled_cars_list, origin_a_score, origin_b_score, origin_judge_num, origin_actioned_index, visit_count=1)\n",
        "\n",
        "        policy, _ = self.model(\n",
        "            torch.tensor(self.game.get_encoded_state(state), device=self.model.device).unsqueeze(0)\n",
        "        )\n",
        "        policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
        "        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
        "            * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size)\n",
        "\n",
        "        valid_moves = self.game.get_valid_moves(state)\n",
        "        policy *= valid_moves\n",
        "        policy /= np.sum(policy)\n",
        "\n",
        "        long_term_scheduled = copy.deepcopy(origin_long_term_scheduled)\n",
        "        schedule_range = copy.deepcopy(origin_schedule_range)\n",
        "        scheduled_cars_list = copy.deepcopy(origin_scheduled_cars_list)\n",
        "        a_score = origin_a_score\n",
        "        b_score = origin_b_score\n",
        "        judge_num = origin_judge_num\n",
        "        actioned_index = origin_actioned_index\n",
        "\n",
        "        # ğŸ”´\n",
        "        child = root.expand(policy, long_term_scheduled, schedule_range, scheduled_cars_list, a_score, b_score, judge_num, actioned_index)\n",
        "\n",
        "        for search in range(self.args['num_searches']):\n",
        "            node = root\n",
        "\n",
        "            long_term_scheduled = copy.deepcopy(origin_long_term_scheduled)\n",
        "            schedule_range = copy.deepcopy(origin_schedule_range)\n",
        "            scheduled_cars_list = copy.deepcopy(origin_scheduled_cars_list)\n",
        "            a_score = origin_a_score\n",
        "            b_score = origin_b_score\n",
        "            judge_num = origin_judge_num\n",
        "\n",
        "            while node.is_fully_expanded():\n",
        "                node = node.select()\n",
        "\n",
        "            long_term_scheduled = node.long_term_scheduled\n",
        "            schedule_range = node.schedule_range\n",
        "            scheduled_cars_list = node.scheduled_cars_list\n",
        "            a_score = node.a_score\n",
        "            b_score = node.b_score\n",
        "            judge_num = node.judge_num\n",
        "\n",
        "            # ğŸŸ¢\n",
        "\n",
        "            value, is_terminal, a_score, b_score, scheduled_cars_list, judge_num \\\n",
        "            = self.game.get_value_and_terminated(node.state, node.action_taken, a_score, b_score, scheduled_cars_list, judge_num)\n",
        "            value = self.game.get_opponent_value(value)\n",
        "\n",
        "            # if (is_terminal):\n",
        "                # print(\"â­â­â­â­â­â­â­â­â­â­â­â­â­â­\")\n",
        "\n",
        "            if not is_terminal:\n",
        "                policy, value = self.model(\n",
        "                    torch.tensor(self.game.get_encoded_state(node.state), device=self.model.device).unsqueeze(0)\n",
        "                )\n",
        "                policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
        "                valid_moves = self.game.get_valid_moves(node.state)\n",
        "                policy *= valid_moves\n",
        "                policy /= np.sum(policy)\n",
        "\n",
        "                value = value.item()\n",
        "\n",
        "                # ğŸ”´\n",
        "                child = node.expand(policy, long_term_scheduled, schedule_range, scheduled_cars_list, a_score, b_score, judge_num, node.actioned_index)\n",
        "\n",
        "            node.backpropagate(value)\n",
        "\n",
        "\n",
        "        # â­â­â­\n",
        "        action_probs = np.zeros(self.game.action_size)\n",
        "        for child in root.children:\n",
        "            action_probs[child.action_taken] = child.visit_count\n",
        "        action_probs /= np.sum(action_probs)\n",
        "        return action_probs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCodj8Ukz_Hj"
      },
      "source": [
        "## alphagozero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1F60mE80BGq"
      },
      "outputs": [],
      "source": [
        "class AlphaZero:\n",
        "    def __init__(self, model, optimizer, game, args, long_term_scheduled, schedule_range, scheduled_cars_list, judge_num, self_judge_num):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.long_term_scheduled = copy.deepcopy(long_term_scheduled)\n",
        "        self.schedule_range = copy.deepcopy(schedule_range)\n",
        "        self.scheduled_cars_list = copy.deepcopy(scheduled_cars_list)\n",
        "        self.judge_num = judge_num\n",
        "        self.self_judge_num = self_judge_num\n",
        "        self.mcts = MCTS(game, args, model)\n",
        "\n",
        "    def selfPlay(self, long_term_scheduled, schedule_range, scheduled_cars_list, judge_num, self_judge_num, a_score = 0, b_score = 0):\n",
        "        memory = []\n",
        "        player = 1\n",
        "        state = self.game.get_initial_state()\n",
        "\n",
        "        for i, counts in enumerate(scheduled_cars_list):\n",
        "            for count in range(int(counts / 2)):\n",
        "                cars_action = np.random.choice(range(-3, 6 + 1), size=1, p=self.game.eta_prob)\n",
        "\n",
        "                action = random.randint(0, 3)\n",
        "                row = np.where(state[:50, i  + action + cars_action] == 0)[0][0]\n",
        "                state[row, i  + action + cars_action] = -1\n",
        "\n",
        "                action = random.randint(0, 3)\n",
        "                row= np.where(state[50:, i  + action + cars_action] == 0)[0][0] + 50\n",
        "                state[row, i + action + cars_action] = 1\n",
        "\n",
        "        # ë§ˆì§€ë§‰ìœ¼ë¡œ bê°€ ë‘ \n",
        "        # aê°€ ì´ˆìˆ˜ë¥¼ ë‘¬ì•¼ í•˜ëŠ” íŒìœ¼ë¡œ state ë“¤ì–´ê°\n",
        "\n",
        "        actioned_index = None\n",
        "\n",
        "        while True:\n",
        "            # ğŸŸ¡\n",
        "            neutral_state = self.game.change_perspective(state, player)\n",
        "\n",
        "            # search\n",
        "            action_probs = self.mcts.search(neutral_state, long_term_scheduled, schedule_range, scheduled_cars_list, judge_num, actioned_index)\n",
        "\n",
        "            memory.append((neutral_state, action_probs, player))\n",
        "\n",
        "            temperature_action_probs = action_probs ** (1 / self.args['temperature'])\n",
        "            temperature_action_probs /= sum(temperature_action_probs)   # Divide temperature_action_probs with its sum in case of an error\n",
        "            action = np.random.choice(self.game.action_size, p=temperature_action_probs)\n",
        "\n",
        "            # ğŸ”´\n",
        "            car_action = np.random.choice(range(-3, 6 + 1), size=1, p=self.game.eta_prob)\n",
        "\n",
        "            state, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index \\\n",
        "             = self.game.get_next_state(state, action, player, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index, car_action)\n",
        "\n",
        "            # ğŸŸ¢\n",
        "            value, is_terminal, a_score, b_score, scheduled_cars_list, self_judge_num \\\n",
        "            = self.game.self_get_value_and_terminated(state, action, a_score, b_score, scheduled_cars_list, self_judge_num)\n",
        "\n",
        "            print(\"ğŸ§  moved_cars: \", sum(scheduled_cars_list) - sum(self.scheduled_cars_list))\n",
        "            print(\"ğŸ§  action\", action)\n",
        "            print(\"ğŸ§  a_score: \", a_score, \"   ğŸ§  b_score\", b_score)\n",
        "\n",
        "            if is_terminal:\n",
        "                returnMemory = []\n",
        "                for hist_neutral_state, hist_action_probs, hist_player in memory:\n",
        "                    hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
        "                    returnMemory.append((\n",
        "                        self.game.get_encoded_state(hist_neutral_state),\n",
        "                        hist_action_probs,\n",
        "                        hist_outcome\n",
        "                    ))\n",
        "                # íŒì´ ì´ëŸ° ìƒíƒœì¼ ë•Œ(ê²Œì„ ì¤‘ ì–´ë–¤ ìƒíƒœ), ì´ ìˆ˜ë¥¼ íƒí•˜ë©´, ê²°ê³¼ì ìœ¼ë¡œ ì§„ë‹¤ / ì´ê¸´ë‹¤\n",
        "                return returnMemory\n",
        "\n",
        "            player = self.game.get_opponent(player)\n",
        "            print(\"ğŸ§  is_terminal:\", is_terminal)\n",
        "            print()\n",
        "\n",
        "    def train(self, memory):\n",
        "        random.shuffle(memory)\n",
        "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
        "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])] # Change to memory[batchIdx:batchIdx+self.args['batch_size']] in case of an error\n",
        "            state, policy_targets, value_targets = zip(*sample)\n",
        "\n",
        "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
        "\n",
        "            state = torch.tensor(state, dtype=torch.float32, device=self.model.device)\n",
        "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n",
        "            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n",
        "\n",
        "            out_policy, out_value = self.model(state)\n",
        "\n",
        "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
        "            value_loss = F.mse_loss(out_value, value_targets)\n",
        "            loss = policy_loss + value_loss\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "    def learn(self):\n",
        "        for iteration in range(self.args['num_iterations']):\n",
        "            memory = []\n",
        "\n",
        "            self.model.eval()\n",
        "            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations']):\n",
        "                memory += self.selfPlay(self.long_term_scheduled, self.schedule_range, self.scheduled_cars_list, self.judge_num, self.self_judge_num)\n",
        "\n",
        "            self.model.train()\n",
        "            for epoch in trange(self.args['num_epochs']):\n",
        "                self.train(memory)\n",
        "\n",
        "            return self.model.state_dict(), self.optimizer.state_dict(), memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj2L-fR_Bo8k"
      },
      "source": [
        "## â­ training_demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QmYjKdQBsOX"
      },
      "outputs": [],
      "source": [
        "# min_key_sample_enter_time_counts[min_key_sample_enter_time_counts == 0] = 1\n",
        "# long_term_scheduled = list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1]\n",
        "\n",
        "# schedule_range = []\n",
        "\n",
        "# for i, cars in enumerate(long_term_scheduled):\n",
        "#     if i < 15:\n",
        "#         schedule_range.append(math.ceil(sum(long_term_scheduled[0 : i]) / 15))\n",
        "#     elif i < 6 * (18-7):\n",
        "#         schedule_range.append(math.ceil(sum(long_term_scheduled[i - 15 + 1: i + 1]) / 15))\n",
        "\n",
        "# for i in range( 6*(18-7) - 15 + 1, 6*(18-7)):\n",
        "#     schedule_range.append(math.ceil(sum(long_term_scheduled[i: 6*(18-7)]) / 15))\n",
        "\n",
        "# # =============================================================\n",
        "\n",
        "# # ğŸ“ŒğŸ“Œ 118ì€ sum(scheduled_cars_list)\n",
        "# # ğŸ“ŒğŸ“Œ ì‹¬ì‚¬ íšŸìˆ˜ì™€ judge_num\n",
        "\n",
        "# initial_index = 14\n",
        "\n",
        "# valid_indices = [i for i, val in enumerate(long_term_scheduled[:initial_index]) if val > 0]\n",
        "\n",
        "# selected_indices = []\n",
        "# for _ in range(sum(schedule_range[:initial_index])):\n",
        "#     idx = np.random.choice(valid_indices)\n",
        "#     while long_term_scheduled[idx] <= 0:\n",
        "#         valid_indices.remove(idx)\n",
        "#         idx = np.random.choice(valid_indices)\n",
        "#     long_term_scheduled[idx] -= 1\n",
        "#     selected_indices.append(idx)\n",
        "\n",
        "# sorted_indices = sorted(selected_indices)\n",
        "# counts = Counter(sorted_indices)\n",
        "# count_list = [counts[element] for element in counts]\n",
        "\n",
        "# long_term_scheduled = list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1]\n",
        "# for i, value in enumerate(count_list):\n",
        "#     long_term_scheduled [i] -= value\n",
        "# scheduled_cars_list = [0] * 3 + count_list + [0] * (len(long_term_scheduled) - len(count_list)) + [0] * 9\n",
        "# judge_num = (sum(long_term_scheduled) - sum(schedule_range[:initial_index])) // 1 + 1\n",
        "# self_judge_num = (sum(long_term_scheduled) - sum(schedule_range[:initial_index])) // 4 + 1\n",
        "# schedule_range[0:initial_index] = [0] * initial_index\n",
        "\n",
        "# long_term_scheduled = list(2 * np.array(long_term_scheduled))\n",
        "# schedule_range = list(2 * np.array(schedule_range))\n",
        "# scheduled_cars_list = list(2 * np.array(scheduled_cars_list))\n",
        "\n",
        "# # ===============================================================\n",
        "\n",
        "\n",
        "# game = MinDelay(eta_distribution_prob, eta_prob)\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# model = ResNet(game, 9, 128, device)\n",
        "\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "\n",
        "# args = {\n",
        "#     'C': 2,\n",
        "#     'num_iterations': 1,          # ëª‡ ë²ˆ ëª¨ë¸ì„ í›ˆë ¨í• êº¼ëƒ\n",
        "#     'num_selfPlay_iterations': 2, # ìê¸°ëŒ€êµ­ ëª‡ ë²ˆ í• êº¼ëƒ = í›ˆë ¨ ìƒ˜í”Œì˜ ìˆ˜\n",
        "#     'num_searches': 50,          # ì–¼ë§Œí¼(ëª‡ ë…¸ë“œë§Œí¼) ë” ë‚´ë‹¤ë³¼ê±°ëƒ\n",
        "#     'num_epochs': 1,              # ëª‡ ì—í¬í¬ ëŒë¦´êº¼ëƒ\n",
        "#     'num_parallel_games': 100,\n",
        "#     'batch_size': 128,\n",
        "#     'temperature': 1.25,\n",
        "#     'dirichlet_epsilon': 0.25,\n",
        "#     'dirichlet_alpha': 0.3\n",
        "# }\n",
        "\n",
        "# alphaZero = AlphaZero(model, optimizer, game, args, long_term_scheduled, schedule_range, scheduled_cars_list, judge_num, self_judge_num)\n",
        "# model_state_dict, optimizer_state_dict, memory = alphaZero.learn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDzdzqeSAf74"
      },
      "outputs": [],
      "source": [
        "# print(list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1])\n",
        "# print()\n",
        "# print(count_list)\n",
        "# print()\n",
        "# print(scheduled_cars_list)\n",
        "# print(sum(scheduled_cars_list))\n",
        "# print(len(scheduled_cars_list))\n",
        "# print()\n",
        "# print(long_term_scheduled)\n",
        "# print(sum(long_term_scheduled))\n",
        "# print(len(long_term_scheduled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoBx3Ke10n6L"
      },
      "outputs": [],
      "source": [
        "# long_term_scheduled = [a - b for a, b in zip(long_term_scheduled, count_list)]\n",
        "# print(long_term_scheduled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbq2Eq771btw"
      },
      "source": [
        "## MCTSParellel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwpS_UFd1krK"
      },
      "outputs": [],
      "source": [
        "class MCTSParallel:\n",
        "    def __init__(self, game, args, model):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.model = model\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def search(self, states, spGames, origin_long_term_scheduleds, origin_schedule_ranges, origin_scheduled_cars_lists, origin_judge_nums, origin_actioned_indexes, origin_a_scores = 0, origin_b_scores = 0):\n",
        "        policy, _ = self.model(torch.tensor(self.game.get_encoded_state(states), device=self.model.device))\n",
        "        policy = torch.softmax(policy, axis=1).cpu().numpy()\n",
        "        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
        "            * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size, size=policy.shape[0])\n",
        "\n",
        "        for i, spg in enumerate(spGames):\n",
        "            spg_policy = policy[i]\n",
        "            valid_moves = self.game.get_valid_moves(states[i])\n",
        "            spg_policy *= valid_moves\n",
        "            spg_policy += 0.2\n",
        "            spg_policy /= np.sum(spg_policy)\n",
        "            print(\"mcts policy: \", spg_policy)\n",
        "\n",
        "            state = copy.deepcopy(states[i])\n",
        "            origin_long_term_scheduled = origin_long_term_scheduleds[i]\n",
        "            origin_schedule_range = origin_schedule_ranges[i]\n",
        "            origin_scheduled_cars_list = origin_scheduled_cars_lists[i]\n",
        "            origin_a_score = 0\n",
        "            origin_b_score = 0\n",
        "            origin_judge_num = origin_judge_nums[i]\n",
        "            origin_actioned_index = origin_actioned_indexes[i]\n",
        "\n",
        "            for root_index in range(len(spg.root)):\n",
        "                spg.root[root_index] = Node(self.game, self.args, state, origin_long_term_scheduled, origin_schedule_range, origin_scheduled_cars_list, \\\n",
        "                                origin_a_score, origin_b_score, origin_judge_num, origin_actioned_index, visit_count=1)\n",
        "\n",
        "                long_term_scheduled = copy.deepcopy(origin_long_term_scheduled)\n",
        "                schedule_range = copy.deepcopy(origin_schedule_range)\n",
        "                scheduled_cars_list = copy.deepcopy(origin_scheduled_cars_list)\n",
        "                a_score = origin_a_score\n",
        "                b_score = origin_b_score\n",
        "                judge_num = origin_judge_num\n",
        "                actioned_index = origin_actioned_index\n",
        "\n",
        "                spg.root[root_index].expand(spg_policy, long_term_scheduled, schedule_range, scheduled_cars_list, a_score, b_score, judge_num, actioned_index)\n",
        "\n",
        "\n",
        "        for root_index in range(len(spGames[0].root)):\n",
        "            for search in range(self.args['num_searches']):\n",
        "                for spg in spGames:\n",
        "                    spg.node = None\n",
        "                    node = spg.root[root_index]\n",
        "\n",
        "                    while node.is_fully_expanded():\n",
        "                        node = node.select()\n",
        "\n",
        "                    long_term_scheduled = node.long_term_scheduled\n",
        "                    schedule_range = node.schedule_range\n",
        "                    scheduled_cars_list = node.scheduled_cars_list\n",
        "                    a_score = node.a_score\n",
        "                    b_score = node.b_score\n",
        "                    judge_num = node.judge_num\n",
        "                    actioned_index = node.actioned_index\n",
        "\n",
        "                    value, is_terminal, a_score, b_score, scheduled_cars_list, judge_num \\\n",
        "                    = self.game.get_value_and_terminated(node.state, node.action_taken, a_score, b_score, scheduled_cars_list, judge_num)\n",
        "                    value = self.game.get_opponent_value(value)\n",
        "\n",
        "                    if is_terminal:\n",
        "                        node.backpropagate(value)\n",
        "\n",
        "                    else:\n",
        "                        spg.node = node\n",
        "\n",
        "                expandable_spGames = [mappingIdx for mappingIdx in range(len(spGames)) if spGames[mappingIdx].node is not None]\n",
        "\n",
        "                # ë‚˜ì˜ í„´ì˜ value ë°˜í™˜\n",
        "                # ğŸ’ => ê²Œì„ì´ ëë‚˜ì§€ ì•Šì•˜ìœ¼ë©´ value ì—…ë°ì´íŠ¸ í•˜ì—¬ < í™•ì¥ >, < ì—­ì „íŒŒ >\n",
        "\n",
        "                # ë³‘ë ¬ë¡œ í•œë²ˆì— ê³ ë ¤í•  game ê²½ìš°ì˜ ìˆ˜ì— ëŒ€í•´ states ìƒì„±,\n",
        "                # ë³‘ë ¬ë¡œ statesì˜ policyì™€ valueê°’ ë°˜í™˜ (value ì—…ë°ì´íŠ¸)\n",
        "\n",
        "                if len(expandable_spGames) > 0:\n",
        "                    states = np.stack([spGames[mappingIdx].node.state for mappingIdx in expandable_spGames])\n",
        "\n",
        "                    policy, value = self.model(\n",
        "                        torch.tensor(self.game.get_encoded_state(states), device=self.model.device)\n",
        "                    )\n",
        "                    policy = torch.softmax(policy, axis=1).cpu().numpy()\n",
        "                    value = value.cpu().numpy()\n",
        "\n",
        "                # ê°ê°ì˜ gameì— ëŒ€í•´ í™•ì¥, ì—­ì „íŒŒ ìˆ˜í–‰\n",
        "                for i, mappingIdx in enumerate(expandable_spGames):\n",
        "                    # ëë‚˜ì§€ ì•Šì€ ê²Œì„ì˜ nodeëŠ” ë°˜ë“œì‹œ ì¡´ì¬ (í•´ë‹¹ ê²Œì„ì˜ ì„ íƒëœ best_child)\n",
        "                    node = spGames[mappingIdx].node\n",
        "                    spg_policy, spg_value = policy[i], value[i]\n",
        "\n",
        "                    valid_moves = self.game.get_valid_moves(node.state)\n",
        "                    spg_policy *= valid_moves\n",
        "                    spg_policy /= np.sum(spg_policy)\n",
        "\n",
        "                    node.expand(spg_policy, long_term_scheduled, schedule_range, scheduled_cars_list, a_score, b_score, judge_num, actioned_index)\n",
        "                    node.backpropagate(spg_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xStX5BWX1n8s"
      },
      "source": [
        "## AlphaZeroParallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY2RDZNY1qeN"
      },
      "outputs": [],
      "source": [
        "class SPG:\n",
        "    def __init__(self, game, long_term_scheduled, schedule_range, scheduled_cars_list, judge_num, self_judge_num, actioned_index, a_score = 0, b_score = 0, size = 1):\n",
        "        self.state = game.get_initial_state()\n",
        "        self.memory = []\n",
        "        self.root = [None] * size\n",
        "        self.node = None\n",
        "\n",
        "        self.long_term_scheduled = copy.deepcopy(long_term_scheduled)\n",
        "        self.schedule_range = copy.deepcopy(schedule_range)\n",
        "        self.scheduled_cars_list = copy.deepcopy(scheduled_cars_list)\n",
        "        self.judge_num = judge_num\n",
        "        self.self_judge_num = self_judge_num\n",
        "        self.actioned_index = copy.deepcopy(actioned_index)\n",
        "        self.a_score = a_score\n",
        "        self.b_score = b_score\n",
        "\n",
        "        for i, counts in enumerate(scheduled_cars_list):\n",
        "            for count in range(int(counts / 2)):\n",
        "                cars_action = np.random.choice(range(-3, 6 + 1), size=1, p=game.eta_prob)\n",
        "                action = random.randint(0, 3)\n",
        "\n",
        "                row = np.where(self.state[:50, i  + action + cars_action] == 0)[0][0]\n",
        "                self.state[row, i  + action + cars_action] = -1\n",
        "\n",
        "                row= np.where(self.state[50:, i  + action + cars_action] == 0)[0][0] + 50\n",
        "                self.state[row, i + action + cars_action] = 1\n",
        "\n",
        "        _, terminated, _, _, _, _ = game.check_win(self.state, self.a_score, self.b_score, self.scheduled_cars_list, self.judge_num)\n",
        "\n",
        "        while terminated == True:\n",
        "            self.state = game.get_initial_state()\n",
        "            for i, counts in enumerate(scheduled_cars_list):\n",
        "                for count in range(int(counts / 2)):\n",
        "                    cars_action = np.random.choice(range(-3, 6 + 1), size=1, p=game.eta_prob)\n",
        "                    action = random.randint(0, 3)\n",
        "\n",
        "                    row = np.where(self.state[:50, i  + action + cars_action] == 0)[0][0]\n",
        "                    self.state[row, i  + action + cars_action] = -1\n",
        "\n",
        "                    row= np.where(self.state[50:, i  + action + cars_action] == 0)[0][0] + 50\n",
        "                    self.state[row, i + action + cars_action] = 1\n",
        "\n",
        "            _, terminated, _, _, _, _ = game.check_win(self.state, self.a_score, self.b_score, self.scheduled_cars_list, self.judge_num)\n",
        "\n",
        "\n",
        "class AlphaZeroParallel:\n",
        "    def __init__(self, model, optimizer, game, args, long_term_scheduled, schedule_range, scheduled_cars_list, judge_num, self_judge_num):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "\n",
        "        self.long_term_scheduled = copy.deepcopy(long_term_scheduled)\n",
        "        self.schedule_range = copy.deepcopy(schedule_range)\n",
        "        self.scheduled_cars_list = copy.deepcopy(scheduled_cars_list)\n",
        "        self.judge_num = judge_num\n",
        "        self.self_judge_num = self_judge_num\n",
        "\n",
        "        self.mcts = MCTSParallel(game, args, model)\n",
        "\n",
        "    def selfPlay(self, long_term_scheduled, schedule_range, scheduled_cars_list, judge_num, self_judge_num, a_score = 0, b_score = 0):\n",
        "        return_memory = []\n",
        "        player = 1\n",
        "        spGames = [SPG(self.game, self.long_term_scheduled, self.schedule_range, self.scheduled_cars_list, self.judge_num, \\\n",
        "                       self.self_judge_num, actioned_index = None, a_score = 0, b_score = 0) for spg in range(self.args['num_parallel_games'])]\n",
        "\n",
        "        num_cars = 0\n",
        "        while len(spGames) > 0:\n",
        "            # ë³‘ë ¬ë¡œ mcts ìˆ˜í–‰ (ê³„ì† ë²ˆê°ˆì•„ê°€ë©° ìˆ˜í–‰)\n",
        "            states = np.stack([spg.state for spg in spGames])\n",
        "            long_term_scheduleds = np.stack([spg.long_term_scheduled for spg in spGames])\n",
        "            schedule_ranges = np.stack([spg.schedule_range for spg in spGames])\n",
        "            scheduled_cars_lists = np.stack([spg.scheduled_cars_list for spg in spGames])\n",
        "            judge_nums = [spg.judge_num for spg in spGames]\n",
        "            self_judge_nums = [spg.self_judge_num for spg in spGames]\n",
        "            actioned_indexs = [spg.actioned_index for spg in spGames]\n",
        "\n",
        "            neutral_states = self.game.change_perspective(states, player)\n",
        "\n",
        "            self.mcts.search(neutral_states, spGames, long_term_scheduleds, schedule_ranges, scheduled_cars_lists, judge_nums, actioned_indexs)\n",
        "\n",
        "            # print(\"â­â­â­â­â­search ì™„â­â­â­â­â­\")\n",
        "\n",
        "            # ê°ê°ì˜ ê²Œì„ í•˜ë‚˜ì— ëŒ€í•´ ìˆ˜í–‰\n",
        "            for i in range(len(spGames))[::-1]:\n",
        "                spg = spGames[i]\n",
        "\n",
        "                # í–‰ë™ í™•ë¥  ê³„ì‚°:\n",
        "                action_probs = np.zeros(self.game.action_size)\n",
        "\n",
        "                for root_index in range(len(spg.root)):\n",
        "                    for child in spg.root[root_index].children:\n",
        "                        action_probs[child.action_taken] += child.visit_count\n",
        "\n",
        "                action_probs /= np.sum(action_probs)\n",
        "                print(\"action_probs: \", action_probs)\n",
        "\n",
        "\n",
        "                # (ìƒíƒœ, ê·¸ ìƒíƒœì¼ ë•Œ í™•ë¥  ë¶„í¬, player)\n",
        "                spg.memory.append((spg.root[0].state, action_probs, player))\n",
        "\n",
        "                #  í–‰ë™ í™•ë¥  ë¶„í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë‚˜ì˜ í–‰ë™ì„ ì„ íƒí•©ë‹ˆë‹¤.\n",
        "                temperature_action_probs = action_probs ** (1 / self.args['temperature'])\n",
        "                temperature_action_probs /= sum(temperature_action_probs)\n",
        "                action = np.random.choice(self.game.action_size, p=temperature_action_probs) # Divide temperature_action_probs with its sum in case of an error\n",
        "\n",
        "                # ìƒíƒœ ì—…ë°ì´íŠ¸\n",
        "\n",
        "                car_action = np.random.choice(range(-3, 6 + 1), size=1, p=self.game.eta_prob)\n",
        "\n",
        "                spg.state, spg.long_term_scheduled, spg.schedule_range, spg.scheduled_cars_list, spg.actioned_index \\\n",
        "                = self.game.get_next_state(spg.state, action, player, spg.long_term_scheduled, spg.schedule_range, spg.scheduled_cars_list, spg.actioned_index, car_action)\n",
        "\n",
        "                # ê²Œì„ ì¢…ë£Œ ì—¬ë¶€ í™•ì¸\n",
        "\n",
        "                value, is_terminal, spg.a_score, spg.b_score, spg.scheduled_cars_list, spg.self_judge_num \\\n",
        "                = self.game.self_get_value_and_terminated(spg.state, action, spg.a_score, spg.b_score, spg.scheduled_cars_list, spg.self_judge_num)\n",
        "\n",
        "                a_sub_array = spg.state[:50]\n",
        "                b_sub_array = spg.state[50:]\n",
        "\n",
        "                a_mask = (a_sub_array != 1) & (a_sub_array != -1)\n",
        "                b_mask = (b_sub_array != 1) & (b_sub_array != -1)\n",
        "\n",
        "                a_count = 50 - a_mask.sum(axis=0)\n",
        "                b_count = 50 - b_mask.sum(axis=0)\n",
        "\n",
        "                print(\"a_count\")\n",
        "                print(a_count)\n",
        "                print(\"b_count\")\n",
        "                print(b_count)\n",
        "\n",
        "                if is_terminal:\n",
        "                    for hist_neutral_state, hist_action_probs, hist_player in spg.memory:\n",
        "                        hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
        "                        return_memory.append((\n",
        "                            self.game.get_encoded_state(hist_neutral_state),\n",
        "                            hist_action_probs,\n",
        "                            hist_outcome\n",
        "                        ))\n",
        "                    del spGames[i]\n",
        "\n",
        "                print(i, \"ë²ˆì§¸ ê²Œì„íŒ\")\n",
        "                print(\"a_score\", spg.a_score, \"   b_score\", spg.b_score)\n",
        "\n",
        "            num_cars += 1\n",
        "            print(\"ğŸ§  ëª¨ë“  ê²Œì„ì— ëŒ€í•´ a, b ëª¨ë‘ í•©í•´ì„œ\", sum(spg.scheduled_cars_list) , \"ë§Œí¼ ìë™ì°¨ ë‘ì—ˆìŒ\")\n",
        "            print()\n",
        "            player = self.game.get_opponent(player)\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        return return_memory\n",
        "\n",
        "    def train(self, memory):\n",
        "        # ë°ì´í„° ì„ê¸°\n",
        "        random.shuffle(memory)\n",
        "\n",
        "        # ë°°ì¹˜ í•™ìŠµ\n",
        "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
        "            # í˜„ì¬ ë°°ì¹˜ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œ\n",
        "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])] # Change to memory[batchIdx:batchIdx+self.args['batch_size']] in case of an error\n",
        "            state, policy_targets, value_targets = zip(*sample)\n",
        "\n",
        "            # ë°ì´í„° ë³€í™˜\n",
        "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
        "\n",
        "            state = torch.tensor(state, dtype=torch.float32, device=self.model.device)\n",
        "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n",
        "            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n",
        "\n",
        "            # ëª¨ë¸ ì˜ˆì¸¡\n",
        "            out_policy, out_value = self.model(state)\n",
        "\n",
        "            # ì†ì‹¤ ê³„ì‚°\n",
        "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
        "            value_loss = F.mse_loss(out_value, value_targets)\n",
        "            loss = policy_loss + value_loss\n",
        "\n",
        "            # ì—­ì „íŒŒ ë° ì—…ë°ì´íŠ¸\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "    # ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì§€ì •\n",
        "    def learn(self):\n",
        "        for iteration in range(self.args['num_iterations']):\n",
        "            print()\n",
        "            print(\"ğŸ“Œ   ğŸ“Œ    ğŸ“Œ    ğŸ“Œ    ğŸ“Œ   ğŸ“Œ\")\n",
        "            print(\"í›ˆë ¨ íšŸìˆ˜: \", iteration + 1)\n",
        "            print(\"ğŸ“Œ   ğŸ“Œ    ğŸ“Œ    ğŸ“Œ    ğŸ“Œ    ğŸ“Œ\")\n",
        "            print()\n",
        "            memory = []\n",
        "\n",
        "            # ì§€ì •ëœ íšŸìˆ˜(num_selfPlay_iterations)ë§Œí¼ ìê¸°ëŒ€êµ­ì„ ìˆ˜í–‰í•˜ì—¬ ê¸°ì–µ(memory)ì„ ìˆ˜ì§‘\n",
        "            self.model.eval()\n",
        "            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations'] // self.args['num_parallel_games']):\n",
        "                print()\n",
        "                print(\"ğŸŒŸ   ğŸŒŸ    ğŸŒŸ    ğŸŒŸ    ğŸŒŸ    ğŸŒŸ\")\n",
        "                print(\"ìê¸°ëŒ€êµ­ íšŸìˆ˜: \", selfPlay_iteration + 1)\n",
        "                print(\"ğŸŒŸ   ğŸŒŸ    ğŸŒŸ    ğŸŒŸ    ğŸŒŸ    ğŸŒŸ\")\n",
        "                print()\n",
        "                memory += self.selfPlay(self.long_term_scheduled, self.schedule_range, self.scheduled_cars_list, self.judge_num, self.self_judge_num, a_score = 0, b_score = 0)\n",
        "\n",
        "            # ê¸°ì–µì„ ëª¨ë‘ ìˆ˜ì§‘í•œ í›„, ëª¨ë¸ì„ í›ˆë ¨ ëª¨ë“œë¡œ ì „í™˜(train())í•˜ê³  ì§€ì •ëœ ì—í­(num_epochs) ìˆ˜ë§Œí¼ ëª¨ë¸ì„ í•™ìŠµ\n",
        "            self.model.train()\n",
        "            for epoch in trange(self.args['num_epochs']):\n",
        "                self.train(memory)\n",
        "\n",
        "            model_path = \"model_{}.pt\".format('current')\n",
        "            optimizer_path = \"optimizer_{}.pt\".format('current')\n",
        "\n",
        "            torch.save(self.model.state_dict(), model_path)\n",
        "            torch.save(self.optimizer.state_dict(), optimizer_path)\n",
        "\n",
        "        return self.model.state_dict(), self.optimizer.state_dict()\n",
        "\n",
        "            # model_path = \"/content/drive/My Drive/ğŸŒŠUlsan_parkinglot/alphazero_models/model_{}_{}.pt\".format(iteration, self.game)\n",
        "            # optimizer_path = \"/content/drive/My Drive/ğŸŒŠUlsan_parkinglot/alphazero_models/optimizer_{}_{}.pt\".format(iteration, self.game)\n",
        "\n",
        "            # torch.save(self.model.state_dict(), model_path)\n",
        "            # torch.save(self.optimizer.state_dict(), optimizer_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlFCuNrE1tPG"
      },
      "source": [
        "# â­ training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xwzvobA1vJV"
      },
      "outputs": [],
      "source": [
        "min_key_sample_enter_time_counts[min_key_sample_enter_time_counts == 0] = 1\n",
        "long_term_scheduled = list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1]\n",
        "\n",
        "schedule_range = []\n",
        "\n",
        "for i, cars in enumerate(long_term_scheduled):\n",
        "    if i < 15:\n",
        "        schedule_range.append(math.ceil(sum(long_term_scheduled[0 : i]) / 15))\n",
        "    elif i < 6 * (18-7):\n",
        "        schedule_range.append(math.ceil(sum(long_term_scheduled[i - 15 + 1: i + 1]) / 15))\n",
        "\n",
        "for i in range( 6*(18-7) - 15 + 1, 6*(18-7)):\n",
        "    schedule_range.append(math.ceil(sum(long_term_scheduled[i: 6*(18-7)]) / 15))\n",
        "\n",
        "# =============================================================\n",
        "\n",
        "# ğŸ“ŒğŸ“Œ ì‹¬ì‚¬ íšŸìˆ˜ì™€ judge_num\n",
        "\n",
        "initial_index = 15\n",
        "\n",
        "valid_indices = [i for i, val in enumerate(long_term_scheduled[:initial_index]) if val > 0]\n",
        "\n",
        "selected_indices = []\n",
        "for _ in range(sum(schedule_range[:initial_index])):\n",
        "    idx = np.random.choice(valid_indices)\n",
        "    while long_term_scheduled[idx] <= 0:\n",
        "        valid_indices.remove(idx)\n",
        "        idx = np.random.choice(valid_indices)\n",
        "    long_term_scheduled[idx] -= 1\n",
        "    selected_indices.append(idx)\n",
        "\n",
        "sorted_indices = sorted(selected_indices)\n",
        "counts = Counter(sorted_indices)\n",
        "count_list = [counts[element] for element in counts]\n",
        "\n",
        "long_term_scheduled = list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1]\n",
        "for i, value in enumerate(count_list):\n",
        "    long_term_scheduled [i] -= value\n",
        "scheduled_cars_list = [0] * 3 + count_list + [0] * (len(long_term_scheduled) - len(count_list)) + [0] * 9\n",
        "schedule_range[0:initial_index] = [0] * initial_index\n",
        "\n",
        "# count_list = []\n",
        "# scheduled_cars_list = [0] * 3 + count_list + [0] * (len(long_term_scheduled) - len(count_list)) + [0] * 9\n",
        "\n",
        "initial_long_term_scheduled = copy.deepcopy(list(2 * np.array(long_term_scheduled)))\n",
        "initial_schedule_range = copy.deepcopy(list(2 * np.array(schedule_range)))\n",
        "initial_scheduled_cars_list = copy.deepcopy(list(2 * np.array(scheduled_cars_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSoghR0tJX-k"
      },
      "outputs": [],
      "source": [
        "# ê¸°ì¡´ ì¤‘ì¥ê¸° ìŠ¤ì¼€ì¤„ë§ëœ ê²°ê³¼\n",
        "print(list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1])\n",
        "print(sum((list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1])))\n",
        "print()\n",
        "print(count_list)\n",
        "print()\n",
        "# ì´ˆê¸° í™”ë¬¼ì°¨ë“¤ì„ ì¡°ê¸ˆ ë‘” ì±„ë¡œ ì‹œì‘\n",
        "print(initial_scheduled_cars_list)\n",
        "print(sum(initial_scheduled_cars_list))\n",
        "print(len(initial_scheduled_cars_list))\n",
        "print()\n",
        "# ì´ˆê¸° í™”ë¬¼ì°¨ë“¤ì„ ì¡°ê¸ˆ ë‘” í›„ ì¤‘ì¥ê¸° ìŠ¤ì¼€ì¤„ë§ëœ ê²°ê³¼ì—ì„œ ë‚¨ì€ í™”ë¬¼ì°¨ë“¤\n",
        "#  == ì•ìœ¼ë¡œ ì‹¤ì‹œê°„ ìŠ¤ì¼€ì¤„ë§ í•´ì•¼ í•  í™”ë¬¼ì°¨ë“¤\n",
        "print(initial_long_term_scheduled)\n",
        "print(sum(initial_long_term_scheduled))\n",
        "print(len(initial_long_term_scheduled))\n",
        "print()\n",
        "# ì¡°ì • ëŒ€ìƒ í™”ë¬¼ì°¨ë“¤ indicator\n",
        "print(initial_schedule_range)\n",
        "print(sum(initial_schedule_range))\n",
        "print(len(initial_schedule_range))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsWLvqoNhD8O"
      },
      "source": [
        "### training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDfr1883dWqE"
      },
      "outputs": [],
      "source": [
        "game = MinDelay(eta_distribution_prob, eta_prob)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ResNet(game, 9, 128, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpKe66F1x6BO",
        "outputId": "cfaca7c3-c504-4910-d4fe-c1206415cf32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"model_current.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qurYq29LAY57"
      },
      "outputs": [],
      "source": [
        "judge_num = (sum(long_term_scheduled) - sum(schedule_range[:initial_index])) // 2 + 1\n",
        "self_judge_num = (sum(long_term_scheduled) - sum(schedule_range[:initial_index])) // 2 + 1\n",
        "\n",
        "game = MinDelay(eta_distribution_prob, eta_prob)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "\n",
        "args = {\n",
        "    'C': 2,\n",
        "    'num_iterations': 10,              # ëª‡ ë²ˆ ëª¨ë¸ì„ í›ˆë ¨í• êº¼ëƒ\n",
        "    'num_selfPlay_iterations': 1,    # ìê¸°ëŒ€êµ­ ëª‡ ë²ˆ í• êº¼ëƒ ... í›ˆë ¨ ìƒ˜í”Œì˜ ìˆ˜\n",
        "    'num_searches': 50,               # ì–¼ë§Œí¼(ëª‡ ë…¸ë“œë§Œí¼) ë” ë‚´ë‹¤ë³¼ê±°ëƒ .... (2~3ìˆ˜ ì•ê¹Œì§€ ë‚´ë‹¤ë³´ì!)\n",
        "    'num_epochs': 50,                  # ëª‡ ì—í¬í¬ ëŒë¦´êº¼ëƒ\n",
        "    'num_parallel_games': 1,          # í•œ ë²ˆì— ëª‡ ê°œì”© ë³‘ë ¬ë¡œ ê²Œì„ ì‹œí–‰\n",
        "    'batch_size': 10,\n",
        "    'temperature': 1.25,\n",
        "    'dirichlet_epsilon': 0.25,\n",
        "    'dirichlet_alpha': 0.3\n",
        "}\n",
        "\n",
        "# ê²Œì„ì´ ì–¼ë§ˆë‚˜ ê¹Šê²Œ ì§„í–‰ë˜ëŠëƒë„ í›ˆë ¨ ìƒ˜í”Œì˜ ìˆ˜ì™€ ê´€ë ¨ ìˆìŒ\n",
        "\n",
        "# args = {\n",
        "#     'C': 2,\n",
        "#     'num_iterations': 8,            # ëª‡ ë²ˆ ëª¨ë¸ì„ í›ˆë ¨í• êº¼ëƒ\n",
        "#     'num_selfPlay_iterations': 500, # ìê¸°ëŒ€êµ­ ëª‡ ë²ˆ í• êº¼ëƒ = í›ˆë ¨ ìƒ˜í”Œì˜ ìˆ˜\n",
        "#     'num_searches': 600,             # ì–¼ë§Œí¼(ëª‡ ë…¸ë“œë§Œí¼) ë” ë‚´ë‹¤ë³¼ê±°ëƒ\n",
        "#     'num_epochs': 4,                # ëª‡ ì—í¬í¬ ëŒë¦´êº¼ëƒ\n",
        "#     'num_parallel_games': 100,      # í•œ ë²ˆì— ëª‡ ê°œì”© ë³‘ë ¬ë¡œ ê²Œì„ ì‹œí–‰\n",
        "#     'batch_size': 128,\n",
        "#     'temperature': 1.25,\n",
        "#     'dirichlet_epsilon': 0.25,\n",
        "#     'dirichlet_alpha': 0.3\n",
        "# }\n",
        "\n",
        "alphaZero = AlphaZeroParallel(model, optimizer, game, args, initial_long_term_scheduled, initial_schedule_range, initial_scheduled_cars_list, judge_num, self_judge_num)\n",
        "model_state_dict, optimizer_state_dict = alphaZero.learn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBItyi7c6Et6"
      },
      "outputs": [],
      "source": [
        "# model_path = \"model_{}.pt\".format('0821')\n",
        "# optimizer_path = \"optimizer_{}.pt\".format('0821')\n",
        "\n",
        "# torch.save(model.state_dict(), model_path)\n",
        "# torch.save(optimizer.state_dict(), optimizer_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRzRmqToka1R"
      },
      "source": [
        "# 4ï¸âƒ£ ì•ŒíŒŒê³  ì œë¡œ ì„±ëŠ¥ í‰ê°€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jJq3IM1nIU2"
      },
      "source": [
        "## ì„±ëŠ¥ í‰ê°€ ê¸°ë³¸ ì„¸íŒ…"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woGRvmGilErR"
      },
      "outputs": [],
      "source": [
        "min_key_sample_enter_time_counts[min_key_sample_enter_time_counts == 0] = 1\n",
        "long_term_scheduled = list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1]\n",
        "\n",
        "schedule_range = []\n",
        "\n",
        "for i, cars in enumerate(long_term_scheduled):\n",
        "    if i < 15:\n",
        "        schedule_range.append(math.ceil(sum(long_term_scheduled[0 : i]) / 15))\n",
        "    elif i < 6 * (18-7):\n",
        "        schedule_range.append(math.ceil(sum(long_term_scheduled[i - 15 + 1: i + 1]) / 15))\n",
        "\n",
        "for i in range( 6*(18-7) - 15 + 1, 6*(18-7)):\n",
        "    schedule_range.append(math.ceil(sum(long_term_scheduled[i: 6*(18-7)]) / 15))\n",
        "\n",
        "# =============================================================\n",
        "\n",
        "# ğŸ“ŒğŸ“Œ ì‹¬ì‚¬ íšŸìˆ˜ì™€ judge_num\n",
        "\n",
        "initial_index = 15\n",
        "\n",
        "while True :\n",
        "    valid_indices = [i for i, val in enumerate(long_term_scheduled[:initial_index]) if val > 0]\n",
        "\n",
        "    selected_indices = []\n",
        "    for _ in range(sum(schedule_range[:initial_index])):\n",
        "        idx = np.random.choice(valid_indices)\n",
        "        while long_term_scheduled[idx] <= 0:\n",
        "            valid_indices.remove(idx)\n",
        "            idx = np.random.choice(valid_indices)\n",
        "        long_term_scheduled[idx] -= 1\n",
        "        selected_indices.append(idx)\n",
        "\n",
        "    sorted_indices = sorted(selected_indices)\n",
        "    counts = Counter(sorted_indices)\n",
        "    count_list = [counts[element] for element in counts]\n",
        "\n",
        "    long_term_scheduled = list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1]\n",
        "    for i, value in enumerate(count_list):\n",
        "        long_term_scheduled [i] -= value\n",
        "    scheduled_cars_list = [0] * 3 + count_list + [0] * (len(long_term_scheduled) - len(count_list)) + [0] * 9\n",
        "    schedule_range[0:initial_index] = [0] * initial_index\n",
        "\n",
        "    # count_list = []\n",
        "    # scheduled_cars_list = [0] * 3 + count_list + [0] * (len(long_term_scheduled) - len(count_list)) + [0] * 9\n",
        "\n",
        "    initial_long_term_scheduled = copy.deepcopy(list(2 * np.array(long_term_scheduled)))\n",
        "    initial_schedule_range = copy.deepcopy(list(2 * np.array(schedule_range)))\n",
        "    initial_scheduled_cars_list = copy.deepcopy(list(2 * np.array(scheduled_cars_list)))\n",
        "\n",
        "    if sum(initial_scheduled_cars_list) % 2 == 0:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsBVI0PNtHOn"
      },
      "outputs": [],
      "source": [
        "# ê¸°ì¡´ ì¤‘ì¥ê¸° ìŠ¤ì¼€ì¤„ë§ëœ ê²°ê³¼\n",
        "print(list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1])\n",
        "print(sum((list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1])))\n",
        "print()\n",
        "print(count_list)\n",
        "print()\n",
        "# ì´ˆê¸° í™”ë¬¼ì°¨ë“¤ì„ ì¡°ê¸ˆ ë‘” ì±„ë¡œ ì‹œì‘\n",
        "print(initial_scheduled_cars_list)\n",
        "print(sum(initial_scheduled_cars_list))\n",
        "print(len(initial_scheduled_cars_list))\n",
        "print()\n",
        "# ì´ˆê¸° í™”ë¬¼ì°¨ë“¤ì„ ì¡°ê¸ˆ ë‘” í›„ ì¤‘ì¥ê¸° ìŠ¤ì¼€ì¤„ë§ëœ ê²°ê³¼ì—ì„œ ë‚¨ì€ í™”ë¬¼ì°¨ë“¤\n",
        "#  == ì•ìœ¼ë¡œ ì‹¤ì‹œê°„ ìŠ¤ì¼€ì¤„ë§ í•´ì•¼ í•  í™”ë¬¼ì°¨ë“¤\n",
        "print(initial_long_term_scheduled)\n",
        "print(sum(initial_long_term_scheduled))\n",
        "print(len(initial_long_term_scheduled))\n",
        "print()\n",
        "# ì¡°ì • ëŒ€ìƒ í™”ë¬¼ì°¨ë“¤ indicator\n",
        "print(initial_schedule_range)\n",
        "print(sum(initial_schedule_range))\n",
        "print(len(initial_schedule_range))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClLh-1TNkmLT"
      },
      "source": [
        "## (ë¹„êµêµ°1) VS ì‹¤ì‹œê°„ ìŠ¤ì¼€ì¤„ë§ ë¯¸ì ìš©\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TwaqU6yC1db"
      },
      "source": [
        "### ì¸ê³µì§€ëŠ¥ìœ¼ë¡œ ìŠ¤ì¼€ì¤„ë§ ì§„í–‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTkr0dalBn0u"
      },
      "outputs": [],
      "source": [
        "long_term_scheduled = copy.deepcopy(initial_long_term_scheduled)\n",
        "schedule_range = copy.deepcopy(initial_schedule_range)\n",
        "scheduled_cars_list = copy.deepcopy(initial_scheduled_cars_list)\n",
        "judge_num = (sum(long_term_scheduled) - sum(schedule_range[:initial_index])) // 2 + 1\n",
        "self_judge_num = (sum(long_term_scheduled) - sum(schedule_range[:initial_index])) // 2 + 1\n",
        "\n",
        "game = MinDelay(eta_distribution_prob, eta_prob)\n",
        "player = 1\n",
        "\n",
        "args = {\n",
        "    'C': 2,\n",
        "    'num_iterations': 10,              # ëª‡ ë²ˆ ëª¨ë¸ì„ í›ˆë ¨í• êº¼ëƒ\n",
        "    'num_selfPlay_iterations': 1,    # ìê¸°ëŒ€êµ­ ëª‡ ë²ˆ í• êº¼ëƒ ... í›ˆë ¨ ìƒ˜í”Œì˜ ìˆ˜\n",
        "    'num_searches': 40,               # ì–¼ë§Œí¼(ëª‡ ë…¸ë“œë§Œí¼) ë” ë‚´ë‹¤ë³¼ê±°ëƒ .... (2~3ìˆ˜ ì•ê¹Œì§€ ë‚´ë‹¤ë³´ì!)\n",
        "    'num_epochs': 50,                  # ëª‡ ì—í¬í¬ ëŒë¦´êº¼ëƒ\n",
        "    'num_parallel_games': 1,          # í•œ ë²ˆì— ëª‡ ê°œì”© ë³‘ë ¬ë¡œ ê²Œì„ ì‹œí–‰\n",
        "    'batch_size': 10,\n",
        "    'temperature': 1.25,\n",
        "    'dirichlet_epsilon': 0.25,\n",
        "    'dirichlet_alpha': 0.3\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ResNet(game, 9, 128, device)\n",
        "model.load_state_dict(torch.load(\"model_current.pt\"))\n",
        "model.eval()\n",
        "\n",
        "mcts = MCTS(game, args, model)\n",
        "\n",
        "state = game.get_initial_state()\n",
        "\n",
        "actioned_index = None\n",
        "a_score = 0\n",
        "b_score = 0\n",
        "\n",
        "for i, counts in enumerate(scheduled_cars_list):\n",
        "    for count in range(int(counts / 2)):\n",
        "        cars_action = np.random.choice(range(-3, 6 + 1), size=1, p=game.eta_prob)\n",
        "        action = random.randint(0, 3)\n",
        "\n",
        "        row = np.where(state[:50, i  + action + cars_action] == 0)[0][0]\n",
        "        state[row, i  + action + cars_action] = -1\n",
        "\n",
        "        row= np.where(state[50:, i  + action + cars_action] == 0)[0][0] + 50\n",
        "        state[row, i + action + cars_action] = 1\n",
        "\n",
        "    _, terminated, _, _, _, _, _, _, _, _, _ = game.check_win(state, a_score, b_score, scheduled_cars_list, judge_num)\n",
        "\n",
        "while terminated == True:\n",
        "      state = game.get_initial_state()\n",
        "      for i, counts in enumerate(scheduled_cars_list):\n",
        "          for count in range(int(counts / 2)):\n",
        "              cars_action = np.random.choice(range(-3, 6 + 1), size=1, p=game.eta_prob)\n",
        "              action = random.randint(0, 3)\n",
        "\n",
        "              row = np.where(state[:50, i  + action + cars_action] == 0)[0][0]\n",
        "              state[row, i  + action + cars_action] = -1\n",
        "\n",
        "              row= np.where(state[50:, i  + action + cars_action] == 0)[0][0] + 50\n",
        "              state[row, i + action + cars_action] = 1\n",
        "\n",
        "      _, terminated, _, _, _, _, _, _, _, _, _ = game.check_win(state, a_score, b_score, scheduled_cars_list, judge_num)\n",
        "\n",
        "while True :\n",
        "    if player == 1:\n",
        "        neutral_state = game.change_perspective(state, player)\n",
        "        mcts_probs = mcts.search(neutral_state, long_term_scheduled, schedule_range, scheduled_cars_list, judge_num, actioned_index)\n",
        "        print(\"mcts_probs : \", mcts_probs)\n",
        "        action = np.argmax(mcts_probs)\n",
        "    else:\n",
        "        action = action\n",
        "\n",
        "    state, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index \\\n",
        "    = game.get_next_state(state, action, player, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index, action, test = True)\n",
        "\n",
        "    value, is_terminal, a_score, b_score, scheduled_cars_list, self_judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars \\\n",
        "    = game.test_get_value_and_terminated(state, action, a_score, b_score, scheduled_cars_list, self_judge_num)\n",
        "\n",
        "    if (sum(scheduled_cars_list)) >= (15 * 2) :\n",
        "        a_sub_array = state[:50]\n",
        "        b_sub_array = state[50:]\n",
        "\n",
        "        a_mask = (a_sub_array != 1) & (a_sub_array != -1)\n",
        "        b_mask = (b_sub_array != 1) & (b_sub_array != -1)\n",
        "\n",
        "        a_count = 50 - a_mask.sum(axis=0)\n",
        "        b_count = 50 - b_mask.sum(axis=0)\n",
        "\n",
        "        print(\"a_count\")\n",
        "        print(a_count)\n",
        "        print(\"b_count\")\n",
        "        print(b_count)\n",
        "\n",
        "\n",
        "    if is_terminal:\n",
        "        # print(state)\n",
        "        # if value == 1:\n",
        "        #     print(\"â­  â­  â­  â­  â­\")\n",
        "        #     print(\"ì¸ê³µì§€ëŠ¥ íŒ¨ë°°\")\n",
        "        # elif value == -1:\n",
        "        #     print(\"â­  â­  â­  â­  â­\")\n",
        "        #     print(\"ì¸ê³µì§€ëŠ¥ ìŠ¹ë¦¬\")\n",
        "        # else:\n",
        "        #     print(\"â­  â­  â­  â­  â­\")\n",
        "        #     print(\"ë¬´ìŠ¹ë¶€\")\n",
        "        break\n",
        "\n",
        "    # print(\"a_score\", a_score, \"   b_score\", b_score)\n",
        "    print(\" ğŸˆ ëª¨ë“  ê²Œì„ì— ëŒ€í•´ a, b ëª¨ë‘ í•©í•´ì„œ\", sum(scheduled_cars_list) , \"ë§Œí¼ ìë™ì°¨ ë‘ì—ˆìŒ\")\n",
        "    print()\n",
        "\n",
        "    player = game.get_opponent(player)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVkg4ukLC_7I"
      },
      "source": [
        "### ìŠ¤ì¼€ì¤„ë§ ì§„í–‰í•˜ì§€ ì•ŠìŒ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZkzYTza08H6"
      },
      "outputs": [],
      "source": [
        "long_term_scheduled = copy.deepcopy(initial_long_term_scheduled)\n",
        "schedule_range = copy.deepcopy(initial_schedule_range)\n",
        "scheduled_cars_list = copy.deepcopy(initial_scheduled_cars_list)\n",
        "judge_num = (sum(long_term_scheduled) - sum(schedule_range[:initial_index])) // 2 + 1\n",
        "self_judge_num = (sum(long_term_scheduled) - sum(schedule_range[:initial_index])) // 2 + 1\n",
        "\n",
        "game = MinDelay(eta_distribution_prob, eta_prob)\n",
        "player = 1\n",
        "\n",
        "args = {\n",
        "    'C': 2,\n",
        "    'num_iterations': 10,              # ëª‡ ë²ˆ ëª¨ë¸ì„ í›ˆë ¨í• êº¼ëƒ\n",
        "    'num_selfPlay_iterations': 1,    # ìê¸°ëŒ€êµ­ ëª‡ ë²ˆ í• êº¼ëƒ ... í›ˆë ¨ ìƒ˜í”Œì˜ ìˆ˜\n",
        "    'num_searches': 50,               # ì–¼ë§Œí¼(ëª‡ ë…¸ë“œë§Œí¼) ë” ë‚´ë‹¤ë³¼ê±°ëƒ .... (2~3ìˆ˜ ì•ê¹Œì§€ ë‚´ë‹¤ë³´ì!)\n",
        "    'num_epochs': 50,                  # ëª‡ ì—í¬í¬ ëŒë¦´êº¼ëƒ\n",
        "    'num_parallel_games': 1,          # í•œ ë²ˆì— ëª‡ ê°œì”© ë³‘ë ¬ë¡œ ê²Œì„ ì‹œí–‰\n",
        "    'batch_size': 10,\n",
        "    'temperature': 1.25,\n",
        "    'dirichlet_epsilon': 0.25,\n",
        "    'dirichlet_alpha': 0.3\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ResNet(game, 9, 128, device)\n",
        "model.load_state_dict(torch.load(\"model_current.pt\"))\n",
        "model.eval()\n",
        "\n",
        "mcts = MCTS(game, args, model)\n",
        "\n",
        "state = game.get_initial_state()\n",
        "\n",
        "actioned_index = None\n",
        "a_score = 0\n",
        "b_score = 0\n",
        "\n",
        "for i, counts in enumerate(scheduled_cars_list):\n",
        "    for count in range(int(counts / 2)):\n",
        "        cars_action = np.random.choice(range(-3, 6 + 1), size=1, p=game.eta_prob)\n",
        "        action = random.randint(0, 3)\n",
        "\n",
        "        row = np.where(state[:50, i  + action + cars_action] == 0)[0][0]\n",
        "        state[row, i  + action + cars_action] = -1\n",
        "\n",
        "        row= np.where(state[50:, i  + action + cars_action] == 0)[0][0] + 50\n",
        "        state[row, i + action + cars_action] = 1\n",
        "\n",
        "    _, terminated, _, _, _, _, _, _, _, _, _ = game.check_win(state, a_score, b_score, scheduled_cars_list, judge_num)\n",
        "\n",
        "while terminated == True:\n",
        "      state = game.get_initial_state()\n",
        "      for i, counts in enumerate(scheduled_cars_list):\n",
        "          for count in range(int(counts / 2)):\n",
        "              cars_action = np.random.choice(range(-3, 6 + 1), size=1, p=game.eta_prob)\n",
        "              action = random.randint(0, 3)\n",
        "\n",
        "              row = np.where(state[:50, i  + action + cars_action] == 0)[0][0]\n",
        "              state[row, i  + action + cars_action] = -1\n",
        "\n",
        "              row= np.where(state[50:, i  + action + cars_action] == 0)[0][0] + 50\n",
        "              state[row, i + action + cars_action] = 1\n",
        "\n",
        "      _, terminated, _, _, _, _, _, _, _, _, _ = game.check_win(state, a_score, b_score, scheduled_cars_list, judge_num)\n",
        "\n",
        "while True :\n",
        "    if player == 1:\n",
        "        action = 0\n",
        "    else:\n",
        "        action = 0\n",
        "\n",
        "    state, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index \\\n",
        "    = game.get_next_state(state, action, player, long_term_scheduled, schedule_range, scheduled_cars_list, actioned_index, action, test = True)\n",
        "\n",
        "    value, is_terminal, a_score, b_score, scheduled_cars_list, self_judge_num, bottom20, bottom35, bottom50, avg_a_total_front_cars, avg_b_total_front_cars \\\n",
        "    = game.test_get_value_and_terminated(state, action, a_score, b_score, scheduled_cars_list, self_judge_num)\n",
        "\n",
        "    if (sum(scheduled_cars_list)) >= (15 * 2) :\n",
        "        a_sub_array = state[:50]\n",
        "        b_sub_array = state[50:]\n",
        "\n",
        "        a_mask = (a_sub_array != 1) & (a_sub_array != -1)\n",
        "        b_mask = (b_sub_array != 1) & (b_sub_array != -1)\n",
        "\n",
        "        a_count = 50 - a_mask.sum(axis=0)\n",
        "        b_count = 50 - b_mask.sum(axis=0)\n",
        "\n",
        "        print(\"a_count\")\n",
        "        print(a_count)\n",
        "        print(\"b_count\")\n",
        "        print(b_count)\n",
        "\n",
        "\n",
        "    if is_terminal:\n",
        "        # print(state)\n",
        "        # if value == 1:\n",
        "        #     print(\"â­  â­  â­  â­  â­\")\n",
        "        #     print(\"ì¸ê³µì§€ëŠ¥ íŒ¨ë°°\")\n",
        "        # elif value == -1:\n",
        "        #     print(\"â­  â­  â­  â­  â­\")\n",
        "        #     print(\"ì¸ê³µì§€ëŠ¥ ìŠ¹ë¦¬\")\n",
        "        # else:\n",
        "        #     print(\"â­  â­  â­  â­  â­\")\n",
        "        #     print(\"ë¬´ìŠ¹ë¶€\")\n",
        "        break\n",
        "\n",
        "    # print(\"a_score\", a_score, \"   b_score\", b_score)\n",
        "    print(\" ğŸˆ ëª¨ë“  ê²Œì„ì— ëŒ€í•´ a, b ëª¨ë‘ í•©í•´ì„œ\", sum(scheduled_cars_list) , \"ë§Œí¼ ìë™ì°¨ ë‘ì—ˆìŒ\")\n",
        "    print()\n",
        "\n",
        "    player = game.get_opponent(player)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n1Z7RTSk2FS"
      },
      "source": [
        "## (ë¹„êµêµ°2) VS ë² ì´ì¦ˆ ì •ë¦¬ ê¸°ë°˜ ëª¬í…Œì¹´ë¥¼ë¡œ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def balls_left_in_queue(enter_times):\n",
        "    # ê° ê³µì´ ë¹ ì ¸ë‚˜ê°€ëŠ” ì‹œê°„ì„ ê³„ì‚°\n",
        "    exit_times = []\n",
        "    current_exit_time = 0\n",
        "    total = 0\n",
        "    q_distribution = []\n",
        "    for i, enter_time in enumerate(enter_times):\n",
        "        # íì— ì•„ë¬´ëŸ° ê³µì´ ì—†ë‹¤ë©´ ë°”ë¡œ ë¹ ì ¸ë‚˜ê°ˆ ìˆ˜ ìˆë‹¤\n",
        "        if current_exit_time == enter_time:\n",
        "            current_exit_time = enter_time\n",
        "        elif current_exit_time + n < enter_time:\n",
        "            current_exit_time = enter_time\n",
        "        else:\n",
        "            # ê·¸ë ‡ì§€ ì•Šìœ¼ë©´, ì´ì „ ê³µì´ ë¹ ì ¸ë‚˜ê°„ ì‹œì  + n\n",
        "            current_exit_time += n\n",
        "        exit_times.append(current_exit_time)\n",
        "\n",
        "        # ê° enter_timeì— ëŒ€í•´ ë¹ ì ¸ë‚˜ê°€ì§€ ì•Šì€ ê³µì˜ ê°œìˆ˜ ê³„ì‚°\n",
        "        front_cars = np.sum(np.array(exit_times[:i+1]) > enter_time)\n",
        "        q_distribution.append(front_cars)\n",
        "        total += front_cars\n",
        "\n",
        "    return total\n",
        "\n",
        "def generate_random_list_test(íŒ_copy):\n",
        "    generated_data = []\n",
        "    # ì„ íƒëœ ì‹œê°„ëŒ€ì— ëŒ€í•œ ëœë¤í•œ ì‹œê°„ ê°’ì„ ìƒì„±\n",
        "    for i,x in enumerate(íŒ_copy):\n",
        "        if x != 0:\n",
        "            for s in range(x):\n",
        "                generated_data.append(random.uniform(i*10, (i+1)*10))\n",
        "    return generated_data\n",
        "\n",
        "def generate(íŒ, origin_index, change_num, num_samples = 1000):\n",
        "    total = []\n",
        "    samples = np.random.choice(len(eta_distribution_prob ), size=num_samples, p=eta_distribution_prob )\n",
        "    # samples ê°’ì€ 0 ì´ìƒ len(eta_probabilities) ... 15 ì´í•˜\n",
        "    samples = np.array(samples)\n",
        "    samples = list(samples)\n",
        "\n",
        "    for sampled_index in samples:\n",
        "        # for s in range(10):\n",
        "        íŒ_copy = copy.deepcopy(íŒ)\n",
        "        íŒ_copy[origin_index + change_num + sampled_index] += 1\n",
        "        sampled = generate_random_list_test(íŒ_copy)\n",
        "        q = balls_left_in_queue(sampled)\n",
        "        total.append((change_num, q))\n",
        "\n",
        "    return total\n",
        "\n",
        "def filter_lower_20(total_samples):\n",
        "    all_q = []\n",
        "    filtered_num = []\n",
        "    # all_samples ì¤‘ í•„í„°ë§\n",
        "    for num,q in total_samples:\n",
        "        all_q.append(q)\n",
        "\n",
        "    all_q.sort()\n",
        "\n",
        "    index_20_percent = int(len(all_q) * 0.20)\n",
        "    lower_20_percent_element = all_q[index_20_percent]\n",
        "\n",
        "    print(\"avg_20\", lower_20_percent_element)\n",
        "\n",
        "    for num,q in total_samples:\n",
        "        if q <= lower_20_percent_element:\n",
        "            filtered_num.append(num)\n",
        "\n",
        "    return filtered_num"
      ],
      "metadata": {
        "id": "6CMRL88E5qw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "íŒ = [1] + [0] * (3 + (18-7) * 6 + 18 - 1)\n",
        "long_term_scheduled = copy.deepcopy(list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1])\n",
        "\n",
        "for origin_index in range(len(long_term_scheduled)):\n",
        "    for _ in range(long_term_scheduled[origin_index]):\n",
        "        total_samples = []\n",
        "\n",
        "        for change_num in range(4):\n",
        "            total_samples.extend(generate(íŒ, origin_index, change_num))\n",
        "\n",
        "        filtered_num = filter_lower_20(total_samples)\n",
        "\n",
        "        counter = Counter(filtered_num)\n",
        "        most_common_element, most_common_count = counter.most_common(1)[0]\n",
        "        for element, count in counter.items():\n",
        "            print(f\"Element: {element}, Count: {count}\")\n",
        "\n",
        "        íŒ[origin_index + most_common_element] += 1\n",
        "\n",
        "        print(str(origin_index + 1) +\"ë²ˆì§¸ ì‹œê°„ëŒ€ \" + str(_+1) + \"ë²ˆì§¸ í™”ë¬¼ì°¨\")\n",
        "        print(\"ì„ íƒì§€\", most_common_element)\n",
        "        print(íŒ)\n",
        "        print()\n",
        "    print(\"=====================\")\n",
        "\n",
        "print()\n",
        "print(\"ìµœì¢…\", íŒ)"
      ],
      "metadata": {
        "id": "H8w0peDj5r0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“Œ ì§€ê¸ˆê¹Œì§€ ì¬ì¡°ì •í•œ í™”ë¬¼ì°¨ë“¤\n",
        "initial_long_term_scheduled = [0,0,0] + copy.deepcopy(list(min_key_sample_enter_time_counts)[6*2 + 1 :  6*2 + 6*(18-7) + 1]) + [0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "# ì§€ê¸ˆê¹Œì§€ ì¬ì¡°ì •í•œ í™”ë¬¼ì°¨ë“¤ì˜ (ì¬ì¡°ì • -> ìŠ¤ìŠ¤ë¡œ ì´ë™ í›„) í™•ë¥  ë¶„í¬\n",
        "distributions = []\n",
        "for index, count in enumerate(initial_long_term_scheduled):\n",
        "    for _ in range(count):\n",
        "        distributions.append([0] * (index - 3) + list(eta_distribution_prob ) + [0] * (len(initial_long_term_scheduled) - (index + 9)))\n",
        "distributions = copy.deepcopy(initial_long_term_scheduled)\n",
        "probabilities = np.array(distributions) / sum(distributions)\n",
        "\n",
        "# í•˜ìœ„ 20, 25, 50 (ëª¬í…Œì¹´ë¥¼ë¡œ)\n",
        "sum_scheduled_cars = sum(copy.deepcopy(initial_long_term_scheduled))\n",
        "\n",
        "total_front_cars_distribution = monte_carlo_distribution(1000, sum_scheduled_cars , probabilities)\n",
        "labels = sorted(total_front_cars_distribution.keys())\n",
        "values = [total_front_cars_distribution[key] for key in labels]\n",
        "cumulative_values = np.cumsum(values)\n",
        "\n",
        "bottom_min = labels[np.where(cumulative_values >= cumulative_values[-1] / (1/0.001))[0][0]]\n",
        "bottom20 = labels[np.where(cumulative_values >= cumulative_values[-1] / (1/0.2))[0][0]]\n",
        "bottom35 = labels[np.where(cumulative_values >= cumulative_values[-1] / (1/0.35))[0][0]]\n",
        "bottom50 = labels[np.where(cumulative_values >= cumulative_values[-1] / (1/0.5))[0][0]]\n",
        "\n",
        "print(\"ì•„ë§ˆ ìµœì†Œ: \", bottom_min)\n",
        "print(\"bottom20: \", bottom20)\n",
        "print(\"bottom35: \", bottom35)\n",
        "print(\"bottom50: \", bottom50)\n",
        "\n",
        "total_front_cars = [1, 1, 5, 15, 12, 11, 12, 12, 8, 7, 8, 15, 7, 8, 12, 7, 14, 12, 9, 17, 8, 7, 12, 7, 10, 10, 10, 10, 12, 7, 14, 9, 6, 6, 10, 5, 8, 6, 14, 11, 14, 11, 11, 10, 9, 8, 7, 7, 9, 5, 9, 7, 9, 11, 7, 7, 3, 5, 4, 4, 8, 6, 2, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "# ğŸ“Œ total_front_carsì—ë‹¤ê°€ ì¶œë ¥ê°’ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ê¸°\n",
        "\n",
        "total_list = []\n",
        "\n",
        "for i in range(200):\n",
        "    chosen_intervals = []\n",
        "    for idx, arr in enumerate(total_front_cars):\n",
        "        for _ in range(int(arr)):\n",
        "            chosen_intervals.append(idx)\n",
        "    enter_times = [random.uniform(i*10, (i+1)*10) for i in chosen_intervals]\n",
        "    total_list.append(balls_left_in_queue(enter_times))\n",
        "counter = Counter(total_list)\n",
        "top_3_common = counter.most_common(3)\n",
        "top_3_values = [item[0] for item in top_3_common]\n",
        "avg_total_front_cars = sum(top_3_values) / len(top_3_values)\n",
        "\n",
        "print(\"avg_total_front_cars: \", avg_total_front_cars)"
      ],
      "metadata": {
        "id": "PRBXLHJ65uk3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Hu9n3SAO4S87",
        "KtjJelMJ8eq-",
        "39cQHa9I-OH-",
        "Tu6ZPD_RIPS_",
        "I4i403CP8l37",
        "KWxQWR_RNPI1",
        "_d1jRJuh332U",
        "4jJq3IM1nIU2"
      ],
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}